#!/usr/bin/env python3
# SPDX-FileCopyrightText: Copyright (c) 2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Test NVIDIA NIM Integration for Warehouse Operational Assistant

This script tests the full LLM integration with various inventory queries.
"""

import asyncio
import json
import sys
import pytest
from pathlib import Path

# Add project root to path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# Import test configuration
from tests.unit.test_config import CHAT_ENDPOINT, DEFAULT_TIMEOUT

@pytest.mark.asyncio
async def test_nvidia_integration():
    """Test the full NVIDIA NIM integration."""
    print("üß™ Testing NVIDIA NIM Integration")
    print("=" * 50)
    
    try:
        # Test 1: NIM Client Health Check
        print("\n1Ô∏è‚É£ Testing NIM Client Health Check...")
        from src.api.services.llm.nim_client import get_nim_client
        
        nim_client = await get_nim_client()
        health = await nim_client.health_check()
        
        print(f"   LLM Service: {'‚úÖ' if health['llm_service'] else '‚ùå'}")
        print(f"   Embedding Service: {'‚úÖ' if health['embedding_service'] else '‚ùå'}")
        print(f"   Overall: {'‚úÖ' if health['overall'] else '‚ùå'}")
        
        if not health['overall']:
            print("‚ùå NVIDIA NIM services are not healthy. Please check your API key and connection.")
            return False
        
        # Test 2: Inventory Agent Initialization
        print("\n2Ô∏è‚É£ Testing Inventory Intelligence Agent...")
        from src.api.agents.inventory.inventory_agent import get_inventory_agent
        
        inventory_agent = await get_inventory_agent()
        print("   ‚úÖ Inventory Intelligence Agent initialized")
        
        # Test 3: Sample Queries
        test_queries = [
            "What is the stock level for SKU123?",
            "Which items need reordering?",
            "Show me low stock items",
            "Where is the Blue Pallet Jack located?",
            "Help me plan cycle counting for Aisle A3"
        ]
        
        print("\n3Ô∏è‚É£ Testing Sample Inventory Queries...")
        for i, query in enumerate(test_queries, 1):
            print(f"\n   Query {i}: {query}")
            try:
                response = await inventory_agent.process_query(query, session_id="test")
                
                print(f"   Response Type: {response.response_type}")
                print(f"   Confidence: {response.confidence:.2f}")
                print(f"   Natural Language: {response.natural_language[:100]}...")
                print(f"   Recommendations: {len(response.recommendations)} items")
                
                if response.structured_data:
                    print(f"   Structured Data: {json.dumps(response.structured_data, indent=2)[:200]}...")
                
            except Exception as e:
                print(f"   ‚ùå Error: {e}")
        
        # Test 4: API Endpoint Test
        print("\n4Ô∏è‚É£ Testing API Endpoint...")
        import httpx
        
        async with httpx.AsyncClient(timeout=DEFAULT_TIMEOUT) as client:
            try:
                response = await client.post(
                    CHAT_ENDPOINT,
                    json={"message": "What is the stock level for SKU123?"},
                    headers={"Content-Type": "application/json"},
                    timeout=DEFAULT_TIMEOUT
                )
                
                if response.status_code == 200:
                    data = response.json()
                    print("   ‚úÖ API endpoint responding")
                    print(f"   Route: {data.get('route')}")
                    print(f"   Intent: {data.get('intent')}")
                    print(f"   Confidence: {data.get('confidence')}")
                    print(f"   Reply: {data.get('reply', '')[:100]}...")
                else:
                    print(f"   ‚ùå API endpoint error: {response.status_code}")
                    
            except Exception as e:
                print(f"   ‚ùå API endpoint test failed: {e}")
        
        print("\nüéâ NVIDIA NIM Integration Test Complete!")
        return True
        
    except Exception as e:
        print(f"‚ùå Integration test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

@pytest.mark.asyncio
async def test_llm_capabilities():
    """Test specific LLM capabilities."""
    print("\nüß† Testing LLM Capabilities")
    print("=" * 30)
    
    try:
        from src.api.services.llm.nim_client import get_nim_client
        
        nim_client = await get_nim_client()
        
        # Test 1: Basic LLM Response
        print("\n1Ô∏è‚É£ Testing Basic LLM Response...")
        messages = [
            {"role": "system", "content": "You are a warehouse inventory expert."},
            {"role": "user", "content": "What is the difference between SKU and barcode?"}
        ]
        
        response = await nim_client.generate_response(messages, temperature=0.1, max_tokens=200)
        print(f"   Response: {response.content[:150]}...")
        print(f"   Model: {response.model}")
        print(f"   Usage: {response.usage}")
        
        # Test 2: Embedding Generation
        print("\n2Ô∏è‚É£ Testing Embedding Generation...")
        texts = ["warehouse inventory management", "safety procedures", "equipment maintenance"]
        
        embedding_response = await nim_client.generate_embeddings(texts)
        print(f"   Generated {len(embedding_response.embeddings)} embeddings")
        print(f"   Embedding dimension: {len(embedding_response.embeddings[0])}")
        print(f"   Model: {embedding_response.model}")
        
        print("   ‚úÖ LLM capabilities working correctly")
        return True
        
    except Exception as e:
        print(f"   ‚ùå LLM capabilities test failed: {e}")
        return False

if __name__ == "__main__":
    async def main():
        print("üöÄ NVIDIA NIM Integration Test Suite")
        print("=" * 50)
        
        # Check if API key is set
        import os
        from dotenv import load_dotenv
        load_dotenv()
        
        api_key = os.getenv("NVIDIA_API_KEY")
        if not api_key or api_key == "your_nvidia_api_key_here":
            print("‚ùå NVIDIA API key not configured.")
            print("Please run: python setup_nvidia_api.py")
            sys.exit(1)
        
        # Run tests
        llm_success = await test_llm_capabilities()
        integration_success = await test_nvidia_integration()
        
        if llm_success and integration_success:
            print("\nüéâ All tests passed! NVIDIA NIM integration is working correctly.")
        else:
            print("\n‚ùå Some tests failed. Please check the errors above.")
            sys.exit(1)
    
    asyncio.run(main())
