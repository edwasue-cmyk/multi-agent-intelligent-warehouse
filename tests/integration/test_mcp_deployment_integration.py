# SPDX-FileCopyrightText: Copyright (c) 2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Deployment integration tests for the MCP system.

This module tests the MCP system in deployment scenarios including:
- Docker containerization
- Kubernetes deployment
- Production environment simulation
- Load balancing and scaling
- Health checks and monitoring
"""

import asyncio
import pytest
import json
import time
from datetime import datetime, timedelta
from typing import Dict, Any, List
from unittest.mock import AsyncMock, MagicMock, patch

from src.api.services.mcp.server import MCPServer, MCPTool, MCPToolType
from src.api.services.mcp.client import MCPClient, MCPConnectionType
from src.api.services.mcp.tool_discovery import ToolDiscoveryService, ToolDiscoveryConfig
from src.api.services.mcp.tool_binding import ToolBindingService, BindingStrategy, ExecutionMode
from src.api.services.mcp.tool_routing import ToolRoutingService, RoutingStrategy
from src.api.services.mcp.tool_validation import ToolValidationService, ValidationLevel
from src.api.services.mcp.service_discovery import ServiceRegistry, ServiceType
from src.api.services.mcp.monitoring import MCPMonitoring


class TestMCPDockerDeployment:
    """Test MCP system in Docker deployment scenarios."""

    @pytest.fixture
    async def mcp_server(self):
        """Create MCP server for Docker testing."""
        server = MCPServer()
        await server.start()
        yield server
        await server.stop()

    @pytest.fixture
    async def mcp_client(self):
        """Create MCP client for Docker testing."""
        client = MCPClient()
        yield client
        await client.disconnect()

    async def test_docker_container_startup(self, mcp_server, mcp_client):
        """Test Docker container startup and health checks."""
        
        # Test server startup
        server_status = await mcp_server.get_server_status()
        assert server_status['running'], "MCP server should be running in Docker"
        
        # Test client connection
        success = await mcp_client.connect("http://localhost:8000", MCPConnectionType.HTTP)
        assert success, "MCP client should connect to server in Docker"
        
        # Test health check endpoint
        health = await mcp_client.get_server_status()
        assert health is not None, "Should have health status in Docker"

    async def test_docker_container_restart(self, mcp_server, mcp_client):
        """Test Docker container restart and recovery."""
        
        # Connect client
        await mcp_client.connect("http://localhost:8000", MCPConnectionType.HTTP)
        
        # Simulate container restart
        await mcp_server.stop()
        await asyncio.sleep(1)
        await mcp_server.start()
        
        # Test reconnection
        success = await mcp_client.connect("http://localhost:8000", MCPConnectionType.HTTP)
        assert success, "Should reconnect after container restart"

    async def test_docker_container_health_monitoring(self, mcp_server, mcp_client, monitoring_service):
        """Test Docker container health monitoring."""
        
        # Start monitoring
        await monitoring_service.start_monitoring()
        
        # Connect client
        await mcp_client.connect("http://localhost:8000", MCPConnectionType.HTTP)
        
        # Record health metrics
        from src.api.services.mcp.monitoring import MetricType
        await monitoring_service.metrics_collector.record_metric("container_health", 1.0, MetricType.GAUGE, {"container": "mcp_server"})
        await monitoring_service.metrics_collector.record_metric("active_connections", 1.0, MetricType.GAUGE, {"container": "mcp_server"})
        
        # Test health monitoring
        dashboard = await monitoring_service.get_monitoring_dashboard()
        assert "system_health" in dashboard, "Should monitor container health"
        
        # Test health check endpoint
        health = await mcp_client.get_server_status()
        assert health is not None, "Should have health status"

    async def test_docker_container_resource_limits(self, mcp_server, mcp_client):
        """Test Docker container resource limits."""
        
        import psutil
        import os
        
        process = psutil.Process(os.getpid())
        
        # Get initial resource usage
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB
        initial_cpu = process.cpu_percent()
        
        # Connect client
        await mcp_client.connect("http://localhost:8000", MCPConnectionType.HTTP)
        
        # Execute many operations to test resource usage
        tasks = []
        for i in range(1000):
            task = mcp_client.execute_tool("get_inventory", {"item_id": f"ITEM{i:03d}"})
            tasks.append(task)
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Check resource usage
        final_memory = process.memory_info().rss / 1024 / 1024  # MB
        final_cpu = process.cpu_percent()
        
        memory_increase = final_memory - initial_memory
        
        # Resource usage should be reasonable
        assert memory_increase < 500, f"Memory increase should be reasonable: {memory_increase:.1f}MB"
        assert final_cpu < 100, f"CPU usage should be reasonable: {final_cpu:.1f}%"

    async def test_docker_container_logging(self, mcp_server, mcp_client):
        """Test Docker container logging."""
        
        # Connect client
        await mcp_client.connect("http://localhost:8000", MCPConnectionType.HTTP)
        
        # Execute operations to generate logs
        await mcp_client.execute_tool("get_inventory", {"item_id": "ITEM001"})
        await mcp_client.execute_tool("get_inventory", {"item_id": "ITEM002"})
        
        # Test log collection (in real implementation, you would check log files)
        # For now, we just verify the operations complete
        assert True, "Should generate logs for operations"

    async def test_docker_container_networking(self, mcp_server, mcp_client):
        """Test Docker container networking."""
        
        # Test different connection types
        success = await mcp_client.connect("http://localhost:8000", MCPConnectionType.HTTP)
        assert success, "Should connect via HTTP"
        
        # Test connection persistence
        result = await mcp_client.execute_tool("get_inventory", {"item_id": "ITEM001"})
        assert result is not None, "Should execute tool over network"
        
        # Test connection timeout
        await mcp_client.disconnect()
        success = await mcp_client.connect("http://localhost:8000", MCPConnectionType.HTTP)
        assert success, "Should reconnect after disconnect"


class TestMCPKubernetesDeployment:
    """Test MCP system in Kubernetes deployment scenarios."""

    @pytest.fixture
    async def mcp_server(self):
        """Create MCP server for Kubernetes testing."""
        server = MCPServer()
        await server.start()
        yield server
        await server.stop()

    @pytest.fixture
    async def mcp_client(self):
        """Create MCP client for Kubernetes testing."""
        client = MCPClient()
        yield client
        await client.disconnect()

    async def test_kubernetes_pod_startup(self, mcp_server, mcp_client):
        """Test Kubernetes pod startup and readiness."""
        
        # Test server startup
        server_status = await mcp_server.get_server_status()
        assert server_status['running'], "MCP server should be running in Kubernetes"
        
        # Test readiness probe
        health = await mcp_client.get_server_status()
        assert health is not None, "Should pass readiness probe"
        
        # Test liveness probe
        result = await mcp_client.execute_tool("get_inventory", {"item_id": "ITEM001"})
        assert result is not None, "Should pass liveness probe"

    async def test_kubernetes_service_discovery(self, mcp_server, mcp_client, service_registry):
        """Test Kubernetes service discovery."""
        
        from src.api.services.mcp.service_discovery import ServiceInfo
        
        # Register services
        mcp_service = ServiceInfo(
            service_id="mcp_server_001",
            service_name="MCP Server",
            service_type=ServiceType.SERVER,
            endpoint="http://mcp-server:8000",
            version="1.0.0",
            capabilities=["tool_execution", "tool_discovery"]
        )
        
        await service_registry.register_service(mcp_service)
        
        # Test service discovery
        services = await service_registry.discover_services(ServiceType.SERVER)
        assert len(services) > 0, "Should discover MCP server service"
        
        # Test service health
        health = await service_registry.get_service_health(mcp_service.service_id)
        assert health is not None, "Should have service health"

    async def test_kubernetes_load_balancing(self, mcp_server, mcp_client):
        """Test Kubernetes load balancing."""
        
        # Simulate multiple client connections (representing different pods)
        clients = []
        for i in range(5):
            client = MCPClient()
            await client.connect("http://localhost:8000", MCPConnectionType.HTTP)
            clients.append(client)
        
        # Execute operations from multiple clients
        tasks = []
        for i, client in enumerate(clients):
            task = client.execute_tool("get_inventory", {"item_id": f"ITEM{i:03d}"})
            tasks.append(task)
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Check load balancing
        successful_results = [r for r in results if not isinstance(r, Exception)]
        assert len(successful_results) > 0, "Should handle load balancing"
        
        # Cleanup
        for client in clients:
            await client.disconnect()

    async def test_kubernetes_scaling(self, mcp_server, mcp_client):
        """Test Kubernetes horizontal scaling."""
        
        # Simulate scaling up
        clients = []
        for i in range(10):  # Simulate 10 replicas
            client = MCPClient()
            await client.connect("http://localhost:8000", MCPConnectionType.HTTP)
            clients.append(client)
        
        # Execute operations from all clients
        tasks = []
        for i, client in enumerate(clients):
            task = client.execute_tool("get_inventory", {"item_id": f"ITEM{i:03d}"})
            tasks.append(task)
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Check scaling
        successful_results = [r for r in results if not isinstance(r, Exception)]
        assert len(successful_results) > 0, "Should handle horizontal scaling"
        
        # Cleanup
        for client in clients:
            await client.disconnect()

    async def test_kubernetes_configuration_management(self, mcp_server, mcp_client, discovery_service):
        """Test Kubernetes configuration management."""
        
        # Test configuration updates
        original_config = discovery_service.config
        new_config = ToolDiscoveryConfig(
            discovery_interval=10,
            max_tools_per_source=200
        )
        
        # Update configuration
        discovery_service.config = new_config
        assert discovery_service.config.discovery_interval == 10, "Should update configuration"
        
        # Test configuration persistence
        assert discovery_service.config.max_tools_per_source == 200, "Should persist configuration"

    async def test_kubernetes_secrets_management(self, mcp_server, mcp_client):
        """Test Kubernetes secrets management."""
        
        # Test with mock secrets
        with patch.dict('os.environ', {
            'DATABASE_URL': 'postgresql://user:password@localhost:5432/db',
            'REDIS_URL': 'redis://localhost:6379/0',
            'JWT_SECRET_KEY': 'secret-key'
        }):
            # Test that secrets are accessible
            import os
            assert os.getenv('DATABASE_URL') is not None, "Should access database URL"
            assert os.getenv('REDIS_URL') is not None, "Should access Redis URL"
            assert os.getenv('JWT_SECRET_KEY') is not None, "Should access JWT secret"

    async def test_kubernetes_monitoring_integration(self, mcp_server, mcp_client, monitoring_service):
        """Test Kubernetes monitoring integration."""
        
        # Start monitoring
        await monitoring_service.start_monitoring()
        
        # Connect client
        await mcp_client.connect("http://localhost:8000", MCPConnectionType.HTTP)
        
        # Record metrics
        from src.api.services.mcp.monitoring import MetricType
        await monitoring_service.metrics_collector.record_metric("pod_health", 1.0, MetricType.GAUGE, {"pod": "mcp-server-001"})
        await monitoring_service.metrics_collector.record_metric("request_count", 1.0, MetricType.COUNTER, {"pod": "mcp-server-001"})
        
        # Test metrics collection
        metrics = await monitoring_service.get_metrics("pod_health")
        assert len(metrics) > 0, "Should collect pod metrics"
        
        # Test monitoring dashboard
        dashboard = await monitoring_service.get_monitoring_dashboard()
        assert "system_health" in dashboard, "Should have monitoring dashboard"


class TestMCPProductionDeployment:
    """Test MCP system in production deployment scenarios."""

    @pytest.fixture
    async def mcp_server(self):
        """Create MCP server for production testing."""
        server = MCPServer()
        await server.start()
        yield server
        await server.stop()

    @pytest.fixture
    async def mcp_client(self):
        """Create MCP client for production testing."""
        client = MCPClient()
        yield client
        await client.disconnect()

    async def test_production_health_checks(self, mcp_server, mcp_client):
        """Test production health checks."""
        
        # Test server health
        server_status = await mcp_server.get_server_status()
        assert server_status['running'], "Server should be healthy in production"
        
        # Test client health
        health = await mcp_client.get_server_status()
        assert health is not None, "Client should have health status"
        
        # Test health check endpoint
        result = await mcp_client.execute_tool("get_inventory", {"item_id": "ITEM001"})
        assert result is not None, "Should pass health check"

    async def test_production_monitoring(self, mcp_server, mcp_client, monitoring_service):
        """Test production monitoring."""
        
        # Start monitoring
        await monitoring_service.start_monitoring()
        
        # Connect client
        await mcp_client.connect("http://localhost:8000", MCPConnectionType.HTTP)
        
        # Record production metrics
        from src.api.services.mcp.monitoring import MetricType
        await monitoring_service.metrics_collector.record_metric("production_requests", 1.0, MetricType.COUNTER, {"environment": "production"})
        await monitoring_service.metrics_collector.record_metric("error_rate", 0.01, MetricType.GAUGE, {"environment": "production"})
        await monitoring_service.metrics_collector.record_metric("response_time", 0.5, MetricType.GAUGE, {"environment": "production"})
        
        # Test metrics collection
        metrics = await monitoring_service.get_metrics("production_requests")
        assert len(metrics) > 0, "Should collect production metrics"
        
        # Test alerting thresholds
        dashboard = await monitoring_service.get_monitoring_dashboard()
        assert "system_health" in dashboard, "Should have production monitoring"

    async def test_production_security(self, mcp_server, mcp_client):
        """Test production security."""
        
        # Test authentication
        with patch('src.api.services.mcp.client.MCPClient._authenticate') as mock_auth:
            mock_auth.return_value = True
            await mcp_client.connect("http://localhost:8000", MCPConnectionType.HTTP)
            
            result = await mcp_client.execute_tool("get_inventory", {"item_id": "ITEM001"})
            assert result is not None, "Should authenticate in production"
        
        # Test authorization
        # In a real implementation, you would test role-based access control
        assert True, "Should enforce authorization in production"

    async def test_production_performance(self, mcp_server, mcp_client):
        """Test production performance."""
        
        # Connect client
        await mcp_client.connect("http://localhost:8000", MCPConnectionType.HTTP)
        
        # Test performance under load
        start_time = time.time()
        
        tasks = []
        for i in range(1000):
            task = mcp_client.execute_tool("get_inventory", {"item_id": f"ITEM{i:03d}"})
            tasks.append(task)
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        end_time = time.time()
        execution_time = end_time - start_time
        
        # Check performance
        successful_results = [r for r in results if not isinstance(r, Exception)]
        success_rate = len(successful_results) / len(results)
        throughput = len(successful_results) / execution_time
        
        assert success_rate > 0.8, f"Should maintain high success rate: {success_rate:.2%}"
        assert throughput > 10, f"Should maintain good throughput: {throughput:.2f} ops/sec"
        assert execution_time < 60, f"Should complete within reasonable time: {execution_time:.2f}s"

    async def test_production_reliability(self, mcp_server, mcp_client):
        """Test production reliability."""
        
        # Connect client
        await mcp_client.connect("http://localhost:8000", MCPConnectionType.HTTP)
        
        # Test fault tolerance
        result = await mcp_client.execute_tool("invalid_tool", {})
        assert not result.success, "Should handle invalid tools gracefully"
        
        # Test connection recovery
        await mcp_client.disconnect()
        success = await mcp_client.connect("http://localhost:8000", MCPConnectionType.HTTP)
        assert success, "Should recover from disconnection"
        
        # Test data consistency
        result1 = await mcp_client.execute_tool("get_inventory", {"item_id": "ITEM001"})
        result2 = await mcp_client.execute_tool("get_inventory", {"item_id": "ITEM001"})
        assert result1 is not None, "Should maintain data consistency"

    async def test_production_scalability(self, mcp_server, mcp_client):
        """Test production scalability."""
        
        # Simulate high load
        clients = []
        for i in range(50):  # Simulate 50 concurrent clients
            client = MCPClient()
            await client.connect("http://localhost:8000", MCPConnectionType.HTTP)
            clients.append(client)
        
        # Execute operations from all clients
        tasks = []
        for i, client in enumerate(clients):
            task = client.execute_tool("get_inventory", {"item_id": f"ITEM{i:03d}"})
            tasks.append(task)
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Check scalability
        successful_results = [r for r in results if not isinstance(r, Exception)]
        success_rate = len(successful_results) / len(results)
        
        assert success_rate > 0.7, f"Should handle high load: {success_rate:.2%}"
        
        # Cleanup
        for client in clients:
            await client.disconnect()

    async def test_production_backup_and_recovery(self, mcp_server, mcp_client, discovery_service):
        """Test production backup and recovery."""
        
        # Register adapter
        mock_adapter = MagicMock()
        mock_adapter.get_tools.return_value = [
            MCPTool(
                name="get_inventory",
                description="Get inventory levels",
                tool_type=MCPToolType.FUNCTION,
                parameters={},
                handler=AsyncMock(return_value={"item_id": "ITEM001", "quantity": 100})
            )
        ]
        
        await discovery_service.register_discovery_source("test_adapter", mock_adapter, "mcp_adapter")
        await asyncio.sleep(2)
        
        # Get initial state
        initial_tools = await discovery_service.search_tools("inventory")
        initial_count = len(initial_tools)
        
        # Simulate system restart
        await discovery_service.stop_discovery()
        await discovery_service.start_discovery()
        
        # Re-register adapter
        await discovery_service.register_discovery_source("test_adapter", mock_adapter, "mcp_adapter")
        await asyncio.sleep(2)
        
        # Verify recovery
        recovered_tools = await discovery_service.search_tools("inventory")
        recovered_count = len(recovered_tools)
        
        assert recovered_count >= initial_count, "Should recover after restart"

    async def test_production_logging_and_auditing(self, mcp_server, mcp_client, monitoring_service):
        """Test production logging and auditing."""
        
        # Start monitoring
        await monitoring_service.start_monitoring()
        
        # Connect client
        await mcp_client.connect("http://localhost:8000", MCPConnectionType.HTTP)
        
        # Execute operations to generate logs
        await mcp_client.execute_tool("get_inventory", {"item_id": "ITEM001"})
        await mcp_client.execute_tool("get_inventory", {"item_id": "ITEM002"})
        
        # Record audit events
        from src.api.services.mcp.monitoring import MetricType
        await monitoring_service.metrics_collector.record_metric("audit_event", 1.0, MetricType.GAUGE, {
            "event_type": "tool_execution",
            "user_id": "user_001",
            "tool_name": "get_inventory"
        })
        
        # Test log collection
        metrics = await monitoring_service.get_metrics("audit_event")
        assert len(metrics) > 0, "Should collect audit events"
        
        # Test monitoring dashboard
        dashboard = await monitoring_service.get_monitoring_dashboard()
        assert "system_health" in dashboard, "Should have production monitoring"


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
