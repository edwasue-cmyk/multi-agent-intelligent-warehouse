# SPDX-FileCopyrightText: Copyright (c) 2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
End-to-end integration tests for the complete MCP system.

This module tests the full MCP workflow including:
- MCP server and client communication
- Tool discovery and registration
- Tool binding and execution
- Service discovery and monitoring
- Complete agent workflows
"""

import asyncio
import pytest
import json
from datetime import datetime, timedelta
from typing import Dict, Any, List
from unittest.mock import AsyncMock, MagicMock, patch

from src.api.services.mcp.server import MCPServer, MCPTool, MCPToolType
from src.api.services.mcp.client import MCPClient, MCPConnectionType
from src.api.services.mcp.tool_discovery import ToolDiscoveryService, ToolDiscoveryConfig
from src.api.services.mcp.tool_binding import ToolBindingService, BindingStrategy, ExecutionMode
from src.api.services.mcp.tool_routing import ToolRoutingService, RoutingStrategy
from src.api.services.mcp.tool_validation import ToolValidationService, ValidationLevel
from src.api.services.mcp.service_discovery import ServiceRegistry, ServiceType
from src.api.services.mcp.monitoring import MCPMonitoring
from src.api.services.mcp.adapters.erp_adapter import MCPERPAdapter
from src.api.services.mcp.adapters.wms_adapter import WMSAdapter
from src.api.services.mcp.adapters.iot_adapter import IoTAdapter
from src.api.agents.inventory.mcp_equipment_agent import MCPEquipmentAssetOperationsAgent
from src.api.agents.operations.mcp_operations_agent import MCPOperationsCoordinationAgent
from src.api.agents.safety.mcp_safety_agent import MCPSafetyComplianceAgent


class TestMCPEndToEnd:
    """End-to-end tests for the complete MCP system."""

    @pytest.fixture
    async def mcp_server(self):
        """Create and start MCP server for testing."""
        server = MCPServer()
        await server.start()
        yield server
        await server.stop()

    @pytest.fixture
    async def mcp_client(self):
        """Create MCP client for testing."""
        client = MCPClient()
        yield client
        await client.disconnect()

    @pytest.fixture
    async def discovery_service(self):
        """Create tool discovery service for testing."""
        config = ToolDiscoveryConfig(
            discovery_interval=1,
            max_tools_per_source=50
        )
        discovery = ToolDiscoveryService(config)
        await discovery.start_discovery()
        yield discovery
        await discovery.stop_discovery()

    @pytest.fixture
    async def binding_service(self, discovery_service):
        """Create tool binding service for testing."""
        binding = ToolBindingService(discovery_service)
        yield binding

    @pytest.fixture
    async def routing_service(self, discovery_service, binding_service):
        """Create tool routing service for testing."""
        routing = ToolRoutingService(discovery_service, binding_service)
        yield routing

    @pytest.fixture
    async def validation_service(self, discovery_service):
        """Create tool validation service for testing."""
        validation = ToolValidationService(discovery_service)
        yield validation

    @pytest.fixture
    async def service_registry(self):
        """Create service discovery registry for testing."""
        registry = ServiceRegistry()
        yield registry

    @pytest.fixture
    async def monitoring_service(self, service_registry, discovery_service):
        """Create monitoring service for testing."""
        monitoring = MCPMonitoring(service_registry, discovery_service)
        await monitoring.start()
        yield monitoring
        await monitoring.stop()

    @pytest.fixture
    async def erp_adapter(self):
        """Create ERP adapter for testing."""
        from src.api.services.mcp.base import AdapterConfig, AdapterType
        
        config = AdapterConfig(
            name="Test ERP Adapter",
            adapter_type=AdapterType.ERP,
            endpoint="postgresql://test:test@localhost:5432/test_erp",
            metadata={"capabilities": ["inventory", "orders", "customers"]}
        )
        adapter = MCPERPAdapter(config)
        await adapter.connect()
        yield adapter
        await adapter.disconnect()

    @pytest.fixture
    async def wms_adapter(self):
        """Create WMS adapter for testing."""
        from src.api.services.mcp.base import AdapterConfig, AdapterType
        
        config = AdapterConfig(
            name="Test WMS Adapter",
            adapter_type=AdapterType.WMS,
            endpoint="postgresql://test:test@localhost:5432/test_wms",
            metadata={"capabilities": ["inventory", "warehouse_operations", "order_fulfillment"]}
        )
        adapter = WMSAdapter(config)
        await adapter.connect()
        yield adapter
        await adapter.disconnect()

    @pytest.fixture
    async def iot_adapter(self):
        """Create IoT adapter for testing."""
        from src.api.services.mcp.base import AdapterConfig, AdapterType
        
        config = AdapterConfig(
            name="Test IoT Adapter",
            adapter_type=AdapterType.IOT,
            endpoint="mqtt://test:test@localhost:1883",
            metadata={"capabilities": ["equipment_monitoring", "sensor_data", "telemetry"]}
        )
        adapter = IoTAdapter(config)
        await adapter.connect()
        yield adapter
        await adapter.disconnect()

    @pytest.fixture
    async def equipment_agent(self, discovery_service, binding_service, routing_service, validation_service):
        """Create MCP-enabled equipment agent for testing."""
        agent = MCPEquipmentAssetOperationsAgent(
            discovery_service=discovery_service,
            binding_service=binding_service,
            routing_service=routing_service,
            validation_service=validation_service
        )
        yield agent

    @pytest.fixture
    async def operations_agent(self, discovery_service, binding_service, routing_service, validation_service):
        """Create MCP-enabled operations agent for testing."""
        agent = MCPOperationsCoordinationAgent(
            discovery_service=discovery_service,
            binding_service=binding_service,
            routing_service=routing_service,
            validation_service=validation_service
        )
        yield agent

    @pytest.fixture
    async def safety_agent(self, discovery_service, binding_service, routing_service, validation_service):
        """Create MCP-enabled safety agent for testing."""
        agent = MCPSafetyComplianceAgent(
            discovery_service=discovery_service,
            binding_service=binding_service,
            routing_service=routing_service,
            validation_service=validation_service
        )
        yield agent

    async def test_complete_mcp_workflow(self, mcp_server, mcp_client, discovery_service, 
                                       binding_service, routing_service, validation_service,
                                       erp_adapter, wms_adapter, iot_adapter):
        """Test complete MCP workflow from tool registration to execution."""
        
        # 1. Connect client to server
        success = await mcp_client.connect("http://localhost:8000", MCPConnectionType.HTTP)
        assert success, "Client should connect to server"
        
        # 2. Register adapters with discovery service
        await discovery_service.register_discovery_source("erp_adapter", erp_adapter, "mcp_adapter")
        await discovery_service.register_discovery_source("wms_adapter", wms_adapter, "mcp_adapter")
        await discovery_service.register_discovery_source("iot_adapter", iot_adapter, "mcp_adapter")
        
        # 3. Wait for tool discovery
        await asyncio.sleep(2)  # Allow discovery to run
        
        # 4. Search for tools
        inventory_tools = await discovery_service.search_tools("inventory")
        assert len(inventory_tools) > 0, "Should discover inventory tools"
        
        # 5. Bind tools for a query
        bindings = await binding_service.bind_tools(
            agent_id="test_agent",
            query="Get inventory levels for item ITEM001",
            intent="inventory_lookup",
            entities={"item_id": "ITEM001"},
            context={},
            strategy=BindingStrategy.SEMANTIC_MATCH,
            max_tools=5
        )
        assert len(bindings) > 0, "Should bind tools for query"
        
        # 6. Create execution plan
        from src.api.services.mcp.tool_binding import ExecutionContext
        context = ExecutionContext(
            agent_id="test_agent",
            session_id="test_session",
            user_id="test_user",
            query="Get inventory levels for item ITEM001",
            intent="inventory_lookup",
            entities={"item_id": "ITEM001"},
            user_context={},
            timestamp=datetime.utcnow()
        )
        
        plan = await binding_service.create_execution_plan(context, bindings, ExecutionMode.SEQUENTIAL)
        assert plan is not None, "Should create execution plan"
        
        # 7. Validate tool execution
        for binding in bindings:
            validation_result = await validation_service.validate_tool_execution(
                tool_id=binding.tool_name,
                arguments=binding.arguments,
                context=context.to_dict(),
                validation_level=ValidationLevel.STANDARD
            )
            assert validation_result.is_valid, f"Tool {binding.tool_name} should be valid"
        
        # 8. Execute tools through client
        for binding in bindings:
            result = await mcp_client.execute_tool(binding.tool_name, binding.arguments)
            assert result.success, f"Tool {binding.tool_name} should execute successfully"

    async def test_agent_workflow_integration(self, equipment_agent, operations_agent, safety_agent,
                                            erp_adapter, wms_adapter, iot_adapter, discovery_service):
        """Test complete agent workflow integration."""
        
        # Register adapters
        await discovery_service.register_discovery_source("erp_adapter", erp_adapter, "mcp_adapter")
        await discovery_service.register_discovery_source("wms_adapter", wms_adapter, "mcp_adapter")
        await discovery_service.register_discovery_source("iot_adapter", iot_adapter, "mcp_adapter")
        
        # Wait for discovery
        await asyncio.sleep(2)
        
        # Test equipment agent workflow
        equipment_result = await equipment_agent.process_query(
            query="Get status of forklift EQ001",
            context={"equipment_id": "EQ001", "equipment_type": "forklift"}
        )
        assert equipment_result is not None, "Equipment agent should process query"
        
        # Test operations agent workflow
        operations_result = await operations_agent.process_query(
            query="Schedule maintenance for equipment EQ001",
            context={"equipment_id": "EQ001", "maintenance_type": "scheduled"}
        )
        assert operations_result is not None, "Operations agent should process query"
        
        # Test safety agent workflow
        safety_result = await safety_agent.process_query(
            query="Check safety compliance for area ZONE_A",
            context={"zone_id": "ZONE_A", "check_type": "compliance"}
        )
        assert safety_result is not None, "Safety agent should process query"

    async def test_service_discovery_integration(self, service_registry, erp_adapter, wms_adapter, iot_adapter):
        """Test service discovery and registry integration."""
        
        from src.api.services.mcp.service_discovery import ServiceInfo
        
        # Register services
        erp_service = ServiceInfo(
            service_id="erp_adapter_001",
            service_name="ERP Adapter",
            service_type=ServiceType.ADAPTER,
            endpoint="http://localhost:8001",
            version="1.0.0",
            capabilities=["inventory", "orders", "customers"]
        )
        
        wms_service = ServiceInfo(
            service_id="wms_adapter_001",
            service_name="WMS Adapter",
            service_type=ServiceType.ADAPTER,
            endpoint="http://localhost:8002",
            version="1.0.0",
            capabilities=["inventory", "warehouse_operations", "order_fulfillment"]
        )
        
        iot_service = ServiceInfo(
            service_id="iot_adapter_001",
            service_name="IoT Adapter",
            service_type=ServiceType.ADAPTER,
            endpoint="http://localhost:8003",
            version="1.0.0",
            capabilities=["equipment_monitoring", "sensor_data", "telemetry"]
        )
        
        # Register services
        await service_registry.register_service(erp_service)
        await service_registry.register_service(wms_service)
        await service_registry.register_service(iot_service)
        
        # Discover services
        all_services = await service_registry.discover_services()
        assert len(all_services) == 3, "Should discover all registered services"
        
        # Discover by type
        adapters = await service_registry.discover_services(ServiceType.ADAPTER)
        assert len(adapters) == 3, "Should discover all adapters"
        
        # Discover by capabilities
        inventory_services = await service_registry.discover_services(capabilities=["inventory"])
        assert len(inventory_services) >= 2, "Should discover services with inventory capability"
        
        # Check service health
        for service in all_services:
            health = await service_registry.get_service_health(service.service_id)
            assert health is not None, f"Should get health for service {service.service_id}"

    async def test_monitoring_integration(self, monitoring_service, mcp_server, mcp_client):
        """Test monitoring and metrics integration."""
        
        # Record some metrics - use metrics_collector.record_metric with MetricType
        from src.api.services.mcp.monitoring import MetricType
        await monitoring_service.metrics_collector.record_metric("tool_executions", 1.0, MetricType.GAUGE, {"tool_name": "get_inventory"})
        await monitoring_service.metrics_collector.record_metric("tool_execution_time", 0.5, MetricType.GAUGE, {"tool_name": "get_inventory"})
        await monitoring_service.metrics_collector.record_metric("active_connections", 1.0, MetricType.GAUGE, {"service": "mcp_server"})
        
        # Get metrics - use get_metrics_by_name
        metrics = await monitoring_service.metrics_collector.get_metrics_by_name("tool_executions")
        assert len(metrics) > 0, "Should record and retrieve metrics"
        
        # Get monitoring dashboard
        dashboard = await monitoring_service.get_monitoring_dashboard()
        assert dashboard is not None, "Should get monitoring dashboard"
        assert "system_health" in dashboard, "Dashboard should include system health"
        assert "active_services" in dashboard, "Dashboard should include active services"

    async def test_error_handling_and_recovery(self, mcp_server, mcp_client, discovery_service):
        """Test error handling and recovery mechanisms."""
        
        # Connect client
        await mcp_client.connect("http://localhost:8000", MCPConnectionType.HTTP)
        
        # Test invalid tool execution
        result = await mcp_client.execute_tool("nonexistent_tool", {})
        assert not result.success, "Should fail for nonexistent tool"
        assert result.error is not None, "Should return error message"
        
        # Test tool execution with invalid parameters
        result = await mcp_client.execute_tool("get_inventory", {"invalid_param": "value"})
        assert not result.success, "Should fail for invalid parameters"
        
        # Test connection recovery
        await mcp_client.disconnect()
        success = await mcp_client.connect("http://localhost:8000", MCPConnectionType.HTTP)
        assert success, "Should reconnect successfully"

    async def test_performance_under_load(self, mcp_server, mcp_client, discovery_service, erp_adapter):
        """Test system performance under load."""
        
        # Register adapter
        await discovery_service.register_discovery_source("erp_adapter", erp_adapter, "mcp_adapter")
        await asyncio.sleep(2)
        
        # Connect client
        await mcp_client.connect("http://localhost:8000", MCPConnectionType.HTTP)
        
        # Execute multiple tools concurrently
        tasks = []
        for i in range(100):
            task = mcp_client.execute_tool("get_inventory", {"item_id": f"ITEM{i:03d}"})
            tasks.append(task)
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Check results
        successful_results = [r for r in results if not isinstance(r, Exception) and r.success]
        assert len(successful_results) > 0, "Should have some successful executions"
        
        # Check performance metrics
        execution_times = [r.execution_time for r in successful_results if hasattr(r, 'execution_time')]
        if execution_times:
            avg_execution_time = sum(execution_times) / len(execution_times)
            assert avg_execution_time < 5.0, f"Average execution time should be reasonable: {avg_execution_time}s"

    async def test_data_consistency_across_services(self, mcp_server, mcp_client, discovery_service, 
                                                   erp_adapter, wms_adapter):
        """Test data consistency across different services."""
        
        # Register adapters
        await discovery_service.register_discovery_source("erp_adapter", erp_adapter, "mcp_adapter")
        await discovery_service.register_discovery_source("wms_adapter", wms_adapter, "mcp_adapter")
        await asyncio.sleep(2)
        
        # Connect client
        await mcp_client.connect("http://localhost:8000", MCPConnectionType.HTTP)
        
        # Get inventory from ERP
        erp_result = await mcp_client.execute_tool("get_inventory", {"item_id": "ITEM001"})
        assert erp_result.success, "ERP inventory lookup should succeed"
        
        # Get inventory from WMS
        wms_result = await mcp_client.execute_tool("get_inventory", {"item_id": "ITEM001"})
        assert wms_result.success, "WMS inventory lookup should succeed"
        
        # Compare results (in real scenario, they should be consistent)
        if erp_result.success and wms_result.success:
            # In a real test, you would compare the actual data
            # For now, we just verify both calls succeeded
            # Note: MCPClient.call_tool returns Any, not ExecutionResult
            # If result is ExecutionResult, use .result; otherwise check result directly
            if hasattr(erp_result, 'result'):
                assert erp_result.result is not None, "ERP result should have data"
            else:
                assert erp_result is not None, "ERP result should have data"
            if hasattr(wms_result, 'result'):
                assert wms_result.result is not None, "WMS result should have data"
            else:
                assert wms_result is not None, "WMS result should have data"

    async def test_security_and_authentication(self, mcp_server, mcp_client):
        """Test security and authentication mechanisms."""
        
        # Test unauthenticated access
        result = await mcp_client.execute_tool("get_inventory", {"item_id": "ITEM001"})
        # In a real implementation, this should fail without authentication
        # For now, we just test that the call completes
        
        # Test with authentication (mock)
        with patch('src.api.services.mcp.client.MCPClient._authenticate') as mock_auth:
            mock_auth.return_value = True
            await mcp_client.connect("http://localhost:8000", MCPConnectionType.HTTP)
            
            result = await mcp_client.execute_tool("get_inventory", {"item_id": "ITEM001"})
            # Should succeed with authentication
            assert result is not None

    async def test_configuration_management(self, mcp_server, mcp_client, discovery_service):
        """Test configuration management and hot reloading."""
        
        # Test configuration changes
        original_config = discovery_service.config
        new_config = ToolDiscoveryConfig(
            discovery_interval=5,
            max_tools_per_source=100
        )
        
        # Update configuration
        discovery_service.config = new_config
        assert discovery_service.config.discovery_interval == 5, "Configuration should be updated"
        
        # Test hot reloading (if implemented)
        # This would test the ability to reload configuration without restarting services

    async def test_backup_and_recovery(self, mcp_server, mcp_client, discovery_service, erp_adapter):
        """Test backup and recovery mechanisms."""
        
        # Register adapter and discover tools
        await discovery_service.register_discovery_source("erp_adapter", erp_adapter, "mcp_adapter")
        await asyncio.sleep(2)
        
        # Get initial state
        initial_tools = await discovery_service.search_tools("inventory")
        initial_count = len(initial_tools)
        
        # Simulate service restart
        await discovery_service.stop_discovery()
        await discovery_service.start_discovery()
        
        # Re-register adapter
        await discovery_service.register_discovery_source("erp_adapter", erp_adapter, "mcp_adapter")
        await asyncio.sleep(2)
        
        # Verify recovery
        recovered_tools = await discovery_service.search_tools("inventory")
        recovered_count = len(recovered_tools)
        
        # Should recover the same tools
        assert recovered_count >= initial_count, "Should recover tools after restart"

    async def test_multi_tenant_isolation(self, mcp_server, mcp_client, discovery_service):
        """Test multi-tenant isolation and security."""
        
        # Simulate multiple tenants
        tenant1_tools = await discovery_service.search_tools("inventory", tenant_id="tenant1")
        tenant2_tools = await discovery_service.search_tools("inventory", tenant_id="tenant2")
        
        # In a real implementation, tools should be isolated by tenant
        # For now, we just test that the calls complete
        
        # Test tenant-specific tool execution
        result1 = await mcp_client.execute_tool("get_inventory", {"item_id": "ITEM001", "tenant_id": "tenant1"})
        result2 = await mcp_client.execute_tool("get_inventory", {"item_id": "ITEM001", "tenant_id": "tenant2"})
        
        # Both should complete (isolation would be enforced in real implementation)
        assert result1 is not None
        assert result2 is not None

    async def test_scalability_and_load_balancing(self, mcp_server, mcp_client, discovery_service):
        """Test scalability and load balancing capabilities."""
        
        # Simulate multiple clients
        clients = []
        for i in range(10):
            client = MCPClient()
            await client.connect("http://localhost:8000", MCPConnectionType.HTTP)
            clients.append(client)
        
        # Execute tools from multiple clients
        tasks = []
        for i, client in enumerate(clients):
            task = client.execute_tool("get_inventory", {"item_id": f"ITEM{i:03d}"})
            tasks.append(task)
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Check that all clients can execute tools
        successful_results = [r for r in results if not isinstance(r, Exception)]
        assert len(successful_results) > 0, "Should handle multiple clients"
        
        # Cleanup
        for client in clients:
            await client.disconnect()

    async def test_observability_and_debugging(self, mcp_server, mcp_client, monitoring_service):
        """Test observability and debugging capabilities."""
        
        # Connect client
        await mcp_client.connect("http://localhost:8000", MCPConnectionType.HTTP)
        
        # Execute some tools
        await mcp_client.execute_tool("get_inventory", {"item_id": "ITEM001"})
        await mcp_client.execute_tool("get_inventory", {"item_id": "ITEM002"})
        
        # Check logs and metrics
        dashboard = await monitoring_service.get_monitoring_dashboard()
        assert "system_health" in dashboard, "Should have system health metrics"
        
        # Test debugging endpoints
        server_status = await mcp_server.get_server_status()
        assert "running" in server_status, "Should have server status"
        
        # Test health checks
        health = await mcp_client.get_server_status()
        assert health is not None, "Should have health status"


class TestMCPPerformance:
    """Performance tests for the MCP system."""

    @pytest.mark.performance
    async def test_tool_execution_performance(self, mcp_server, mcp_client):
        """Test tool execution performance under various loads."""
        
        await mcp_client.connect("http://localhost:8000", MCPConnectionType.HTTP)
        
        # Test single tool execution
        start_time = datetime.utcnow()
        result = await mcp_client.execute_tool("get_inventory", {"item_id": "ITEM001"})
        single_execution_time = (datetime.utcnow() - start_time).total_seconds()
        
        assert single_execution_time < 1.0, f"Single execution should be fast: {single_execution_time}s"
        
        # Test concurrent executions
        start_time = datetime.utcnow()
        tasks = [mcp_client.execute_tool("get_inventory", {"item_id": f"ITEM{i:03d}"}) for i in range(50)]
        results = await asyncio.gather(*tasks)
        concurrent_execution_time = (datetime.utcnow() - start_time).total_seconds()
        
        assert concurrent_execution_time < 10.0, f"Concurrent execution should be reasonable: {concurrent_execution_time}s"
        
        # Test throughput
        throughput = len(results) / concurrent_execution_time
        assert throughput > 5.0, f"Should achieve reasonable throughput: {throughput} ops/sec"

    @pytest.mark.performance
    async def test_memory_usage(self, mcp_server, mcp_client, discovery_service):
        """Test memory usage under load."""
        
        import psutil
        import os
        
        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        # Execute many tools
        tasks = []
        for i in range(1000):
            task = mcp_client.execute_tool("get_inventory", {"item_id": f"ITEM{i:03d}"})
            tasks.append(task)
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        final_memory = process.memory_info().rss / 1024 / 1024  # MB
        memory_increase = final_memory - initial_memory
        
        # Memory increase should be reasonable
        assert memory_increase < 100, f"Memory increase should be reasonable: {memory_increase}MB"

    @pytest.mark.performance
    async def test_concurrent_connections(self, mcp_server):
        """Test system behavior under concurrent connections."""
        
        # Create multiple clients
        clients = []
        for i in range(20):
            client = MCPClient()
            await client.connect("http://localhost:8000", MCPConnectionType.HTTP)
            clients.append(client)
        
        # Execute tools from all clients simultaneously
        tasks = []
        for i, client in enumerate(clients):
            task = client.execute_tool("get_inventory", {"item_id": f"ITEM{i:03d}"})
            tasks.append(task)
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Check that most executions succeeded
        successful_results = [r for r in results if not isinstance(r, Exception) and r.success]
        success_rate = len(successful_results) / len(results)
        
        assert success_rate > 0.8, f"Should maintain high success rate: {success_rate:.2%}"
        
        # Cleanup
        for client in clients:
            await client.disconnect()


class TestMCPReliability:
    """Reliability tests for the MCP system."""

    async def test_fault_tolerance(self, mcp_server, mcp_client):
        """Test system behavior under various failure conditions."""
        
        await mcp_client.connect("http://localhost:8000", MCPConnectionType.HTTP)
        
        # Test with invalid tool names
        result = await mcp_client.execute_tool("invalid_tool", {})
        assert not result.success, "Should handle invalid tool gracefully"
        
        # Test with malformed parameters
        result = await mcp_client.execute_tool("get_inventory", {"invalid_param": "value"})
        assert not result.success, "Should handle invalid parameters gracefully"
        
        # Test connection recovery
        await mcp_client.disconnect()
        success = await mcp_client.connect("http://localhost:8000", MCPConnectionType.HTTP)
        assert success, "Should recover from disconnection"

    async def test_data_integrity(self, mcp_server, mcp_client, discovery_service, erp_adapter):
        """Test data integrity across operations."""
        
        await discovery_service.register_discovery_source("erp_adapter", erp_adapter, "mcp_adapter")
        await asyncio.sleep(2)
        
        await mcp_client.connect("http://localhost:8000", MCPConnectionType.HTTP)
        
        # Execute same tool multiple times
        results = []
        for i in range(10):
            result = await mcp_client.execute_tool("get_inventory", {"item_id": "ITEM001"})
            results.append(result)
        
        # All results should be consistent
        successful_results = [r for r in results if r.success]
        assert len(successful_results) > 0, "Should have some successful results"
        
        # In a real implementation, you would compare the actual data
        # For now, we just verify the calls complete

    async def test_graceful_degradation(self, mcp_server, mcp_client, discovery_service):
        """Test graceful degradation when services are unavailable."""
        
        # Test with no adapters registered
        tools = await discovery_service.search_tools("inventory")
        assert len(tools) == 0, "Should handle no tools gracefully"
        
        # Test tool execution with no tools
        result = await mcp_client.execute_tool("get_inventory", {"item_id": "ITEM001"})
        # Should either fail gracefully or return empty result
        assert result is not None, "Should handle missing tools gracefully"


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
