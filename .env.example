# =============================================================================
# Warehouse Operational Assistant - Environment Configuration
# =============================================================================
# 
# Copy this file to .env and update with your actual values:
#   cp .env.example .env
#   nano .env  # or your preferred editor
#
# For Docker Compose deployments, place .env in deploy/compose/ directory
# =============================================================================

# =============================================================================
# ENVIRONMENT
# =============================================================================
# Set to 'production' for production deployments, 'development' for local dev
ENVIRONMENT=development

# =============================================================================
# DATABASE CONFIGURATION (PostgreSQL/TimescaleDB)
# =============================================================================
# Database connection settings
POSTGRES_USER=warehouse
# ⚠️ CHANGE IN PRODUCTION!
POSTGRES_PASSWORD=changeme
POSTGRES_DB=warehouse
DB_HOST=localhost
DB_PORT=5435

# Alternative database URL format (overrides individual settings above)
# DATABASE_URL=postgresql://warehouse:changeme@localhost:5435/warehouse

# =============================================================================
# SECURITY
# =============================================================================
# JWT Secret Key - REQUIRED for production, optional for development
# Generate a strong random key: openssl rand -hex 32
# Minimum 32 characters recommended
JWT_SECRET_KEY=your-strong-random-secret-minimum-32-characters-change-this-in-production

# Admin user default password (change in production!)
DEFAULT_ADMIN_PASSWORD=changeme

# =============================================================================
# REDIS CONFIGURATION
# =============================================================================
REDIS_HOST=localhost
REDIS_PORT=6379
# Leave empty for development
REDIS_PASSWORD=
REDIS_DB=0

# =============================================================================
# VECTOR DATABASE (Milvus)
# =============================================================================
MILVUS_HOST=localhost
MILVUS_PORT=19530
MILVUS_USER=root
MILVUS_PASSWORD=Milvus

# GPU Acceleration for Milvus
MILVUS_USE_GPU=true
MILVUS_GPU_DEVICE_ID=0
CUDA_VISIBLE_DEVICES=0
MILVUS_INDEX_TYPE=GPU_CAGRA
MILVUS_COLLECTION_NAME=warehouse_docs_gpu

# =============================================================================
# MESSAGE QUEUE (Kafka)
# =============================================================================
KAFKA_BOOTSTRAP_SERVERS=localhost:9092
# Alternative: KAFKA_BROKER=kafka:9092

# =============================================================================
# NVIDIA NIM LLM CONFIGURATION
# =============================================================================
# 
# IMPORTANT: API Key Configuration
# 
# The LLM service uses NVIDIA_API_KEY which can be:
#   1. A Brev API key (starts with "brev_api_") - for use with https://api.brev.dev/v1
#   2. An NVIDIA API key (starts with "nvapi-") - works with both endpoints
#
# For the 49B model (llama-3.3-nemotron-super-49b-v1):
#   - Endpoint: https://api.brev.dev/v1
#   - Can use either Brev API key OR NVIDIA API key
#   - If using Brev API key, you MUST set EMBEDDING_API_KEY separately (see below)
#
# For other NVIDIA NIM models:
#   - Endpoint: https://integrate.api.nvidia.com/v1
#   - Requires NVIDIA API key (starts with "nvapi-")
#
# For self-hosted NIM instances:
#   - Use your own endpoint URL (e.g., http://localhost:8000/v1 or https://your-nim-instance.com/v1)
#   - Use the API key provided by your NIM instance
#
# LLM Service API Key
# IMPORTANT: Choose the correct API key based on your endpoint:
# - If using Brev endpoint (api.brev.dev): Use Brev API key (brev_api_...)
#   * Brev API keys are specific to Brev and work with api.brev.dev
#   * Format: brev_api_xxxxxxxxxxxxxxxxxxxxxxxxxxxxx
#   * Get from: Your Brev account
# - If using NVIDIA endpoint (integrate.api.nvidia.com): Use NVIDIA API key (nvapi-...)
#   * NVIDIA API keys work with integrate.api.nvidia.com
#   * Format: nvapi-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
#   * Get from: https://build.nvidia.com/
# - Note: According to NVIDIA documentation, NVIDIA API keys may also work with api.brev.dev,
#   but Brev API keys are recommended for the Brev endpoint to ensure compatibility.
# - If using Brev API key for LLM, you MUST set EMBEDDING_API_KEY separately (see Embedding section)
NVIDIA_API_KEY=your-nvidia-api-key-here

# LLM Service Endpoint
# For 49B model: https://api.brev.dev/v1
# For other NIMs: https://integrate.api.nvidia.com/v1
# For self-hosted: http://your-nim-host:port/v1
LLM_NIM_URL=https://api.brev.dev/v1

# LLM Model Identifier
# Example for 49B model:
LLM_MODEL=nvcf:nvidia/llama-3.3-nemotron-super-49b-v1:dep-36ZiLbQIG2ZzK7gIIC5yh1E6lGk

# LLM Generation Parameters
LLM_TEMPERATURE=0.1
LLM_MAX_TOKENS=2000
LLM_TOP_P=1.0
LLM_FREQUENCY_PENALTY=0.0
LLM_PRESENCE_PENALTY=0.0
# Timeout in seconds
LLM_CLIENT_TIMEOUT=120

# LLM Caching
LLM_CACHE_ENABLED=true
# Cache TTL in seconds (5 minutes)
LLM_CACHE_TTL_SECONDS=300

# =============================================================================
# EMBEDDING SERVICE CONFIGURATION
# =============================================================================
# Embedding service endpoint (always uses NVIDIA endpoint)
EMBEDDING_NIM_URL=https://integrate.api.nvidia.com/v1

# Embedding API Key
# IMPORTANT: Embedding service REQUIRES an NVIDIA API key (starts with "nvapi-")
# 
# Configuration options:
#   1. If NVIDIA_API_KEY is an NVIDIA API key: Leave EMBEDDING_API_KEY unset (will use NVIDIA_API_KEY)
#   2. If NVIDIA_API_KEY is a Brev API key: MUST set EMBEDDING_API_KEY with an NVIDIA API key
#   3. To use a different NVIDIA API key for embeddings: Set EMBEDDING_API_KEY explicitly
#
# Format: nvapi-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
# Get your NVIDIA API key from: https://build.nvidia.com/
EMBEDDING_API_KEY=your-nvidia-api-key-here

# =============================================================================
# CORS CONFIGURATION
# =============================================================================
# Allowed origins for CORS (comma-separated)
# Add your frontend URLs here
CORS_ORIGINS=http://localhost:3001,http://localhost:3000,http://127.0.0.1:3001,http://127.0.0.1:3000

# =============================================================================
# UPLOAD & REQUEST LIMITS
# =============================================================================
# Maximum request size in bytes (default: 10MB)
MAX_REQUEST_SIZE=10485760

# Maximum upload size in bytes (default: 50MB)
MAX_UPLOAD_SIZE=52428800

# =============================================================================
# NeMo Guardrails Configuration
# =============================================================================
# NeMo Guardrails API endpoint
RAIL_API_URL=https://integrate.api.nvidia.com/v1

# NeMo Guardrails API Key
# Falls back to NVIDIA_API_KEY if not set (but NVIDIA_API_KEY must be an NVIDIA API key, not Brev)
# Format: nvapi-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
RAIL_API_KEY=your-nvidia-api-key-here

# =============================================================================
# Document Extraction Agent - NVIDIA NeMo API Keys
# =============================================================================
# All document processing NIMs use NVIDIA API keys (starts with "nvapi-")
# These can be the same as NVIDIA_API_KEY or EMBEDDING_API_KEY, or separate keys
# Format: nvapi-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
NEMO_RETRIEVER_API_KEY=your-nvidia-api-key-here
NEMO_OCR_API_KEY=your-nvidia-api-key-here
NEMO_PARSE_API_KEY=your-nvidia-api-key-here
LLAMA_NANO_VL_API_KEY=your-nvidia-api-key-here
LLAMA_70B_API_KEY=your-nvidia-api-key-here

# =============================================================================
# EXTERNAL SERVICE INTEGRATIONS
# =============================================================================
# WMS_API_KEY=your-wms-api-key
# ERP_API_KEY=your-erp-api-key

# =============================================================================
# NOTES FOR DEVELOPERS
# =============================================================================
#
# 1. API Key Configuration Summary:
#    - LLM Service (NVIDIA_API_KEY):
#      * Can use Brev API key (brev_api_...) if using api.brev.dev endpoint
#      * Can use NVIDIA API key (nvapi-...) for any endpoint
#      * If using Brev API key, you MUST set EMBEDDING_API_KEY separately
#    
#    - Embedding Service (EMBEDDING_API_KEY):
#      * REQUIRES NVIDIA API key (nvapi-...)
#      * Defaults to NVIDIA_API_KEY if not set
#      * MUST be set separately if NVIDIA_API_KEY is a Brev key
#    
#    - Document Processing & Guardrails:
#      * All require NVIDIA API keys (nvapi-...)
#      * Can use same key as EMBEDDING_API_KEY or separate keys
#
# 2. Getting API Keys:
#    - NVIDIA API Key: Sign up at https://build.nvidia.com/
#      * Works with both api.brev.dev and integrate.api.nvidia.com endpoints
#      * Format: nvapi-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
#    - Brev API Key: Get from your Brev account (if using Brev endpoint)
#      * Only works with api.brev.dev endpoint
#      * Format: brev_api_xxxxxxxxxxxxxxxxxxxxxxxxxxxxx
#
# 3. Security:
#    - NEVER commit .env files to version control
#    - Change all default passwords in production
#    - Use strong, unique JWT_SECRET_KEY in production
#    - JWT_SECRET_KEY is REQUIRED in production (app will fail to start without it)
#
# 4. Database:
#    - Default port 5435 is used to avoid conflicts with standard PostgreSQL (5432)
#    - Ensure Docker containers are running before starting the backend
#
# 5. Testing:
#    - View logs in real-time: ./scripts/view_logs.sh
#    - Restart backend: ./restart_backend.sh
#    - Check health: curl http://localhost:8001/api/v1/health
#
# =============================================================================
