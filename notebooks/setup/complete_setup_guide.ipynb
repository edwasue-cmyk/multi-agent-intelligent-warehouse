{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Setup Guide - Warehouse Operational Assistant\n",
    "\n",
    "This notebook provides a **complete, step-by-step setup guide** from cloning the repository to running the full application with backend and frontend.\n",
    "\n",
    "## Overview\n",
    "\n",
    "This guide will walk you through:\n",
    "1. \u2705 Prerequisites verification\n",
    "2. \ud83d\udce6 Repository setup\n",
    "3. \ud83d\udd27 Environment configuration\n",
    "4. \ud83d\udd11 NVIDIA API key setup\n",
    "5. \ud83d\uddc4\ufe0f Database setup and migrations\n",
    "6. \ud83d\ude80 Starting backend and frontend services\n",
    "7. \u2705 Verification and testing\n",
    "\n",
    "**Estimated Time:** 30-45 minutes\n",
    "\n",
    "**Requirements:**\n",
    "- Python 3.9+\n",
    "- Node.js 20.0.0+ (or minimum 18.17.0+)\n",
    "- Docker & Docker Compose (for infrastructure services)\n",
    "- Git\n",
    "- NVIDIA API key (free account at https://build.nvidia.com/)\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Prerequisites Check](#prerequisites-check)\n",
    "2. [Repository Setup](#repository-setup)\n",
    "3. [Environment Setup](#environment-setup)\n",
    "4. [API Key Configuration (NVIDIA & Brev)](#api-key-configuration-nvidia--brev)\n",
    "5. [Environment Variables Setup](#environment-variables-setup)\n",
    "6. [Infrastructure Services](#infrastructure-services)\n",
    "7. [Database Setup](#database-setup)\n",
    "8. [Create Default Users](#create-default-users)\n",
    "9. [Generate Demo Data](#generate-demo-data)\n",
    "10. [\ud83d\ude80 (Optional) Install RAPIDS GPU Acceleration](#optional-install-rapids-gpu-acceleration)\n",
    "11. [Start Backend Server](#start-backend-server)\n",
    "12. [Start Frontend](#start-frontend)\n",
    "13. [Verification](#verification)\n",
    "14. [Troubleshooting](#troubleshooting)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Prerequisites Check\n",
    "\n",
    "Let's verify that all required tools are installed and meet version requirements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "def check_command(command, min_version=None, version_flag='--version'):\n",
    "    \"\"\"Check if a command exists and optionally verify version.\"\"\"\n",
    "    if not shutil.which(command):\n",
    "        return False, None, f\"\u274c {command} is not installed\"\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [command, version_flag],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=5\n",
    "        )\n",
    "        version = result.stdout.strip() or result.stderr.strip()\n",
    "        return True, version, f\"\u2705 {command} found: {version}\"\n",
    "    except Exception as e:\n",
    "        return False, None, f\"\u26a0\ufe0f  {command} found but version check failed: {e}\"\n",
    "\n",
    "def check_python_version():\n",
    "    \"\"\"Check Python version.\"\"\"\n",
    "    version = sys.version_info\n",
    "    version_str = f\"{version.major}.{version.minor}.{version.micro}\"\n",
    "    \n",
    "    if version.major < 3 or (version.major == 3 and version.minor < 9):\n",
    "        return False, version_str, f\"\u274c Python {version_str} is too old. Required: Python 3.9+\"\n",
    "    return True, version_str, f\"\u2705 Python {version_str} meets requirements\"\n",
    "\n",
    "def check_node_version():\n",
    "    \"\"\"Check Node.js version.\"\"\"\n",
    "    exists, version, message = check_command('node')\n",
    "    if not exists:\n",
    "        return exists, None, message\n",
    "    \n",
    "    # Extract version number\n",
    "    try:\n",
    "        version_str = version.split()[1] if ' ' in version else version.replace('v', '')\n",
    "        parts = version_str.split('.')\n",
    "        major = int(parts[0])\n",
    "        minor = int(parts[1]) if len(parts) > 1 else 0\n",
    "        patch = int(parts[2]) if len(parts) > 2 else 0\n",
    "        \n",
    "        # Check minimum: 18.17.0, Recommended: 20.0.0+\n",
    "        if major < 18:\n",
    "            return False, version_str, f\"\u274c Node.js {version_str} is too old. Required: 18.17.0+ (Recommended: 20.0.0+)\"\n",
    "        elif major == 18 and (minor < 17 or (minor == 17 and patch < 0)):\n",
    "            return False, version_str, f\"\u274c Node.js {version_str} is too old. Required: 18.17.0+ (Recommended: 20.0.0+)\"\n",
    "        elif major == 18:\n",
    "            return True, version_str, f\"\u26a0\ufe0f  Node.js {version_str} meets minimum (18.17.0+). Recommended: 20.0.0+\"\n",
    "        else:\n",
    "            return True, version_str, f\"\u2705 Node.js {version_str} meets requirements (Recommended: 20.0.0+)\"\n",
    "    except:\n",
    "        return True, version, f\"\u2705 Node.js found: {version}\"\n",
    "\n",
    "print(\"\ud83d\udd0d Checking Prerequisites...\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check Python\n",
    "ok, version, msg = check_python_version()\n",
    "print(msg)\n",
    "\n",
    "# Check Node.js\n",
    "ok, version, msg = check_node_version()\n",
    "print(msg)\n",
    "\n",
    "# Check npm\n",
    "ok, version, msg = check_command('npm')\n",
    "print(msg)\n",
    "\n",
    "# Check Git\n",
    "ok, version, msg = check_command('git')\n",
    "print(msg)\n",
    "\n",
    "# Check Docker\n",
    "ok, version, msg = check_command('docker')\n",
    "print(msg)\n",
    "\n",
    "# Check Docker Compose\n",
    "ok, version, msg = check_command('docker-compose')\n",
    "if not ok:\n",
    "    ok, version, msg = check_command('docker', version_flag='compose version')\n",
    "print(msg)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"\\n\u2705 Prerequisites check complete!\")\n",
    "print(\"\\n\ud83d\udcdd If any checks failed, please install the missing tools before proceeding.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Repository Setup\n",
    "\n",
    "If you haven't cloned the repository yet, follow the instructions below. If you're already in the repository, you can skip this step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Detect project root: navigate from current directory to find project root\n",
    "# This handles cases where notebook is opened from notebooks/setup/ or project root\n",
    "def find_project_root():\n",
    "    \"\"\"Find the project root directory.\"\"\"\n",
    "    current = Path.cwd()\n",
    "    \n",
    "    # Check if we're already in project root\n",
    "    if (current / \"src\" / \"api\").exists() and (current / \"scripts\" / \"setup\").exists():\n",
    "        return current\n",
    "    \n",
    "    # Check if we're in notebooks/setup/ (go up 2 levels)\n",
    "    if (current / \"complete_setup_guide.ipynb\").exists() or current.name == \"setup\":\n",
    "        parent = current.parent.parent\n",
    "        if (parent / \"src\" / \"api\").exists() and (parent / \"scripts\" / \"setup\").exists():\n",
    "            return parent\n",
    "    \n",
    "    # Check if we're in notebooks/ (go up 1 level)\n",
    "    if current.name == \"notebooks\":\n",
    "        parent = current.parent\n",
    "        if (parent / \"src\" / \"api\").exists() and (parent / \"scripts\" / \"setup\").exists():\n",
    "            return parent\n",
    "    \n",
    "    # Try going up from current directory\n",
    "    for parent in current.parents:\n",
    "        if (parent / \"src\" / \"api\").exists() and (parent / \"scripts\" / \"setup\").exists():\n",
    "            return parent\n",
    "    \n",
    "    # Fallback: return current directory\n",
    "    return current\n",
    "\n",
    "# Find and change to project root\n",
    "project_root = find_project_root()\n",
    "is_in_repo = (project_root / \"src\" / \"api\").exists() and (project_root / \"scripts\" / \"setup\").exists()\n",
    "\n",
    "if is_in_repo:\n",
    "    # Change to project root so all subsequent operations work correctly\n",
    "    os.chdir(project_root)\n",
    "    print(\"\u2705 You're already in the Warehouse Operational Assistant repository!\")\n",
    "    print(f\"   Project root: {project_root}\")\n",
    "    print(f\"   Changed working directory to: {Path.cwd()}\")\n",
    "    print(\"\\n\ud83d\udcdd You can skip the cloning step and proceed to environment setup.\")\n",
    "else:\n",
    "    print(\"\ud83d\udce6 Repository Setup Instructions\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\nTo clone the repository, run the following command in your terminal:\")\n",
    "    print(\"\\n```bash\")\n",
    "    print(\"git clone https://github.com/NVIDIA-AI-Blueprints/Multi-Agent-Intelligent-Warehouse.git\")\n",
    "    print(\"cd Multi-Agent-Intelligent-Warehouse\")\n",
    "    print(\"```\")\n",
    "    print(\"\\n\u26a0\ufe0f  After cloning, restart this notebook from the project root directory.\")\n",
    "    print(\"\\nAlternatively, if you want to clone it now, uncomment and run the cell below:\")\n",
    "    \n",
    "print(f\"\\n\ud83d\udcc1 Current directory: {Path.cwd()}\")\n",
    "print(f\"\ud83d\udcc1 Project root: {project_root}\")\n",
    "print(f\"\ud83d\udcc1 Expected structure: {project_root / 'src' / 'api'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the lines below to clone the repository automatically\n",
    "# WARNING: This will clone to the current directory\n",
    "\n",
    "# import subprocess\n",
    "# \n",
    "# repo_url = \"https://github.com/NVIDIA-AI-Blueprints/Multi-Agent-Intelligent-Warehouse.git\"\n",
    "# repo_name = \"Multi-Agent-Intelligent-Warehouse\"\n",
    "# \n",
    "# if not Path(repo_name).exists():\n",
    "#     print(f\"\ud83d\udce6 Cloning repository from {repo_url}...\")\n",
    "#     subprocess.run([\"git\", \"clone\", repo_url], check=True)\n",
    "#     print(f\"\u2705 Repository cloned to {Path.cwd() / repo_name}\")\n",
    "#     print(f\"\\n\u26a0\ufe0f  Please change directory and restart this notebook:\")\n",
    "#     print(f\"   cd {repo_name}\")\n",
    "#     print(f\"   jupyter notebook notebooks/setup/complete_setup_guide.ipynb\")\n",
    "# else:\n",
    "#     print(f\"\u2705 Repository already exists at {Path.cwd() / repo_name}\")\n",
    "\n",
    "print(\"\ud83d\udca1 To clone manually, use the command shown in the previous cell.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Environment Setup\n",
    "\n",
    "This step will:\n",
    "- Create a Python virtual environment\n",
    "- Install all Python dependencies\n",
    "- Verify the installation\n",
    "\n",
    "### \u26a0\ufe0f Important: Virtual Environment and Jupyter Kernel\n",
    "\n",
    "**Best Practice:** For the smoothest experience, create the virtual environment **before** starting Jupyter:\n",
    "\n",
    "```bash\n",
    "# Option 1: Create venv first, then start Jupyter (RECOMMENDED)\n",
    "python3 -m venv env\n",
    "source env/bin/activate  # or env\\Scripts\\activate on Windows\n",
    "pip install jupyter ipykernel\n",
    "python -m ipykernel install --user --name=warehouse-assistant\n",
    "jupyter notebook notebooks/setup/complete_setup_guide.ipynb\n",
    "# Then select \"warehouse-assistant\" as the kernel\n",
    "```\n",
    "\n",
    "**Alternative:** You can create the venv inside this notebook (see below), but you'll need to:\n",
    "1. Create the venv (this cell)\n",
    "2. Install ipykernel in the new venv\n",
    "3. Restart the kernel and switch to the new venv kernel\n",
    "4. Continue with the rest of the setup\n",
    "\n",
    "**Note:** The next cell will show which Python/kernel you're currently using.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def run_command(cmd, check=True, shell=False):\n",
    "    \"\"\"Run a shell command and return the result.\"\"\"\n",
    "    if isinstance(cmd, str) and not shell:\n",
    "        cmd = cmd.split()\n",
    "    \n",
    "    result = subprocess.run(\n",
    "        cmd,\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        shell=shell,\n",
    "        check=check\n",
    "    )\n",
    "    return result.returncode == 0, result.stdout, result.stderr\n",
    "\n",
    "# Show current kernel info\n",
    "print(\"\ud83d\udd0d Current Jupyter Kernel Information\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Working directory: {Path.cwd()}\")\n",
    "\n",
    "# Check if we're already in a virtual environment\n",
    "in_venv = hasattr(sys, 'real_prefix') or (hasattr(sys, 'base_prefix') and sys.base_prefix != sys.prefix)\n",
    "if in_venv:\n",
    "    print(f\"\u2705 Already running in a virtual environment: {sys.prefix}\")\n",
    "    if 'env' in str(sys.prefix) or 'venv' in str(sys.prefix):\n",
    "        print(\"   This appears to be the project's virtual environment!\")\n",
    "        use_existing = True\n",
    "    else:\n",
    "        print(\"   \u26a0\ufe0f  This is a different virtual environment\")\n",
    "        use_existing = False\n",
    "else:\n",
    "    print(\"\u26a0\ufe0f  Not running in a virtual environment (using system Python)\")\n",
    "    use_existing = False\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# Check if virtual environment exists\n",
    "env_path = Path(\"env\")\n",
    "if env_path.exists():\n",
    "    print(\"\u2705 Virtual environment directory 'env' already exists!\")\n",
    "    \n",
    "    if use_existing:\n",
    "        print(\"\u2705 You're already using the project's virtual environment - perfect!\")\n",
    "        print(\"   You can skip the venv creation step and proceed.\")\n",
    "        skip_setup = True\n",
    "    else:\n",
    "        print(\"\\n\ud83d\udca1 Options:\")\n",
    "        print(\"   1. Switch to the existing venv kernel (recommended)\")\n",
    "        print(\"   2. Recreate the virtual environment\")\n",
    "        print(\"   3. Continue with current kernel (not recommended)\")\n",
    "        \n",
    "        choice = input(\"\\n\u2753 What would you like to do? (1/2/3): \").strip()\n",
    "        \n",
    "        if choice == '1':\n",
    "            print(\"\\n\ud83d\udcdd To switch kernels:\")\n",
    "            print(\"   1. Go to: Kernel \u2192 Change Kernel \u2192 warehouse-assistant\")\n",
    "            print(\"   2. Or install kernel now:\")\n",
    "            if sys.platform == \"win32\":\n",
    "                python_path = Path(\"env\") / \"Scripts\" / \"python.exe\"\n",
    "            else:\n",
    "                python_path = Path(\"env\") / \"bin\" / \"python\"\n",
    "            \n",
    "            if python_path.exists():\n",
    "                print(f\"   {python_path} -m ipykernel install --user --name=warehouse-assistant\")\n",
    "                install_kernel = input(\"\\n\u2753 Install kernel now? (y/N): \").strip().lower()\n",
    "                if install_kernel == 'y':\n",
    "                    success, _, _ = run_command([str(python_path), \"-m\", \"ipykernel\", \"install\", \"--user\", \"--name=warehouse-assistant\"])\n",
    "                    if success:\n",
    "                        print(\"\u2705 Kernel installed! Please restart kernel and select 'warehouse-assistant'\")\n",
    "                    else:\n",
    "                        print(\"\u274c Failed to install kernel\")\n",
    "            skip_setup = True\n",
    "        elif choice == '2':\n",
    "            import shutil\n",
    "            print(\"\ud83d\uddd1\ufe0f  Removing existing virtual environment...\")\n",
    "            shutil.rmtree(env_path)\n",
    "            print(\"\u2705 Removed\")\n",
    "            skip_setup = False\n",
    "        else:\n",
    "            print(\"\u26a0\ufe0f  Continuing with current kernel (may cause issues)\")\n",
    "            skip_setup = True\n",
    "else:\n",
    "    skip_setup = False\n",
    "\n",
    "if not skip_setup:\n",
    "    print(\"\\n\ud83d\udd27 Setting up Python virtual environment...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create virtual environment\n",
    "    print(\"\\n1\ufe0f\u20e3 Creating virtual environment...\")\n",
    "    success, stdout, stderr = run_command([sys.executable, \"-m\", \"venv\", \"env\"])\n",
    "    if success:\n",
    "        print(\"\u2705 Virtual environment created\")\n",
    "    else:\n",
    "        print(f\"\u274c Failed to create virtual environment: {stderr}\")\n",
    "        raise RuntimeError(\"Virtual environment creation failed\")\n",
    "    \n",
    "    # Determine activation script path\n",
    "    if sys.platform == \"win32\":\n",
    "        activate_script = Path(\"env\") / \"Scripts\" / \"activate\"\n",
    "        pip_path = Path(\"env\") / \"Scripts\" / \"pip\"\n",
    "        python_path = Path(\"env\") / \"Scripts\" / \"python\"\n",
    "    else:\n",
    "        activate_script = Path(\"env\") / \"bin\" / \"activate\"\n",
    "        pip_path = Path(\"env\") / \"bin\" / \"pip\"\n",
    "        python_path = Path(\"env\") / \"bin\" / \"python\"\n",
    "    \n",
    "    # Upgrade pip\n",
    "    print(\"\\n2\ufe0f\u20e3 Upgrading pip...\")\n",
    "    success, stdout, stderr = run_command([str(pip_path), \"install\", \"--upgrade\", \"pip\", \"setuptools\", \"wheel\"])\n",
    "    if success:\n",
    "        print(\"\u2705 pip upgraded\")\n",
    "    else:\n",
    "        print(f\"\u26a0\ufe0f  pip upgrade had issues: {stderr}\")\n",
    "    \n",
    "    # Install jupyter and ipykernel in the new venv\n",
    "    print(\"\\n3\ufe0f\u20e3 Installing Jupyter and ipykernel in new environment...\")\n",
    "    success, stdout, stderr = run_command([str(pip_path), \"install\", \"jupyter\", \"ipykernel\"])\n",
    "    if success:\n",
    "        print(\"\u2705 Jupyter and ipykernel installed\")\n",
    "        \n",
    "        # Register the kernel\n",
    "        print(\"\\n4\ufe0f\u20e3 Registering kernel...\")\n",
    "        success, stdout, stderr = run_command([str(python_path), \"-m\", \"ipykernel\", \"install\", \"--user\", \"--name=warehouse-assistant\"])\n",
    "        if success:\n",
    "            print(\"\u2705 Kernel 'warehouse-assistant' registered!\")\n",
    "            print(\"\\n\u26a0\ufe0f  IMPORTANT: Please restart the kernel and select 'warehouse-assistant'\")\n",
    "            print(\"   Go to: Kernel \u2192 Restart Kernel \u2192 Change Kernel \u2192 warehouse-assistant\")\n",
    "        else:\n",
    "            print(f\"\u26a0\ufe0f  Could not register kernel: {stderr}\")\n",
    "            print(\"   You can do this manually later\")\n",
    "    else:\n",
    "        print(f\"\u26a0\ufe0f  Could not install Jupyter: {stderr}\")\n",
    "    \n",
    "    # Install requirements\n",
    "    print(\"\\n5\ufe0f\u20e3 Installing Python dependencies...\")\n",
    "    print(\"   This may take a few minutes...\")\n",
    "    success, stdout, stderr = run_command([str(pip_path), \"install\", \"-r\", \"requirements.txt\"])\n",
    "    if success:\n",
    "        print(\"\u2705 Dependencies installed successfully\")\n",
    "    else:\n",
    "        print(f\"\u274c Failed to install dependencies: {stderr}\")\n",
    "        print(\"\\n\ud83d\udca1 Try running manually:\")\n",
    "        print(f\"   source env/bin/activate  # or env\\\\Scripts\\\\activate on Windows\")\n",
    "        print(\"   pip install -r requirements.txt\")\n",
    "        raise RuntimeError(\"Dependency installation failed\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"\u26a0\ufe0f  IMPORTANT NEXT STEP:\")\n",
    "    print(\"   1. Go to: Kernel \u2192 Restart Kernel\")\n",
    "    print(\"   2. Then: Kernel \u2192 Change Kernel \u2192 warehouse-assistant\")\n",
    "    print(\"   3. Re-run this cell to verify you're in the correct environment\")\n",
    "    print(\"   4. Continue with the rest of the notebook\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"\u2705 Environment setup complete!\")\n",
    "    print(\"\\n\ud83d\udcdd Next: Configure environment variables and API keys\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: API Key Configuration (NVIDIA & Brev)\n",
    "\n",
    "The Warehouse Operational Assistant uses NVIDIA NIMs (NVIDIA Inference Microservices) for AI capabilities. You have **two deployment options** for NIMs:\n",
    "\n",
    "### \ud83d\ude80 NIM Deployment Options\n",
    "\n",
    "**Option 1: Cloud Endpoints** (Easiest - Default)\n",
    "- Use NVIDIA's cloud-hosted NIM services\n",
    "- **No installation required** - just configure API keys\n",
    "- Quick setup, perfect for development and testing\n",
    "- Endpoints: `api.brev.dev` or `integrate.api.nvidia.com`\n",
    "\n",
    "**Option 2: Self-Hosted NIMs** (Recommended for Production)\n",
    "- **Install NIMs on your own infrastructure** using Docker\n",
    "- **Create custom endpoints** on your servers\n",
    "- Benefits:\n",
    "  - \ud83d\udd12 **Data Privacy**: Keep sensitive data on-premises\n",
    "  - \ud83d\udcb0 **Cost Control**: Avoid per-request cloud costs\n",
    "  - \u2699\ufe0f **Custom Requirements**: Full control over infrastructure\n",
    "  - \u26a1 **Low Latency**: Reduced network latency\n",
    "\n",
    "**Self-Hosting Example:**\n",
    "```bash\n",
    "# Deploy LLM NIM on your server\n",
    "docker run --gpus all -p 8000:8000 \\\n",
    "  nvcr.io/nvidia/nim/llama-3.3-nemotron-super-49b:latest\n",
    "\n",
    "# Then set in .env:\n",
    "LLM_NIM_URL=http://your-server:8000/v1\n",
    "```\n",
    "\n",
    "**\ud83d\udcdd Note**: This step configures API keys for cloud endpoints. If you're self-hosting NIMs, you can skip API keys (unless your NIMs require authentication) and just configure the endpoint URLs in Step 5.\n",
    "\n",
    "---\n",
    "\n",
    "### \u26a0\ufe0f Important: Two Types of API Keys (for Cloud Endpoints)\n",
    "\n",
    "**1. NVIDIA API Key** (starts with `nvapi-`)\n",
    "- **Format**: `nvapi-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx`\n",
    "- **Get from**: https://build.nvidia.com/\n",
    "- **Works with**: Both `api.brev.dev` and `integrate.api.nvidia.com` endpoints\n",
    "- **Required for**: Embedding service (always requires NVIDIA API key)\n",
    "\n",
    "**2. Brev API Key** (starts with `brev_api_`)\n",
    "- **Format**: `brev_api_xxxxxxxxxxxxxxxxxxxxxxxxxxxxx`\n",
    "- **Get from**: Your Brev account\n",
    "- **Works with**: `api.brev.dev` endpoint only\n",
    "- **Optional**: Can use NVIDIA API key instead\n",
    "\n",
    "### Configuration Options (Cloud Endpoints)\n",
    "\n",
    "**Option A: Use NVIDIA API Key for Everything** (Recommended)\n",
    "- Set `NVIDIA_API_KEY` with your NVIDIA API key\n",
    "- Leave `EMBEDDING_API_KEY` unset (will use `NVIDIA_API_KEY`)\n",
    "- Works with both endpoints\n",
    "\n",
    "**Option B: Use Brev API Key for LLM + NVIDIA API Key for Embedding**\n",
    "- Set `NVIDIA_API_KEY` with your Brev API key\n",
    "- **MUST** set `EMBEDDING_API_KEY` with your NVIDIA API key (required!)\n",
    "- Embedding service always requires NVIDIA API key\n",
    "\n",
    "### Getting Your API Keys (for Cloud Endpoints)\n",
    "\n",
    "**NVIDIA API Key:**\n",
    "1. **Visit**: https://build.nvidia.com/\n",
    "2. **Sign up** or log in to your NVIDIA account\n",
    "3. **Navigate** to the \"API Keys\" section\n",
    "4. **Create** a new API key\n",
    "5. **Copy** the API key (starts with `nvapi-`)\n",
    "\n",
    "**Brev API Key (Optional):**\n",
    "1. **Visit**: Your Brev account dashboard\n",
    "2. **Navigate** to API Keys section\n",
    "3. **Create** or copy your Brev API key (starts with `brev_api_`)\n",
    "\n",
    "### What You'll Get Access To\n",
    "\n",
    "- **LLM Service** (Llama 3.3 Nemotron Super 49B) - for chat and reasoning\n",
    "- **Embedding Service** (llama-3_2-nv-embedqa-1b-v2) - for semantic search\n",
    "- **Document Processing** - OCR and structured data extraction\n",
    "- **Content Safety** - NeMo Guardrails for content moderation\n",
    "\n",
    "**\ud83d\udca1 For Self-Hosted NIMs**: See `DEPLOYMENT.md` section \"NVIDIA NIMs Deployment & Configuration\" for detailed self-hosting instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "def setup_api_keys():\n",
    "    \"\"\"Interactive setup for API keys (NVIDIA and/or Brev).\"\"\"\n",
    "    print(\"\ud83d\udd11 API Key Configuration\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Check if .env.example exists\n",
    "    env_example = Path(\".env.example\")\n",
    "    if not env_example.exists():\n",
    "        print(\"\u274c .env.example not found!\")\n",
    "        print(\"   Please ensure you're in the project root directory.\")\n",
    "        return False\n",
    "    \n",
    "    # Check if .env already exists\n",
    "    env_file = Path(\".env\")\n",
    "    if env_file.exists():\n",
    "        print(\"\u2705 .env file already exists\")\n",
    "        overwrite = input(\"\\n\u2753 Update API keys in existing .env? (y/N): \").strip().lower()\n",
    "        if overwrite != 'y':\n",
    "            print(\"\ud83d\udcdd Skipping API key setup. Using existing .env file.\")\n",
    "            return True\n",
    "    else:\n",
    "        print(\"\ud83d\udcdd Creating .env file from .env.example...\")\n",
    "        import shutil\n",
    "        shutil.copy(env_example, env_file)\n",
    "        print(\"\u2705 .env file created\")\n",
    "    \n",
    "    # Ask about deployment option\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"\ud83d\ude80 NIM Deployment Options:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\n1. Cloud Endpoints (Default - Easiest)\")\n",
    "    print(\"   \u2022 Use NVIDIA's cloud-hosted NIM services\")\n",
    "    print(\"   \u2022 No installation required\")\n",
    "    print(\"   \u2022 Requires API keys (configured below)\")\n",
    "    print(\"\\n2. Self-Hosted NIMs (Advanced)\")\n",
    "    print(\"   \u2022 Install NIMs on your own infrastructure\")\n",
    "    print(\"   \u2022 Create custom endpoints\")\n",
    "    print(\"   \u2022 Better for production, data privacy, cost control\")\n",
    "    print(\"   \u2022 See DEPLOYMENT.md for self-hosting instructions\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    deployment_choice = input(\"\\n\u2753 Using cloud endpoints or self-hosted NIMs? (1=Cloud, 2=Self-hosted, default: 1): \").strip() or \"1\"\n",
    "    \n",
    "    if deployment_choice == \"2\":\n",
    "        print(\"\\n\u2705 Self-hosted NIMs selected\")\n",
    "        print(\"   \u2022 You can skip API key configuration if your NIMs don't require authentication\")\n",
    "        print(\"   \u2022 Configure endpoint URLs in Step 5 (Environment Variables Setup)\")\n",
    "        print(\"   \u2022 Example: LLM_NIM_URL=http://your-server:8000/v1\")\n",
    "        skip_keys = input(\"\\n\u2753 Skip API key configuration? (y/N): \").strip().lower()\n",
    "        if skip_keys == 'y':\n",
    "            print(\"\ud83d\udcdd Skipping API key setup. Configure endpoints in Step 5.\")\n",
    "            return True\n",
    "    \n",
    "    # Get API key configuration choice (for cloud endpoints)\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"\ud83d\udccb API Key Configuration Options (for Cloud Endpoints):\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\nOption 1: Use NVIDIA API Key for Everything (Recommended)\")\n",
    "    print(\"  \u2022 Set NVIDIA_API_KEY with NVIDIA API key (nvapi-...)\")\n",
    "    print(\"  \u2022 Leave EMBEDDING_API_KEY unset\")\n",
    "    print(\"  \u2022 Works with both endpoints\")\n",
    "    print(\"\\nOption 2: Use Brev API Key for LLM + NVIDIA API Key for Embedding\")\n",
    "    print(\"  \u2022 Set NVIDIA_API_KEY with Brev API key (brev_api_...)\")\n",
    "    print(\"  \u2022 MUST set EMBEDDING_API_KEY with NVIDIA API key (nvapi-...)\")\n",
    "    print(\"  \u2022 Embedding service always requires NVIDIA API key\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    choice = input(\"\\n\u2753 Which option? (1 or 2, default: 1): \").strip() or \"1\"\n",
    "    \n",
    "    # Get NVIDIA_API_KEY\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    if choice == \"1\":\n",
    "        print(\"\ud83d\udccb Getting NVIDIA API Key:\")\n",
    "        print(\"1. Visit: https://build.nvidia.com/\")\n",
    "        print(\"2. Sign up or log in\")\n",
    "        print(\"3. Go to 'API Keys' section\")\n",
    "        print(\"4. Create a new API key (starts with 'nvapi-')\")\n",
    "        print(\"5. Copy the API key\")\n",
    "        print(\"=\" * 60)\n",
    "        api_key = getpass.getpass(\"\\n\ud83d\udd11 Enter your NVIDIA API key (nvapi-...): \").strip()\n",
    "        embedding_key = None  # Will use NVIDIA_API_KEY\n",
    "    else:\n",
    "        print(\"\ud83d\udccb Getting Brev API Key for LLM:\")\n",
    "        print(\"1. Visit: Your Brev account dashboard\")\n",
    "        print(\"2. Navigate to API Keys section\")\n",
    "        print(\"3. Create or copy your Brev API key (starts with 'brev_api_')\")\n",
    "        print(\"=\" * 60)\n",
    "        api_key = getpass.getpass(\"\\n\ud83d\udd11 Enter your Brev API key (brev_api_...): \").strip()\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"\ud83d\udccb Getting NVIDIA API Key for Embedding (REQUIRED):\")\n",
    "        print(\"1. Visit: https://build.nvidia.com/\")\n",
    "        print(\"2. Sign up or log in\")\n",
    "        print(\"3. Go to 'API Keys' section\")\n",
    "        print(\"4. Create a new API key (starts with 'nvapi-')\")\n",
    "        print(\"5. Copy the API key\")\n",
    "        print(\"=\" * 60)\n",
    "        print(\"\u26a0\ufe0f  IMPORTANT: Embedding service REQUIRES NVIDIA API key!\")\n",
    "        embedding_key = getpass.getpass(\"\\n\ud83d\udd11 Enter your NVIDIA API key for Embedding (nvapi-...): \").strip()\n",
    "    \n",
    "    if not api_key:\n",
    "        print(\"\u274c No API key provided. Skipping API key setup.\")\n",
    "        print(\"   You can set it later in the .env file or environment variables.\")\n",
    "        return False\n",
    "    \n",
    "    if api_key.lower() in [\"your_nvidia_api_key_here\", \"your-api-key-here\", \"\"]:\n",
    "        print(\"\u274c Please enter your actual API key, not the placeholder.\")\n",
    "        return False\n",
    "    \n",
    "    # Validate key formats\n",
    "    if choice == \"1\" and not api_key.startswith(\"nvapi-\"):\n",
    "        print(\"\u26a0\ufe0f  Warning: NVIDIA API key should start with 'nvapi-'\")\n",
    "        confirm = input(\"   Continue anyway? (y/N): \").strip().lower()\n",
    "        if confirm != 'y':\n",
    "            return False\n",
    "    elif choice == \"2\":\n",
    "        if not api_key.startswith(\"brev_api_\"):\n",
    "            print(\"\u26a0\ufe0f  Warning: Brev API key should start with 'brev_api_'\")\n",
    "            confirm = input(\"   Continue anyway? (y/N): \").strip().lower()\n",
    "            if confirm != 'y':\n",
    "                return False\n",
    "        if not embedding_key or not embedding_key.startswith(\"nvapi-\"):\n",
    "            print(\"\u274c Embedding service REQUIRES NVIDIA API key (must start with 'nvapi-')\")\n",
    "            return False\n",
    "    \n",
    "    # Update .env file\n",
    "    try:\n",
    "        with open(env_file, 'r') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # Replace NVIDIA_API_KEY\n",
    "        content = re.sub(\n",
    "            r'^NVIDIA_API_KEY=.*$',\n",
    "            f'NVIDIA_API_KEY={api_key}',\n",
    "            content,\n",
    "            flags=re.MULTILINE\n",
    "        )\n",
    "        \n",
    "        # Update EMBEDDING_API_KEY if provided\n",
    "        if embedding_key:\n",
    "            content = re.sub(\n",
    "                r'^EMBEDDING_API_KEY=.*$',\n",
    "                f'EMBEDDING_API_KEY={embedding_key}',\n",
    "                content,\n",
    "                flags=re.MULTILINE\n",
    "            )\n",
    "        else:\n",
    "            # Remove EMBEDDING_API_KEY line if using Option 1 (will use NVIDIA_API_KEY)\n",
    "            content = re.sub(r'^EMBEDDING_API_KEY=.*$\\n?', '', content, flags=re.MULTILINE)\n",
    "        \n",
    "        # Also update RAIL_API_KEY if it's a placeholder\n",
    "        if 'RAIL_API_KEY=your_nvidia_api_key_here' in content or 'RAIL_API_KEY=' not in content:\n",
    "            # Use NVIDIA API key for RAIL (always needs NVIDIA key)\n",
    "            rail_key = embedding_key if embedding_key else api_key if api_key.startswith(\"nvapi-\") else \"\"\n",
    "            if rail_key:\n",
    "                content = re.sub(\n",
    "                    r'^RAIL_API_KEY=.*$',\n",
    "                    f'RAIL_API_KEY={rail_key}',\n",
    "                    content,\n",
    "                    flags=re.MULTILINE\n",
    "                )\n",
    "        \n",
    "        with open(env_file, 'w') as f:\n",
    "            f.write(content)\n",
    "        \n",
    "        print(\"\\n\u2705 API keys configured in .env file\")\n",
    "        if choice == \"1\":\n",
    "            print(\"   \u2022 NVIDIA_API_KEY: Set (will be used for all services)\")\n",
    "        else:\n",
    "            print(\"   \u2022 NVIDIA_API_KEY: Set (Brev API key for LLM)\")\n",
    "            print(\"   \u2022 EMBEDDING_API_KEY: Set (NVIDIA API key for Embedding)\")\n",
    "        print(\"\\n\ud83d\udca1 The API keys are stored in .env file (not committed to git)\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\u274c Error updating .env file: {e}\")\n",
    "        return False\n",
    "\n",
    "# Run the setup\n",
    "setup_api_keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Environment Variables Setup\n",
    "\n",
    "Now let's verify and configure other important environment variables. The `.env` file should already be created from the previous step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import re\n",
    "\n",
    "def check_env_file():\n",
    "    \"\"\"Check and display environment variable configuration.\"\"\"\n",
    "    env_file = Path(\".env\")\n",
    "    env_example = Path(\".env.example\")\n",
    "    \n",
    "    if not env_file.exists():\n",
    "        if env_example.exists():\n",
    "            print(\"\ud83d\udcdd Creating .env file from .env.example...\")\n",
    "            import shutil\n",
    "            shutil.copy(env_example, env_file)\n",
    "            print(\"\u2705 .env file created\")\n",
    "        else:\n",
    "            print(\"\u274c Neither .env nor .env.example found!\")\n",
    "            return False\n",
    "    \n",
    "    # Load and display key variables\n",
    "    print(\"\ud83d\udccb Environment Variables Configuration\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    with open(env_file, 'r') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Extract key variables\n",
    "    key_vars = {\n",
    "        'NVIDIA_API_KEY': 'NVIDIA API Key (for NIM services)',\n",
    "        'LLM_NIM_URL': 'LLM NIM Endpoint',\n",
    "        'EMBEDDING_NIM_URL': 'Embedding NIM Endpoint',\n",
    "        'POSTGRES_PASSWORD': 'Database Password',\n",
    "        'JWT_SECRET_KEY': 'JWT Secret Key (for authentication)',\n",
    "        'DEFAULT_ADMIN_PASSWORD': 'Default Admin Password',\n",
    "        'DB_HOST': 'Database Host',\n",
    "        'DB_PORT': 'Database Port',\n",
    "    }\n",
    "    \n",
    "    print(\"\\n\ud83d\udd0d Current Configuration:\\n\")\n",
    "    for var, description in key_vars.items():\n",
    "        match = re.search(rf'^{var}=(.*)$', content, re.MULTILINE)\n",
    "        if match:\n",
    "            value = match.group(1).strip()\n",
    "            # Mask sensitive values\n",
    "            if 'PASSWORD' in var or 'SECRET' in var or 'API_KEY' in var:\n",
    "                if value and value not in ['changeme', 'your_nvidia_api_key_here', '']:\n",
    "                    display_value = value[:8] + \"...\" if len(value) > 8 else \"***\"\n",
    "                else:\n",
    "                    display_value = \"\u26a0\ufe0f  NOT SET (using default/placeholder)\"\n",
    "            else:\n",
    "                display_value = value if value else \"\u26a0\ufe0f  NOT SET\"\n",
    "            print(f\"  {var:25} = {display_value:30} # {description}\")\n",
    "        else:\n",
    "            print(f\"  {var:25} = \u26a0\ufe0f  NOT FOUND              # {description}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"\\n\u2705 Environment file check complete!\")\n",
    "    print(\"\\n\ud83d\udca1 Important Notes:\")\n",
    "    print(\"   - For production, change all default passwords and secrets\")\n",
    "    print(\"   - NVIDIA_API_KEY is required for AI features\")\n",
    "    print(\"   - JWT_SECRET_KEY is required in production\")\n",
    "    print(\"\\n\ud83d\udcdd To edit: nano .env  (or your preferred editor)\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Check environment file\n",
    "check_env_file()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Infrastructure Services\n",
    "\n",
    "The application requires several infrastructure services:\n",
    "- **TimescaleDB** (PostgreSQL with time-series extensions) - Database\n",
    "- **Redis** - Caching layer\n",
    "- **Milvus** - Vector database for embeddings\n",
    "- **Kafka** - Message broker\n",
    "\n",
    "We'll use Docker Compose to start these services.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "def check_docker_running():\n",
    "    \"\"\"Check if Docker is running.\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"docker\", \"info\"],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=5\n",
    "        )\n",
    "        return result.returncode == 0\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def start_infrastructure():\n",
    "    \"\"\"Start infrastructure services using Docker Compose.\"\"\"\n",
    "    print(\"\ud83d\udc33 Starting Infrastructure Services\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if not check_docker_running():\n",
    "        print(\"\u274c Docker is not running!\")\n",
    "        print(\"   Please start Docker Desktop or Docker daemon and try again.\")\n",
    "        return False\n",
    "    \n",
    "    compose_file = Path(\"deploy/compose/docker-compose.dev.yaml\")\n",
    "    if not compose_file.exists():\n",
    "        print(f\"\u274c Docker Compose file not found: {compose_file}\")\n",
    "        return False\n",
    "    \n",
    "    print(\"\\n1\ufe0f\u20e3 Checking for existing containers...\")\n",
    "    # Check if docker-compose or docker compose is available\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"docker\", \"compose\", \"version\"],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=5\n",
    "        )\n",
    "        compose_cmd = [\"docker\", \"compose\"]\n",
    "    except:\n",
    "        compose_cmd = [\"docker-compose\"]\n",
    "    \n",
    "    print(f\"   Using: {' '.join(compose_cmd)}\")\n",
    "    \n",
    "    print(\"\\n2\ufe0f\u20e3 Starting infrastructure services...\")\n",
    "    print(\"   This may take a few minutes on first run (downloading images)...\")\n",
    "    \n",
    "    result = subprocess.run(\n",
    "        compose_cmd + [\n",
    "            \"-f\", str(compose_file),\n",
    "            \"up\", \"-d\"\n",
    "        ],\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"\u2705 Infrastructure services started\")\n",
    "    else:\n",
    "        print(f\"\u274c Failed to start services: {result.stderr}\")\n",
    "        return False\n",
    "    \n",
    "    print(\"\\n3\ufe0f\u20e3 Waiting for services to be ready...\")\n",
    "    print(\"   (This may take 30-60 seconds)\")\n",
    "    \n",
    "    # Wait for TimescaleDB\n",
    "    max_wait = 60\n",
    "    waited = 0\n",
    "    while waited < max_wait:\n",
    "        try:\n",
    "            result = subprocess.run(\n",
    "                [\"docker\", \"exec\", \"wosa-timescaledb\", \"pg_isready\", \"-U\", \"warehouse\"],\n",
    "                capture_output=True,\n",
    "                timeout=5\n",
    "            )\n",
    "            if result.returncode == 0:\n",
    "                print(\"\u2705 TimescaleDB is ready\")\n",
    "                break\n",
    "        except:\n",
    "            pass\n",
    "        time.sleep(2)\n",
    "        waited += 2\n",
    "        if waited % 10 == 0:\n",
    "            print(f\"   Waiting... ({waited}s)\")\n",
    "    \n",
    "    if waited >= max_wait:\n",
    "        print(\"\u26a0\ufe0f  TimescaleDB may not be ready yet. Continuing anyway...\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"\u2705 Infrastructure services are running!\")\n",
    "    print(\"\\n\ud83d\udccb Service Endpoints:\")\n",
    "    print(\"   \u2022 TimescaleDB: localhost:5435\")\n",
    "    print(\"   \u2022 Redis: localhost:6379\")\n",
    "    print(\"   \u2022 Milvus: localhost:19530 (gRPC), localhost:9091 (HTTP)\")\n",
    "    print(\"   \u2022 Kafka: localhost:9092\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Uncomment to start infrastructure automatically\n",
    "# start_infrastructure()\n",
    "\n",
    "print(\"\ud83d\udca1 To start infrastructure services, run:\")\n",
    "print(\"   ./scripts/setup/dev_up.sh\")\n",
    "print(\"\\n   Or uncomment the start_infrastructure() call above.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Database Setup\n",
    "\n",
    "Now we'll run database migrations to set up the schema. This includes:\n",
    "- Core schema\n",
    "- Equipment schema\n",
    "- Document schema\n",
    "- Inventory movements schema\n",
    "- Model tracking tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess",
    "import os",
    "from pathlib import Path",
    "from dotenv import load_dotenv",
    "",
    "# Load environment variables",
    "load_dotenv()",
    "",
    "def run_migration(sql_file):",
    "    \"\"\"Run a single SQL migration file.",
    "    ",
    "    Tries methods in order:",
    "    1. docker-compose exec (recommended - no psql client needed)",
    "    2. docker exec (fallback)",
    "    3. psql from host (requires PostgreSQL client installed)",
    "    \"\"\"",
    "    db_host = os.getenv(\"DB_HOST\", \"localhost\")",
    "    db_port = os.getenv(\"DB_PORT\", \"5435\")",
    "    db_user = os.getenv(\"POSTGRES_USER\", \"warehouse\")",
    "    db_password = os.getenv(\"POSTGRES_PASSWORD\", \"changeme\")",
    "    db_name = os.getenv(\"POSTGRES_DB\", \"warehouse\")",
    "    ",
    "    sql_path = Path(sql_file)",
    "    if not sql_path.exists():",
    "        return False, f\"File not found: {sql_file}\"",
    "    ",
    "    # Method 1: Try docker-compose exec first (recommended)",
    "    try:",
    "        result = subprocess.run(",
    "            [",
    "                \"docker-compose\", \"-f\", \"deploy/compose/docker-compose.dev.yaml\",",
    "                \"exec\", \"-T\", \"timescaledb\",",
    "                \"psql\", \"-U\", db_user, \"-d\", db_name",
    "            ],",
    "            input=sql_path.read_text(),",
    "            capture_output=True,",
    "            text=True,",
    "            timeout=30",
    "        )",
    "        if result.returncode == 0:",
    "            return True, \"Success\"",
    "    except FileNotFoundError:",
    "        pass  # docker-compose not found, try next method",
    "    except Exception as e:",
    "        pass  # Try next method",
    "    ",
    "    # Method 2: Try docker exec (fallback)",
    "    try:",
    "        result = subprocess.run(",
    "            [",
    "                \"docker\", \"exec\", \"-i\", \"wosa-timescaledb\",",
    "                \"psql\", \"-U\", db_user, \"-d\", db_name",
    "            ],",
    "            input=sql_path.read_text(),",
    "            capture_output=True,",
    "            text=True,",
    "            timeout=30",
    "        )",
    "        if result.returncode == 0:",
    "            return True, \"Success\"",
    "    except FileNotFoundError:",
    "        pass  # docker not found, try next method",
    "    except Exception as e:",
    "        pass  # Try next method",
    "    ",
    "    # Method 3: Fall back to psql from host (requires PostgreSQL client)",
    "    try:",
    "        env = os.environ.copy()",
    "        env[\"PGPASSWORD\"] = db_password",
    "        result = subprocess.run(",
    "            [",
    "                \"psql\",",
    "                \"-h\", db_host,",
    "                \"-p\", db_port,",
    "                \"-U\", db_user,",
    "                \"-d\", db_name,",
    "                \"-f\", str(sql_path)",
    "            ],",
    "            env=env,",
    "            capture_output=True,",
    "            text=True,",
    "            timeout=30",
    "        )",
    "        if result.returncode == 0:",
    "            return True, \"Success\"",
    "        else:",
    "            return False, result.stderr",
    "    except FileNotFoundError:",
    "        return False, \"psql not found. Install PostgreSQL client or use Docker Compose method.\"",
    "    except Exception as e:",
    "        return False, f\"All methods failed: {str(e)}\"",
    "",
    "def setup_database():",
    "    \"\"\"Run all database migrations.\"\"\"",
    "    print(\"\ud83d\uddc4\ufe0f  Database Setup and Migrations\")",
    "    print(\"=\" * 60)",
    "    ",
    "    migrations = [",
    "        (\"data/postgres/000_schema.sql\", \"Core schema\"),",
    "        (\"data/postgres/001_equipment_schema.sql\", \"Equipment schema\"),",
    "        (\"data/postgres/002_document_schema.sql\", \"Document schema\"),",
    "        (\"data/postgres/004_inventory_movements_schema.sql\", \"Inventory movements schema\"),",
    "        (\"scripts/setup/create_model_tracking_tables.sql\", \"Model tracking tables\"),",
    "    ]",
    "    ",
    "    print(\"\\n\ud83d\udccb Running migrations...\\n\")",
    "    ",
    "    for sql_file, description in migrations:",
    "        print(f\"  \ud83d\udd04 {description}...\", end=\" \")",
    "        success, message = run_migration(sql_file)",
    "        if success:",
    "            print(\"\u2705\")",
    "        else:",
    "            print(f\"\u274c\\n     Error: {message}\")",
    "            print(f\"\\n\ud83d\udca1 Try running manually:\")",
    "            print(f\"   # Using Docker Compose (recommended):\")",
    "            print(f\"   docker-compose -f deploy/compose/docker-compose.dev.yaml exec -T timescaledb psql -U warehouse -d warehouse < {sql_file}\")",
    "            print(f\"   # Or using psql (requires PostgreSQL client):\")",
    "            print(f\"   PGPASSWORD=${{POSTGRES_PASSWORD:-changeme}} psql -h localhost -p 5435 -U warehouse -d warehouse -f {sql_file}\")",
    "            return False",
    "    ",
    "    print(\"\\n\" + \"=\" * 60)",
    "    print(\"\u2705 Database migrations completed successfully!\")",
    "    return True",
    "",
    "# Run migrations",
    "setup_database()",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Create Default Users\n",
    "\n",
    "Create the default admin user for accessing the application.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def create_default_users():\n",
    "    \"\"\"Create default admin user.\"\"\"\n",
    "    print(\"\ud83d\udc64 Creating Default Users\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    script_path = Path(\"scripts/setup/create_default_users.py\")\n",
    "    if not script_path.exists():\n",
    "        print(f\"\u274c Script not found: {script_path}\")\n",
    "        return False\n",
    "    \n",
    "    # Determine Python path\n",
    "    if sys.platform == \"win32\":\n",
    "        python_path = Path(\"env\") / \"Scripts\" / \"python.exe\"\n",
    "    else:\n",
    "        python_path = Path(\"env\") / \"bin\" / \"python\"\n",
    "    \n",
    "    if not python_path.exists():\n",
    "        print(f\"\u274c Python not found at: {python_path}\")\n",
    "        print(\"   Make sure virtual environment is set up (Step 3)\")\n",
    "        return False\n",
    "    \n",
    "    print(\"\\n\ud83d\udd04 Running user creation script...\")\n",
    "    result = subprocess.run(\n",
    "        [str(python_path), str(script_path)],\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"\u2705 Default users created successfully\")\n",
    "        print(\"\\n\ud83d\udccb Default Credentials:\")\n",
    "        print(\"   Username: admin\")\n",
    "        print(\"   Password: (check DEFAULT_ADMIN_PASSWORD in .env, default: 'changeme')\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"\u274c Failed to create users: {result.stderr}\")\n",
    "        print(\"\\n\ud83d\udca1 Try running manually:\")\n",
    "        print(f\"   source env/bin/activate  # or env\\\\Scripts\\\\activate on Windows\")\n",
    "        print(f\"   python {script_path}\")\n",
    "        return False\n",
    "\n",
    "# Create users\n",
    "create_default_users()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Generate Demo Data (Optional)\n",
    "\n",
    "Generate sample data for testing and demonstration purposes. This includes:\n",
    "- Equipment assets\n",
    "- Inventory items\n",
    "- Historical demand data (for forecasting)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def generate_demo_data():\n",
    "    \"\"\"Generate demo data for testing.\"\"\"\n",
    "    print(\"\ud83d\udcca Generating Demo Data\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Determine Python path\n",
    "    if sys.platform == \"win32\":\n",
    "        python_path = Path(\"env\") / \"Scripts\" / \"python.exe\"\n",
    "    else:\n",
    "        python_path = Path(\"env\") / \"bin\" / \"python\"\n",
    "    \n",
    "    if not python_path.exists():\n",
    "        print(f\"\u274c Python not found at: {python_path}\")\n",
    "        return False\n",
    "    \n",
    "    scripts = [\n",
    "        (\"scripts/data/quick_demo_data.py\", \"Quick demo data (equipment, inventory)\"),\n",
    "        (\"scripts/data/generate_historical_demand.py\", \"Historical demand data (for forecasting)\"),\n",
    "    ]\n",
    "    \n",
    "    for script_path, description in scripts:\n",
    "        script = Path(script_path)\n",
    "        if not script.exists():\n",
    "            print(f\"\u26a0\ufe0f  Script not found: {script_path} (skipping)\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n\ud83d\udd04 {description}...\")\n",
    "        result = subprocess.run(\n",
    "            [str(python_path), str(script)],\n",
    "            capture_output=True,\n",
    "            text=True\n",
    "        )\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(f\"\u2705 {description} generated\")\n",
    "        else:\n",
    "            print(f\"\u26a0\ufe0f  {description} had issues: {result.stderr[:200]}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"\u2705 Demo data generation complete!\")\n",
    "    print(\"\\n\ud83d\udca1 You can skip this step if you don't need demo data.\")\n",
    "    return True\n",
    "\n",
    "# Generate demo data\n",
    "generate_demo_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: \ud83d\ude80 (Optional) Install RAPIDS GPU Acceleration\n",
    "\n",
    "**This step is OPTIONAL** but highly recommended if you have an NVIDIA GPU. RAPIDS enables **10-100x faster forecasting** with GPU acceleration.\n",
    "\n",
    "### Benefits\n",
    "- \u26a1 **10-100x faster** training and inference\n",
    "- \ud83c\udfaf **Automatic GPU detection** - Falls back to CPU if GPU unavailable\n",
    "- \ud83d\udd04 **Zero code changes** - Works automatically when installed\n",
    "- \ud83d\udcca **Full model support** - Random Forest, Linear Regression, SVR via cuML; XGBoost via CUDA\n",
    "\n",
    "### Requirements\n",
    "- **NVIDIA GPU** with CUDA 12.x support\n",
    "- **CUDA Compute Capability 7.0+** (Volta, Turing, Ampere, Ada, Hopper)\n",
    "- **16GB+ GPU memory** (recommended)\n",
    "- **Python 3.9-3.11**\n",
    "\n",
    "**Note**: If you don't have a GPU or prefer not to install RAPIDS, you can skip this step. The application will work perfectly on CPU with automatic fallback.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def check_gpu_availability():\n",
    "    \"\"\"Check if NVIDIA GPU is available.\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['nvidia-smi'],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=5\n",
    "        )\n",
    "        if result.returncode == 0:\n",
    "            return True, result.stdout\n",
    "        return False, None\n",
    "    except (FileNotFoundError, subprocess.TimeoutExpired):\n",
    "        return False, None\n",
    "\n",
    "def check_rapids_installed():\n",
    "    \"\"\"Check if RAPIDS is already installed.\"\"\"\n",
    "    try:\n",
    "        import cudf\n",
    "        import cuml\n",
    "        return True, f\"cuDF {cudf.__version__}, cuML {cuml.__version__}\"\n",
    "    except ImportError:\n",
    "        return False, None\n",
    "\n",
    "def install_rapids():\n",
    "    \"\"\"Install RAPIDS cuDF and cuML.\"\"\"\n",
    "    print(\"\ud83d\udce6 Installing RAPIDS cuDF and cuML...\")\n",
    "    print(\"   This may take several minutes (packages are ~2GB)...\")\n",
    "    \n",
    "    try:\n",
    "        # Install RAPIDS\n",
    "        result = subprocess.run(\n",
    "            [\n",
    "                sys.executable, '-m', 'pip', 'install',\n",
    "                '--extra-index-url=https://pypi.nvidia.com',\n",
    "                'cudf-cu12', 'cuml-cu12'\n",
    "            ],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=1800  # 30 minutes timeout\n",
    "        )\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            return True, \"RAPIDS installed successfully\"\n",
    "        else:\n",
    "            return False, f\"Installation failed: {result.stderr}\"\n",
    "    except subprocess.TimeoutExpired:\n",
    "        return False, \"Installation timed out (took longer than 30 minutes)\"\n",
    "    except Exception as e:\n",
    "        return False, f\"Installation error: {str(e)}\"\n",
    "\n",
    "# Check GPU availability\n",
    "print(\"\ud83d\udd0d Checking GPU Availability...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "gpu_available, gpu_info = check_gpu_availability()\n",
    "if gpu_available:\n",
    "    print(\"\u2705 NVIDIA GPU detected!\")\n",
    "    print(\"\\nGPU Information:\")\n",
    "    print(gpu_info.split('\\n')[0:5])  # Show first few lines\n",
    "    print(\"\\n\ud83d\udca1 You can install RAPIDS for GPU acceleration!\")\n",
    "else:\n",
    "    print(\"\u26a0\ufe0f  NVIDIA GPU not detected or nvidia-smi not available\")\n",
    "    print(\"   RAPIDS installation is optional - the system will use CPU fallback\")\n",
    "\n",
    "# Check if RAPIDS is already installed\n",
    "print(\"\\n\ud83d\udd0d Checking RAPIDS Installation...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "rapids_installed, rapids_version = check_rapids_installed()\n",
    "if rapids_installed:\n",
    "    print(f\"\u2705 RAPIDS is already installed: {rapids_version}\")\n",
    "    print(\"   GPU acceleration will be enabled automatically!\")\n",
    "else:\n",
    "    print(\"\u274c RAPIDS is not installed\")\n",
    "    print(\"   The system will use CPU fallback (still works great!)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"\\n\ud83d\udcdd Next Steps:\")\n",
    "if not rapids_installed and gpu_available:\n",
    "    print(\"   \u2022 Run the next cell to install RAPIDS (optional but recommended)\")\n",
    "    print(\"   \u2022 Or skip to start the backend server\")\n",
    "elif not gpu_available:\n",
    "    print(\"   \u2022 GPU not detected - skipping RAPIDS installation\")\n",
    "    print(\"   \u2022 System will use CPU fallback (works perfectly!)\")\n",
    "    print(\"   \u2022 Proceed to start the backend server\")\n",
    "else:\n",
    "    print(\"   \u2022 RAPIDS is already installed - proceed to start the backend server\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Install RAPIDS for GPU acceleration\n",
    "# Uncomment and run this cell if you want to install RAPIDS\n",
    "\n",
    "# Check if we should install\n",
    "gpu_available, _ = check_gpu_availability()\n",
    "rapids_installed, _ = check_rapids_installed()\n",
    "\n",
    "if rapids_installed:\n",
    "    print(\"\u2705 RAPIDS is already installed - no need to reinstall!\")\n",
    "elif not gpu_available:\n",
    "    print(\"\u26a0\ufe0f  GPU not detected. RAPIDS installation is not recommended.\")\n",
    "    print(\"   The system will work perfectly with CPU fallback.\")\n",
    "    print(\"   If you're sure you have a GPU, you can still install RAPIDS.\")\n",
    "    print(\"\\n   To install anyway, uncomment the install_rapids() call below.\")\n",
    "else:\n",
    "    print(\"\ud83d\ude80 Ready to install RAPIDS!\")\n",
    "    print(\"   This will install:\")\n",
    "    print(\"   \u2022 cuDF (GPU-accelerated DataFrames)\")\n",
    "    print(\"   \u2022 cuML (GPU-accelerated Machine Learning)\")\n",
    "    print(\"   \u2022 Estimated time: 5-15 minutes\")\n",
    "    print(\"   \u2022 Estimated size: ~2GB\")\n",
    "    print(\"\\n   Uncomment the line below to proceed with installation:\")\n",
    "    print(\"   install_rapids()\")\n",
    "\n",
    "# Uncomment the line below to install RAPIDS:\n",
    "# success, message = install_rapids()\n",
    "# if success:\n",
    "#     print(f\"\u2705 {message}\")\n",
    "#     print(\"\\n\ud83d\udd0d Verifying installation...\")\n",
    "#     rapids_installed, rapids_version = check_rapids_installed()\n",
    "#     if rapids_installed:\n",
    "#         print(f\"\u2705 RAPIDS verified: {rapids_version}\")\n",
    "#         print(\"   GPU acceleration will be enabled automatically!\")\n",
    "#     else:\n",
    "#         print(\"\u26a0\ufe0f  Installation completed but verification failed\")\n",
    "# else:\n",
    "#     print(f\"\u274c {message}\")\n",
    "#     print(\"\\n\ud83d\udca1 Don't worry! The system will work perfectly with CPU fallback.\")\n",
    "#     print(\"   You can try installing RAPIDS later if needed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Start Backend Server\n",
    "\n",
    "Now we'll start the FastAPI backend server. The server will run on port 8001 by default.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "def check_port(port):\n",
    "    \"\"\"Check if a port is in use.\"\"\"\n",
    "    import socket\n",
    "    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    result = sock.connect_ex(('localhost', port))\n",
    "    sock.close()\n",
    "    return result == 0\n",
    "\n",
    "def start_backend():\n",
    "    \"\"\"Start the backend server.\"\"\"\n",
    "    print(\"\ud83d\ude80 Starting Backend Server\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    port = 8001\n",
    "    \n",
    "    # Check if port is already in use\n",
    "    if check_port(port):\n",
    "        print(f\"\u26a0\ufe0f  Port {port} is already in use!\")\n",
    "        print(\"   The backend may already be running.\")\n",
    "        print(f\"   Check: http://localhost:{port}/health\")\n",
    "        return True\n",
    "    \n",
    "    # Determine Python path\n",
    "    if sys.platform == \"win32\":\n",
    "        python_path = Path(\"env\") / \"Scripts\" / \"python.exe\"\n",
    "    else:\n",
    "        python_path = Path(\"env\") / \"bin\" / \"python\"\n",
    "    \n",
    "    if not python_path.exists():\n",
    "        print(f\"\u274c Python not found at: {python_path}\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"\\n\ud83d\udd04 Starting FastAPI server on port {port}...\")\n",
    "    print(\"   This will run in the background.\")\n",
    "    print(\"   To stop: Find the process and kill it, or restart the kernel.\")\n",
    "    print(\"\\n\ud83d\udccb Server Endpoints:\")\n",
    "    print(f\"   \u2022 API: http://localhost:{port}\")\n",
    "    print(f\"   \u2022 Docs: http://localhost:{port}/docs\")\n",
    "    print(f\"   \u2022 Health: http://localhost:{port}/health\")\n",
    "    \n",
    "    # Start server in background\n",
    "    import threading\n",
    "    \n",
    "    def run_server():\n",
    "        subprocess.run(\n",
    "            [\n",
    "                str(python_path),\n",
    "                \"-m\", \"uvicorn\",\n",
    "                \"src.api.app:app\",\n",
    "                \"--reload\",\n",
    "                \"--port\", str(port),\n",
    "                \"--host\", \"0.0.0.0\"\n",
    "            ],\n",
    "            cwd=Path.cwd()\n",
    "        )\n",
    "    \n",
    "    server_thread = threading.Thread(target=run_server, daemon=True)\n",
    "    server_thread.start()\n",
    "    \n",
    "    # Wait a bit and check if server started\n",
    "    print(\"\\n\u23f3 Waiting for server to start...\")\n",
    "    for i in range(10):\n",
    "        time.sleep(1)\n",
    "        if check_port(port):\n",
    "            print(f\"\u2705 Backend server is running on port {port}!\")\n",
    "            return True\n",
    "        print(f\"   Waiting... ({i+1}/10)\")\n",
    "    \n",
    "    print(\"\u26a0\ufe0f  Server may still be starting. Check manually:\")\n",
    "    print(f\"   curl http://localhost:{port}/health\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "print(\"\ud83d\udca1 To start the backend server, you have two options:\")\n",
    "print(\"\\n1\ufe0f\u20e3  Run in this notebook (uncomment below):\")\n",
    "print(\"   # start_backend()\")\n",
    "print(\"\\n2\ufe0f\u20e3  Run in a separate terminal (recommended):\")\n",
    "print(\"   ./scripts/start_server.sh\")\n",
    "print(\"\\n   Or manually:\")\n",
    "print(\"   source env/bin/activate\")\n",
    "print(\"   python -m uvicorn src.api.app:app --reload --port 8001 --host 0.0.0.0\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Start Frontend\n",
    "\n",
    "The frontend is a React application that runs on port 3001. You'll need to install Node.js dependencies first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "def setup_frontend():\n",
    "    \"\"\"Setup and start the frontend.\"\"\"\n",
    "    print(\"\ud83c\udfa8 Frontend Setup and Start\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    frontend_dir = Path(\"src/ui/web\")\n",
    "    if not frontend_dir.exists():\n",
    "        print(f\"\u274c Frontend directory not found: {frontend_dir}\")\n",
    "        return False\n",
    "    \n",
    "    # Check if node_modules exists\n",
    "    node_modules = frontend_dir / \"node_modules\"\n",
    "    if not node_modules.exists():\n",
    "        print(\"\\n\ud83d\udce6 Installing Node.js dependencies...\")\n",
    "        print(\"   This may take a few minutes...\")\n",
    "        \n",
    "        result = subprocess.run(\n",
    "            [\"npm\", \"install\"],\n",
    "            cwd=frontend_dir,\n",
    "            capture_output=True,\n",
    "            text=True\n",
    "        )\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"\u2705 Dependencies installed\")\n",
    "        else:\n",
    "            print(f\"\u274c Failed to install dependencies: {result.stderr}\")\n",
    "            return False\n",
    "    else:\n",
    "        print(\"\u2705 Node.js dependencies already installed\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"\u2705 Frontend setup complete!\")\n",
    "    print(\"\\n\ud83d\udccb To start the frontend, run in a separate terminal:\")\n",
    "    print(f\"   cd {frontend_dir}\")\n",
    "    print(\"   npm start\")\n",
    "    print(\"\\n   The frontend will be available at: http://localhost:3001\")\n",
    "    print(\"   Default login: admin / (check DEFAULT_ADMIN_PASSWORD in .env)\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Setup frontend\n",
    "setup_frontend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 13: Verification\n",
    "\n",
    "Let's verify that everything is set up correctly and the services are running.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import subprocess\n",
    "import socket\n",
    "from pathlib import Path\n",
    "\n",
    "def check_service(host, port, name):\n",
    "    \"\"\"Check if a service is running on a port.\"\"\"\n",
    "    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    sock.settimeout(2)\n",
    "    result = sock.connect_ex((host, port))\n",
    "    sock.close()\n",
    "    return result == 0\n",
    "\n",
    "def verify_setup():\n",
    "    \"\"\"Verify the complete setup.\"\"\"\n",
    "    print(\"\u2705 Verification Checklist\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    checks = {\n",
    "        \"Virtual Environment\": Path(\"env\").exists(),\n",
    "        \"Environment File\": Path(\".env\").exists(),\n",
    "        \"Backend Port (8001)\": check_service(\"localhost\", 8001, \"Backend\"),\n",
    "        \"Frontend Port (3001)\": check_service(\"localhost\", 3001, \"Frontend\"),\n",
    "        \"TimescaleDB (5435)\": check_service(\"localhost\", 5435, \"TimescaleDB\"),\n",
    "        \"Redis (6379)\": check_service(\"localhost\", 6379, \"Redis\"),\n",
    "        \"Milvus (19530)\": check_service(\"localhost\", 19530, \"Milvus\"),\n",
    "    }\n",
    "    \n",
    "    print(\"\\n\ud83d\udd0d Service Status:\\n\")\n",
    "    for service, status in checks.items():\n",
    "        status_icon = \"\u2705\" if status else \"\u274c\"\n",
    "        print(f\"  {status_icon} {service:25} {'Running' if status else 'Not Running'}\")\n",
    "    \n",
    "    # Test backend health endpoint\n",
    "    print(\"\\n\ud83c\udfe5 Backend Health Check:\")\n",
    "    try:\n",
    "        response = requests.get(\"http://localhost:8001/health\", timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            print(\"  \u2705 Backend is healthy\")\n",
    "            health_data = response.json()\n",
    "            if isinstance(health_data, dict):\n",
    "                print(f\"     Status: {health_data.get('status', 'unknown')}\")\n",
    "        else:\n",
    "            print(f\"  \u26a0\ufe0f  Backend returned status {response.status_code}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"  \u274c Backend health check failed: {e}\")\n",
    "    \n",
    "    # Test API endpoint\n",
    "    print(\"\\n\ud83d\udd0c API Endpoint Check:\")\n",
    "    try:\n",
    "        response = requests.get(\"http://localhost:8001/api/v1/version\", timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            print(\"  \u2705 API is accessible\")\n",
    "            version_data = response.json()\n",
    "            if isinstance(version_data, dict):\n",
    "                print(f\"     Version: {version_data.get('version', 'unknown')}\")\n",
    "        else:\n",
    "            print(f\"  \u26a0\ufe0f  API returned status {response.status_code}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"  \u274c API check failed: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    \n",
    "    all_checks = all(checks.values())\n",
    "    if all_checks:\n",
    "        print(\"\ud83c\udf89 All checks passed! Your setup is complete!\")\n",
    "    else:\n",
    "        print(\"\u26a0\ufe0f  Some checks failed. Please review the status above.\")\n",
    "    \n",
    "    print(\"\\n\ud83d\udccb Access Points:\")\n",
    "    print(\"   \u2022 Frontend: http://localhost:3001\")\n",
    "    print(\"   \u2022 Backend API: http://localhost:8001\")\n",
    "    print(\"   \u2022 API Docs: http://localhost:8001/docs\")\n",
    "    print(\"   \u2022 Health Check: http://localhost:8001/health\")\n",
    "    \n",
    "    return all_checks\n",
    "\n",
    "# Run verification\n",
    "verify_setup()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 14: Troubleshooting\n",
    "\n",
    "### Common Issues and Solutions\n",
    "\n",
    "#### 1. Port Already in Use\n",
    "\n",
    "If a port is already in use, you can either:\n",
    "- Stop the existing service\n",
    "- Change the port in the configuration\n",
    "\n",
    "**Backend (port 8001):**\n",
    "```bash\n",
    "# Find and kill process\n",
    "lsof -ti:8001 | xargs kill -9\n",
    "# Or change port: export PORT=8002\n",
    "```\n",
    "\n",
    "**Frontend (port 3001):**\n",
    "```bash\n",
    "# Find and kill process\n",
    "lsof -ti:3001 | xargs kill -9\n",
    "# Or change port: PORT=3002 npm start\n",
    "```\n",
    "\n",
    "#### 2. Database Connection Errors\n",
    "\n",
    "**Check if TimescaleDB is running:**\n",
    "```bash\n",
    "docker ps | grep timescaledb\n",
    "```\n",
    "\n",
    "**Test connection:**\n",
    "```bash\n",
    "PGPASSWORD=${POSTGRES_PASSWORD:-changeme} psql -h localhost -p 5435 -U warehouse -d warehouse -c \"SELECT 1;\"\n",
    "```\n",
    "\n",
    "#### 3. Missing Dependencies\n",
    "\n",
    "**Python:**\n",
    "```bash\n",
    "source env/bin/activate\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "**Node.js:**\n",
    "```bash\n",
    "cd src/ui/web\n",
    "npm install\n",
    "```\n",
    "\n",
    "#### 4. NVIDIA API Key Issues\n",
    "\n",
    "- Verify your API key at https://build.nvidia.com/\n",
    "- Check that `NVIDIA_API_KEY` is set in `.env`\n",
    "- Test the API key with a curl command (see DEPLOYMENT.md)\n",
    "\n",
    "#### 5. Node.js Version Issues\n",
    "\n",
    "If you see `Cannot find module 'node:path'`:\n",
    "- Upgrade to Node.js 18.17.0+ (recommended: 20.0.0+)\n",
    "- Check version: `node --version`\n",
    "- Use nvm to switch versions: `nvm use 20`\n",
    "\n",
    "### Getting Help\n",
    "\n",
    "- **Documentation**: See `DEPLOYMENT.md` for detailed deployment guide\n",
    "- **Issues**: Check GitHub Issues for known problems\n",
    "- **Logs**: Check service logs for error messages\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. \u2705 Access the frontend at http://localhost:3001\n",
    "2. \u2705 Log in with admin credentials\n",
    "3. \u2705 Explore the features:\n",
    "   - Chat Assistant\n",
    "   - Equipment Management\n",
    "   - Forecasting\n",
    "   - Operations\n",
    "   - Safety\n",
    "   - Document Extraction\n",
    "\n",
    "**Congratulations! Your Warehouse Operational Assistant is now set up and running! \ud83c\udf89**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Summary\n",
    "print(\"\ud83d\udccb Setup Summary\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n\u2705 Completed Steps:\")\n",
    "print(\"   1. Prerequisites verified\")\n",
    "print(\"   2. Repository setup\")\n",
    "print(\"   3. Environment configured\")\n",
    "print(\"   4. API keys configured\")\n",
    "print(\"   5. Infrastructure services started\")\n",
    "print(\"   6. Database migrations completed\")\n",
    "print(\"   7. Default users created\")\n",
    "print(\"   8. Demo data generated (optional)\")\n",
    "print(\"\\n\ud83d\ude80 Next Steps:\")\n",
    "print(\"   1. Start backend: ./scripts/start_server.sh\")\n",
    "print(\"   2. Start frontend: cd src/ui/web && npm start\")\n",
    "print(\"   3. Access: http://localhost:3001\")\n",
    "print(\"\\n\ud83d\udcda Documentation:\")\n",
    "print(\"   \u2022 DEPLOYMENT.md - Detailed deployment guide\")\n",
    "print(\"   \u2022 README.md - Project overview\")\n",
    "print(\"   \u2022 docs/ - Additional documentation\")\n",
    "print(\"\\n\ud83c\udf89 Setup complete! Happy coding!\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}