{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Setup Guide - Warehouse Operational Assistant\n",
    "\n",
    "This notebook provides a **complete, step-by-step setup guide** from cloning the repository to running the full application with backend and frontend.\n",
    "\n",
    "## Overview\n",
    "\n",
    "This guide will walk you through:\n",
    "1. ‚úÖ Prerequisites verification\n",
    "2. üì¶ Repository setup\n",
    "3. üîß Environment configuration\n",
    "4. üîë NVIDIA API key setup\n",
    "5. üóÑÔ∏è Database setup and migrations\n",
    "6. üöÄ Starting backend and frontend services\n",
    "7. ‚úÖ Verification and testing\n",
    "\n",
    "**Estimated Time:** 30-45 minutes\n",
    "\n",
    "**Requirements:**\n",
    "- Python 3.9+\n",
    "- Node.js 20.0.0+ (or minimum 18.17.0+)\n",
    "- Docker & Docker Compose (for infrastructure services)\n",
    "- Git\n",
    "- NVIDIA API key (free account at https://build.nvidia.com/)\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Prerequisites Check](#prerequisites-check)\n",
    "2. [Repository Setup](#repository-setup)\n",
    "3. [Environment Setup](#environment-setup)\n",
    "4. [API Key Configuration (NVIDIA & Brev)](#api-key-configuration-nvidia--brev)\n",
    "5. [Environment Variables Setup](#environment-variables-setup)\n",
    "6. [Infrastructure Services](#infrastructure-services)\n",
    "7. [Database Setup](#database-setup)\n",
    "8. [Create Default Users](#create-default-users)\n",
    "9. [Generate Demo Data](#generate-demo-data)\n",
    "10. [üöÄ (Optional) Install RAPIDS GPU Acceleration](#optional-install-rapids-gpu-acceleration)\n",
    "11. [Start Backend Server](#start-backend-server)\n",
    "12. [Start Frontend](#start-frontend)\n",
    "13. [Verification](#verification)\n",
    "14. [Troubleshooting](#troubleshooting)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Prerequisites Check\n",
    "\n",
    "Let's verify that all required tools are installed and meet version requirements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "def check_command(command, min_version=None, version_flag='--version'):\n",
    "    \"\"\"Check if a command exists and optionally verify version.\"\"\"\n",
    "    if not shutil.which(command):\n",
    "        return False, None, f\"‚ùå {command} is not installed\"\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [command, version_flag],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=5\n",
    "        )\n",
    "        version = result.stdout.strip() or result.stderr.strip()\n",
    "        return True, version, f\"‚úÖ {command} found: {version}\"\n",
    "    except Exception as e:\n",
    "        return False, None, f\"‚ö†Ô∏è  {command} found but version check failed: {e}\"\n",
    "\n",
    "def check_python_version():\n",
    "    \"\"\"Check Python version.\"\"\"\n",
    "    version = sys.version_info\n",
    "    version_str = f\"{version.major}.{version.minor}.{version.micro}\"\n",
    "    \n",
    "    if version.major < 3 or (version.major == 3 and version.minor < 9):\n",
    "        return False, version_str, f\"‚ùå Python {version_str} is too old. Required: Python 3.9+\"\n",
    "    return True, version_str, f\"‚úÖ Python {version_str} meets requirements\"\n",
    "\n",
    "def check_node_version():\n",
    "    \"\"\"Check Node.js version.\"\"\"\n",
    "    exists, version, message = check_command('node')\n",
    "    if not exists:\n",
    "        return exists, None, message\n",
    "    \n",
    "    # Extract version number\n",
    "    try:\n",
    "        version_str = version.split()[1] if ' ' in version else version.replace('v', '')\n",
    "        parts = version_str.split('.')\n",
    "        major = int(parts[0])\n",
    "        minor = int(parts[1]) if len(parts) > 1 else 0\n",
    "        patch = int(parts[2]) if len(parts) > 2 else 0\n",
    "        \n",
    "        # Check minimum: 18.17.0, Recommended: 20.0.0+\n",
    "        if major < 18:\n",
    "            return False, version_str, f\"‚ùå Node.js {version_str} is too old. Required: 18.17.0+ (Recommended: 20.0.0+)\"\n",
    "        elif major == 18 and (minor < 17 or (minor == 17 and patch < 0)):\n",
    "            return False, version_str, f\"‚ùå Node.js {version_str} is too old. Required: 18.17.0+ (Recommended: 20.0.0+)\"\n",
    "        elif major == 18:\n",
    "            return True, version_str, f\"‚ö†Ô∏è  Node.js {version_str} meets minimum (18.17.0+). Recommended: 20.0.0+\"\n",
    "        else:\n",
    "            return True, version_str, f\"‚úÖ Node.js {version_str} meets requirements (Recommended: 20.0.0+)\"\n",
    "    except:\n",
    "        return True, version, f\"‚úÖ Node.js found: {version}\"\n",
    "\n",
    "print(\"üîç Checking Prerequisites...\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check Python\n",
    "ok, version, msg = check_python_version()\n",
    "print(msg)\n",
    "\n",
    "# Check Node.js\n",
    "ok, version, msg = check_node_version()\n",
    "print(msg)\n",
    "\n",
    "# Check npm\n",
    "ok, version, msg = check_command('npm')\n",
    "print(msg)\n",
    "\n",
    "# Check Git\n",
    "ok, version, msg = check_command('git')\n",
    "print(msg)\n",
    "\n",
    "# Check Docker\n",
    "ok, version, msg = check_command('docker')\n",
    "print(msg)\n",
    "\n",
    "# Check Docker Compose\n",
    "ok, version, msg = check_command('docker-compose')\n",
    "if not ok:\n",
    "    # Try 'docker compose' (newer Docker CLI plugin format)\n",
    "    # Need to check this separately since it requires multiple arguments\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['docker', 'compose', 'version'],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=5\n",
    "        )\n",
    "        if result.returncode == 0:\n",
    "            version = result.stdout.strip() or result.stderr.strip()\n",
    "            ok, version, msg = True, version, f\"‚úÖ docker compose found: {version}\"\n",
    "        else:\n",
    "            ok, version, msg = False, None, \"‚ùå docker compose is not available\"\n",
    "    except (FileNotFoundError, subprocess.TimeoutExpired):\n",
    "        ok, version, msg = False, None, \"‚ùå docker compose is not available\"\n",
    "print(msg)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"\\n‚úÖ Prerequisites check complete!\")\n",
    "print(\"\\nüìù If any checks failed, please install the missing tools before proceeding.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Repository Setup\n",
    "\n",
    "If you haven't cloned the repository yet, follow the instructions below. If you're already in the repository, you can skip this step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Detect project root: navigate from current directory to find project root\n",
    "# This handles cases where notebook is opened from notebooks/setup/ or project root\n",
    "def find_project_root():\n",
    "    \"\"\"Find the project root directory.\"\"\"\n",
    "    current = Path.cwd()\n",
    "    \n",
    "    # Check if we're already in project root\n",
    "    if (current / \"src\" / \"api\").exists() and (current / \"scripts\" / \"setup\").exists():\n",
    "        return current\n",
    "    \n",
    "    # Check if we're in notebooks/setup/ (go up 2 levels)\n",
    "    if (current / \"complete_setup_guide.ipynb\").exists() or current.name == \"setup\":\n",
    "        parent = current.parent.parent\n",
    "        if (parent / \"src\" / \"api\").exists() and (parent / \"scripts\" / \"setup\").exists():\n",
    "            return parent\n",
    "    \n",
    "    # Check if we're in notebooks/ (go up 1 level)\n",
    "    if current.name == \"notebooks\":\n",
    "        parent = current.parent\n",
    "        if (parent / \"src\" / \"api\").exists() and (parent / \"scripts\" / \"setup\").exists():\n",
    "            return parent\n",
    "    \n",
    "    # Try going up from current directory\n",
    "    for parent in current.parents:\n",
    "        if (parent / \"src\" / \"api\").exists() and (parent / \"scripts\" / \"setup\").exists():\n",
    "            return parent\n",
    "    \n",
    "    # Fallback: return current directory\n",
    "    return current\n",
    "\n",
    "# Find and change to project root\n",
    "project_root = find_project_root()\n",
    "is_in_repo = (project_root / \"src\" / \"api\").exists() and (project_root / \"scripts\" / \"setup\").exists()\n",
    "\n",
    "if is_in_repo:\n",
    "    # Change to project root so all subsequent operations work correctly\n",
    "    os.chdir(project_root)\n",
    "    # Store project_root globally so other cells can use it\n",
    "    import builtins\n",
    "    builtins.__project_root__ = project_root\n",
    "    builtins.__find_project_root__ = find_project_root\n",
    "    print(\"‚úÖ You're already in the Warehouse Operational Assistant repository!\")\n",
    "    print(f\"   Project root: {project_root}\")\n",
    "    print(f\"   Changed working directory to: {Path.cwd()}\")\n",
    "    print(\"\\nüìù You can skip the cloning step and proceed to environment setup.\")\n",
    "else:\n",
    "    print(\"üì¶ Repository Setup Instructions\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\nTo clone the repository, run the following command in your terminal:\")\n",
    "    print(\"\\n```bash\")\n",
    "    print(\"git clone https://github.com/NVIDIA-AI-Blueprints/Multi-Agent-Intelligent-Warehouse.git\")\n",
    "    print(\"cd Multi-Agent-Intelligent-Warehouse\")\n",
    "    print(\"```\")\n",
    "    print(\"\\n‚ö†Ô∏è  After cloning, restart this notebook from the project root directory.\")\n",
    "    print(\"\\nAlternatively, if you want to clone it now, uncomment and run the cell below:\")\n",
    "    print(f\"\\nüìÅ Current directory: {Path.cwd()}\")\n",
    "\n",
    "print(f\"üìÅ Project root: {project_root}\")\n",
    "print(f\"üìÅ Expected structure: {project_root / 'src' / 'api'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the lines below to clone the repository automatically\n",
    "# WARNING: This will clone to the current directory\n",
    "\n",
    "# import subprocess\n",
    "# \n",
    "# repo_url = \"https://github.com/NVIDIA-AI-Blueprints/Multi-Agent-Intelligent-Warehouse.git\"\n",
    "# repo_name = \"Multi-Agent-Intelligent-Warehouse\"\n",
    "# \n",
    "# if not Path(repo_name).exists():\n",
    "#     print(f\"üì¶ Cloning repository from {repo_url}...\")\n",
    "#     subprocess.run([\"git\", \"clone\", repo_url], check=True)\n",
    "#     print(f\"‚úÖ Repository cloned to {Path.cwd() / repo_name}\")\n",
    "#     print(f\"\\n‚ö†Ô∏è  Please change directory and restart this notebook:\")\n",
    "#     print(f\"   cd {repo_name}\")\n",
    "#     print(f\"   jupyter notebook notebooks/setup/complete_setup_guide.ipynb\")\n",
    "# else:\n",
    "#     print(f\"‚úÖ Repository already exists at {Path.cwd() / repo_name}\")\n",
    "\n",
    "print(\"üí° To clone manually, use the command shown in the previous cell.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Environment Setup\n",
    "\n",
    "This step will:\n",
    "- Create a Python virtual environment\n",
    "- Install all Python dependencies\n",
    "- Verify the installation\n",
    "\n",
    "### ‚ö†Ô∏è Important: Virtual Environment and Jupyter Kernel\n",
    "\n",
    "**Best Practice:** For the smoothest experience, create the virtual environment **before** starting Jupyter:\n",
    "\n",
    "```bash\n",
    "# Option 1: Create venv first, then start Jupyter (RECOMMENDED)\n",
    "python3 -m venv env\n",
    "source env/bin/activate  # or env\\Scripts\\activate on Windows\n",
    "pip install jupyter ipykernel\n",
    "python -m ipykernel install --user --name=warehouse-assistant\n",
    "jupyter notebook notebooks/setup/complete_setup_guide.ipynb\n",
    "# Then select \"warehouse-assistant\" as the kernel\n",
    "```\n",
    "\n",
    "**Alternative:** You can create the venv inside this notebook (see below), but you'll need to:\n",
    "1. Create the venv (this cell)\n",
    "2. Install ipykernel in the new venv\n",
    "3. Restart the kernel and switch to the new venv kernel\n",
    "4. Continue with the rest of the setup\n",
    "\n",
    "**Note:** The next cell will show which Python/kernel you're currently using.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def run_command(cmd, check=True, shell=False):\n",
    "    \"\"\"Run a shell command and return the result.\"\"\"\n",
    "    if isinstance(cmd, str) and not shell:\n",
    "        cmd = cmd.split()\n",
    "    \n",
    "    result = subprocess.run(\n",
    "        cmd,\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        shell=shell,\n",
    "        check=check\n",
    "    )\n",
    "    return result.returncode == 0, result.stdout, result.stderr\n",
    "\n",
    "# Show current kernel info\n",
    "print(\"üîç Current Jupyter Kernel Information\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Working directory: {Path.cwd()}\")\n",
    "\n",
    "# Check if we're already in a virtual environment\n",
    "in_venv = hasattr(sys, 'real_prefix') or (hasattr(sys, 'base_prefix') and sys.base_prefix != sys.prefix)\n",
    "if in_venv:\n",
    "    print(f\"‚úÖ Already running in a virtual environment: {sys.prefix}\")\n",
    "    if 'env' in str(sys.prefix) or 'venv' in str(sys.prefix):\n",
    "        print(\"   This appears to be the project's virtual environment!\")\n",
    "        use_existing = True\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è  This is a different virtual environment\")\n",
    "        use_existing = False\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Not running in a virtual environment (using system Python)\")\n",
    "    use_existing = False\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# Check if virtual environment exists\n",
    "env_path = Path(\"env\")\n",
    "if env_path.exists():\n",
    "    print(\"‚úÖ Virtual environment directory 'env' already exists!\")\n",
    "    \n",
    "    if use_existing:\n",
    "        print(\"‚úÖ You're already using the project's virtual environment - perfect!\")\n",
    "        print(\"   You can skip the venv creation step and proceed.\")\n",
    "        skip_setup = True\n",
    "    else:\n",
    "        print(\"\\nüí° Options:\")\n",
    "        print(\"   1. Switch to the existing venv kernel (recommended)\")\n",
    "        print(\"   2. Recreate the virtual environment\")\n",
    "        print(\"   3. Continue with current kernel (not recommended)\")\n",
    "        \n",
    "        choice = input(\"\\n‚ùì What would you like to do? (1/2/3): \").strip()\n",
    "        \n",
    "        if choice == '1':\n",
    "            print(\"\\nüìù To switch kernels:\")\n",
    "            print(\"   1. Go to: Kernel ‚Üí Change Kernel ‚Üí warehouse-assistant\")\n",
    "            print(\"   2. Or install kernel now:\")\n",
    "            if sys.platform == \"win32\":\n",
    "                python_path = Path(\"env\") / \"Scripts\" / \"python.exe\"\n",
    "            else:\n",
    "                python_path = Path(\"env\") / \"bin\" / \"python\"\n",
    "            \n",
    "            if python_path.exists():\n",
    "                print(f\"   {python_path} -m ipykernel install --user --name=warehouse-assistant\")\n",
    "                install_kernel = input(\"\\n‚ùì Install kernel now? (y/N): \").strip().lower()\n",
    "                if install_kernel == 'y':\n",
    "                    success, _, _ = run_command([str(python_path), \"-m\", \"ipykernel\", \"install\", \"--user\", \"--name=warehouse-assistant\"])\n",
    "                    if success:\n",
    "                        print(\"‚úÖ Kernel installed! Please restart kernel and select 'warehouse-assistant'\")\n",
    "                    else:\n",
    "                        print(\"‚ùå Failed to install kernel\")\n",
    "            skip_setup = True\n",
    "        elif choice == '2':\n",
    "            import shutil\n",
    "            print(\"üóëÔ∏è  Removing existing virtual environment...\")\n",
    "            shutil.rmtree(env_path)\n",
    "            print(\"‚úÖ Removed\")\n",
    "            skip_setup = False\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  Continuing with current kernel (may cause issues)\")\n",
    "            skip_setup = True\n",
    "else:\n",
    "    skip_setup = False\n",
    "\n",
    "if not skip_setup:\n",
    "    print(\"\\nüîß Setting up Python virtual environment...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create virtual environment\n",
    "    print(\"\\n1Ô∏è‚É£ Creating virtual environment...\")\n",
    "    success, stdout, stderr = run_command([sys.executable, \"-m\", \"venv\", \"env\"])\n",
    "    if success:\n",
    "        print(\"‚úÖ Virtual environment created\")\n",
    "    else:\n",
    "        print(f\"‚ùå Failed to create virtual environment: {stderr}\")\n",
    "        raise RuntimeError(\"Virtual environment creation failed\")\n",
    "    \n",
    "    # Determine activation script path\n",
    "    if sys.platform == \"win32\":\n",
    "        activate_script = Path(\"env\") / \"Scripts\" / \"activate\"\n",
    "        pip_path = Path(\"env\") / \"Scripts\" / \"pip\"\n",
    "        python_path = Path(\"env\") / \"Scripts\" / \"python\"\n",
    "    else:\n",
    "        activate_script = Path(\"env\") / \"bin\" / \"activate\"\n",
    "        pip_path = Path(\"env\") / \"bin\" / \"pip\"\n",
    "        python_path = Path(\"env\") / \"bin\" / \"python\"\n",
    "    \n",
    "    # Upgrade pip\n",
    "    print(\"\\n2Ô∏è‚É£ Upgrading pip...\")\n",
    "    success, stdout, stderr = run_command([str(pip_path), \"install\", \"--upgrade\", \"pip\", \"setuptools\", \"wheel\"])\n",
    "    if success:\n",
    "        print(\"‚úÖ pip upgraded\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  pip upgrade had issues: {stderr}\")\n",
    "    \n",
    "    # Install jupyter and ipykernel in the new venv\n",
    "    print(\"\\n3Ô∏è‚É£ Installing Jupyter and ipykernel in new environment...\")\n",
    "    success, stdout, stderr = run_command([str(pip_path), \"install\", \"jupyter\", \"ipykernel\"])\n",
    "    if success:\n",
    "        print(\"‚úÖ Jupyter and ipykernel installed\")\n",
    "        \n",
    "        # Register the kernel\n",
    "        print(\"\\n4Ô∏è‚É£ Registering kernel...\")\n",
    "        success, stdout, stderr = run_command([str(python_path), \"-m\", \"ipykernel\", \"install\", \"--user\", \"--name=warehouse-assistant\"])\n",
    "        if success:\n",
    "            print(\"‚úÖ Kernel 'warehouse-assistant' registered!\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  Could not register kernel: {stderr}\")\n",
    "            print(\"   You can do this manually later\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Could not install Jupyter: {stderr}\")\n",
    "    \n",
    "    # Install requirements\n",
    "    print(\"\\n5Ô∏è‚É£ Installing Python dependencies...\")\n",
    "    print(\"   This may take a few minutes...\")\n",
    "    success, stdout, stderr = run_command([str(pip_path), \"install\", \"-r\", \"requirements.txt\"])\n",
    "    if success:\n",
    "        print(\"‚úÖ Dependencies installed successfully\")\n",
    "    else:\n",
    "        print(f\"‚ùå Failed to install dependencies: {stderr}\")\n",
    "        print(\"\\nüí° Try running manually:\")\n",
    "        print(f\"   source env/bin/activate  # or env\\\\Scripts\\\\activate on Windows\")\n",
    "        print(\"   pip install -r requirements.txt\")\n",
    "        raise RuntimeError(\"Dependency installation failed\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"‚ö†Ô∏è  IMPORTANT NEXT STEP:\")\n",
    "    print(\"   1. Go to: Kernel ‚Üí Restart Kernel\")\n",
    "    print(\"   2. Then: Kernel ‚Üí Change Kernel ‚Üí warehouse-assistant\")\n",
    "    print(\"   3. Re-run this cell to verify you're in the correct environment\")\n",
    "    print(\"   4. Continue with the rest of the notebook\")\n",
    "else:\n",
    "    # Even if skip_setup is True, check if dependencies are installed\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"üîç Checking if dependencies are installed...\")\n",
    "    \n",
    "    # Determine pip path based on current environment\n",
    "    if sys.platform == \"win32\":\n",
    "        pip_path = Path(\"env\") / \"Scripts\" / \"pip.exe\"\n",
    "        python_path = Path(\"env\") / \"Scripts\" / \"python.exe\"\n",
    "    else:\n",
    "        pip_path = Path(\"env\") / \"bin\" / \"pip\"\n",
    "        python_path = Path(\"env\") / \"bin\" / \"python\"\n",
    "    \n",
    "    # If we're in the venv, use sys.executable's pip\n",
    "    if in_venv and ('env' in str(sys.prefix) or 'venv' in str(sys.prefix)):\n",
    "        pip_path = Path(sys.executable).parent / \"pip\"\n",
    "        if sys.platform == \"win32\":\n",
    "            pip_path = Path(sys.executable).parent / \"pip.exe\"\n",
    "    \n",
    "    # Check if key packages are installed\n",
    "    key_packages = ['fastapi', 'asyncpg', 'pydantic']\n",
    "    missing_packages = []\n",
    "    \n",
    "    for package in key_packages:\n",
    "        result, _, _ = run_command([str(pip_path), \"show\", package], check=False)\n",
    "        if not result:\n",
    "            missing_packages.append(package)\n",
    "    \n",
    "    if missing_packages:\n",
    "        print(f\"‚ö†Ô∏è  Missing packages detected: {', '.join(missing_packages)}\")\n",
    "        print(\"\\nüí° Dependencies need to be installed.\")\n",
    "        install_deps = input(\"‚ùì Install dependencies from requirements.txt? (Y/n): \").strip().lower()\n",
    "        \n",
    "        if install_deps != 'n':\n",
    "            print(\"\\n5Ô∏è‚É£ Installing Python dependencies...\")\n",
    "            print(\"   This may take a few minutes...\")\n",
    "            success, stdout, stderr = run_command([str(pip_path), \"install\", \"-r\", \"requirements.txt\"])\n",
    "            if success:\n",
    "                print(\"‚úÖ Dependencies installed successfully\")\n",
    "            else:\n",
    "                print(f\"‚ùå Failed to install dependencies: {stderr}\")\n",
    "                print(\"\\nüí° Try running manually:\")\n",
    "                if sys.platform == \"win32\":\n",
    "                    print(\"   env\\\\Scripts\\\\activate\")\n",
    "                else:\n",
    "                    print(\"   source env/bin/activate\")\n",
    "                print(\"   pip install -r requirements.txt\")\n",
    "                print(\"\\n‚ö†Ô∏è  Continuing anyway, but some features may not work.\")\n",
    "        else:\n",
    "            print(\"‚è≠Ô∏è  Skipping dependency installation\")\n",
    "            print(\"‚ö†Ô∏è  Warning: Some features may not work without dependencies\")\n",
    "    else:\n",
    "        print(\"‚úÖ Key dependencies are already installed\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"‚úÖ Environment setup complete!\")\n",
    "    \n",
    "    # Check CUDA version for RAPIDS compatibility\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"üîç Checking CUDA version for GPU acceleration...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    def check_cuda_version():\n",
    "        \"\"\"Check CUDA version and warn about RAPIDS compatibility.\"\"\"\n",
    "        cuda_version = None\n",
    "        detection_method = None\n",
    "        \n",
    "        # Try to detect CUDA version from nvcc\n",
    "        try:\n",
    "            result = subprocess.run(\n",
    "                ['nvcc', '--version'],\n",
    "                capture_output=True,\n",
    "                text=True,\n",
    "                timeout=5\n",
    "            )\n",
    "            if result.returncode == 0:\n",
    "                import re\n",
    "                match = re.search(r'release (\\d+\\.\\d+)', result.stdout)\n",
    "                if match:\n",
    "                    cuda_version = match.group(1)\n",
    "                    detection_method = \"nvcc\"\n",
    "        except (FileNotFoundError, subprocess.TimeoutExpired):\n",
    "            pass\n",
    "        \n",
    "        # Fallback to nvidia-smi\n",
    "        if not cuda_version:\n",
    "            try:\n",
    "                result = subprocess.run(\n",
    "                    ['nvidia-smi'],\n",
    "                    capture_output=True,\n",
    "                    text=True,\n",
    "                    timeout=5\n",
    "                )\n",
    "                if result.returncode == 0:\n",
    "                    import re\n",
    "                    match = re.search(r'CUDA Version: (\\d+\\.\\d+)', result.stdout)\n",
    "                    if match:\n",
    "                        cuda_version = match.group(1)\n",
    "                        detection_method = \"nvidia-smi (driver)\"\n",
    "            except (FileNotFoundError, subprocess.TimeoutExpired):\n",
    "                pass\n",
    "        \n",
    "        if cuda_version:\n",
    "            print(f\"‚úÖ CUDA version detected: {cuda_version} (via {detection_method})\")\n",
    "            \n",
    "            # Check if RAPIDS packages are installed\n",
    "            rapids_installed = False\n",
    "            rapids_cuda = None\n",
    "            try:\n",
    "                if in_venv and ('env' in str(sys.prefix) or 'venv' in str(sys.prefix)):\n",
    "                    pip_path = Path(sys.executable).parent / \"pip\"\n",
    "                else:\n",
    "                    if sys.platform == \"win32\":\n",
    "                        pip_path = Path(\"env\") / \"Scripts\" / \"pip.exe\"\n",
    "                    else:\n",
    "                        pip_path = Path(\"env\") / \"bin\" / \"pip\"\n",
    "                \n",
    "                # Check for RAPIDS packages\n",
    "                result, stdout, _ = run_command([str(pip_path), \"list\"], check=False)\n",
    "                if result:\n",
    "                    if 'cudf' in stdout.lower() or 'cuml' in stdout.lower():\n",
    "                        rapids_installed = True\n",
    "                        # Try to determine which CUDA version RAPIDS was installed for\n",
    "                        if 'cudf-cu12' in stdout or 'cuml-cu12' in stdout:\n",
    "                            rapids_cuda = \"cu12\"\n",
    "                        elif 'cudf-cu11' in stdout or 'cuml-cu11' in stdout:\n",
    "                            rapids_cuda = \"cu11\"\n",
    "            except Exception:\n",
    "                pass\n",
    "            \n",
    "            # Determine expected RAPIDS CUDA version\n",
    "            major_version = float(cuda_version.split('.')[0])\n",
    "            if major_version >= 12:\n",
    "                expected_rapids = \"cu12\"\n",
    "            elif major_version >= 11:\n",
    "                expected_rapids = \"cu11\"\n",
    "            else:\n",
    "                expected_rapids = None\n",
    "            \n",
    "            if rapids_installed:\n",
    "                if rapids_cuda:\n",
    "                    if expected_rapids and rapids_cuda != expected_rapids:\n",
    "                        print(f\"\\n‚ö†Ô∏è  CUDA Version Mismatch Detected!\")\n",
    "                        print(f\"   Installed CUDA: {cuda_version}\")\n",
    "                        print(f\"   RAPIDS installed for: {rapids_cuda}\")\n",
    "                        print(f\"   Expected RAPIDS version: {expected_rapids}\")\n",
    "                        print(f\"\\nüí° Recommendation:\")\n",
    "                        if major_version >= 12:\n",
    "                            print(f\"   Your CUDA {cuda_version} is compatible with cu12 packages.\")\n",
    "                            print(f\"   If you experience issues, reinstall RAPIDS:\")\n",
    "                            print(f\"   ./scripts/setup/install_rapids.sh\")\n",
    "                        else:\n",
    "                            print(f\"   Consider reinstalling RAPIDS for your CUDA version:\")\n",
    "                            print(f\"   ./scripts/setup/install_rapids.sh\")\n",
    "                    else:\n",
    "                        print(f\"‚úÖ RAPIDS packages installed and compatible with CUDA {cuda_version}\")\n",
    "                else:\n",
    "                    print(f\"‚úÖ RAPIDS packages detected (CUDA version not specified in package name)\")\n",
    "            else:\n",
    "                print(f\"\\nüí° RAPIDS GPU acceleration not installed yet\")\n",
    "                print(f\"   To install RAPIDS for CUDA {cuda_version}:\")\n",
    "                print(f\"   ./scripts/setup/install_rapids.sh\")\n",
    "                print(f\"   (This will auto-detect your CUDA version and install the correct packages)\")\n",
    "        else:\n",
    "            print(\"‚ÑπÔ∏è  CUDA not detected (GPU acceleration will use CPU fallback)\")\n",
    "            print(\"   If you have an NVIDIA GPU, ensure:\")\n",
    "            print(\"   1. NVIDIA drivers are installed\")\n",
    "            print(\"   2. CUDA toolkit is installed (optional, for development)\")\n",
    "            print(\"   3. Run: nvidia-smi to verify GPU access\")\n",
    "    \n",
    "    check_cuda_version()\n",
    "    \n",
    "    print(\"\\nüìù Next: Configure environment variables and API keys\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: API Key Configuration (NVIDIA & Brev)\n",
    "\n",
    "The Warehouse Operational Assistant uses NVIDIA NIMs (NVIDIA Inference Microservices) for AI capabilities. You have **two deployment options** for NIMs:\n",
    "\n",
    "### üöÄ NIM Deployment Options\n",
    "\n",
    "**Option 1: Cloud Endpoints** (Easiest - Default)\n",
    "- Use NVIDIA's cloud-hosted NIM services\n",
    "- **No installation required** - just configure API keys\n",
    "- Quick setup, perfect for development and testing\n",
    "- Endpoints: `api.brev.dev` or `integrate.api.nvidia.com`\n",
    "\n",
    "**Option 2: Self-Hosted NIMs** (Recommended for Production)\n",
    "- **Install NIMs on your own infrastructure** using Docker\n",
    "- **Create custom endpoints** on your servers\n",
    "- Benefits:\n",
    "  - üîí **Data Privacy**: Keep sensitive data on-premises\n",
    "  - üí∞ **Cost Control**: Avoid per-request cloud costs\n",
    "  - ‚öôÔ∏è **Custom Requirements**: Full control over infrastructure\n",
    "  - ‚ö° **Low Latency**: Reduced network latency\n",
    "\n",
    "**Self-Hosting Example:**\n",
    "```bash\n",
    "# Deploy LLM NIM on your server\n",
    "docker run --gpus all -p 8000:8000 \\\n",
    "  nvcr.io/nvidia/nim/llama-3.3-nemotron-super-49b-v1:latest \\\n",
    "  -e NVIDIA_API_KEY=\\\"your-key\\\"\n",
    "```\n",
    "\n",
    "Then configure `LLM_NIM_URL=http://your-server:8000/v1` in Step 5.\n",
    "\n",
    "---\n",
    "\n",
    "### üìã API Key Configuration\n",
    "\n",
    "**NVIDIA API Key** (`nvapi-...`)\n",
    "- **Get from**: https://build.nvidia.com/\n",
    "- **Used for**: All NVIDIA cloud services (LLM, Embedding, Guardrails)\n",
    "- **Format**: Starts with `nvapi-`\n",
    "\n",
    "**Brev API Key** (`brev_api_...`)\n",
    "- **Get from**: https://brev.nvidia.com/ (Brev account dashboard)\n",
    "- **Used for**: Brev-specific endpoints (`api.brev.dev`)\n",
    "- **Format**: Starts with `brev_api_`\n",
    "- **Note**: Some Brev endpoints may also accept NVIDIA API keys\n",
    "\n",
    "---\n",
    "\n",
    "### Configuration Options\n",
    "\n",
    "**Option 1: Use NVIDIA API Key for Everything (Recommended)**\n",
    "- Set `NVIDIA_API_KEY` with NVIDIA API key (`nvapi-...`)\n",
    "- Leave `EMBEDDING_API_KEY` unset\n",
    "- Works with both `api.brev.dev` and `integrate.api.nvidia.com`\n",
    "\n",
    "**Option 2: Use Brev API Key for LLM + NVIDIA API Key for Embedding**\n",
    "- Set `NVIDIA_API_KEY` with Brev API key (`brev_api_...`)\n",
    "- **MUST** set `EMBEDDING_API_KEY` with NVIDIA API key (`nvapi-...`)\n",
    "- Embedding service always requires NVIDIA API key\n",
    "\n",
    "The interactive setup below will guide you through the configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_project_root():\n",
    "    \"\"\"Get project root directory, detecting it if needed.\n",
    "    \n",
    "    This function works regardless of where the notebook is opened from.\n",
    "    It stores the result in builtins so it persists across cells.\n",
    "    \"\"\"\n",
    "    import builtins\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    \n",
    "    # Check if already stored\n",
    "    if hasattr(builtins, '__project_root__'):\n",
    "        return builtins.__project_root__\n",
    "    \n",
    "    # Try to find project root\n",
    "    current = Path.cwd()\n",
    "    \n",
    "    # Check if we're already in project root\n",
    "    if (current / \"src\" / \"api\").exists() and (current / \"scripts\" / \"setup\").exists():\n",
    "        project_root = current\n",
    "    # Check if we're in notebooks/setup/ (go up 2 levels)\n",
    "    elif (current / \"complete_setup_guide.ipynb\").exists() or current.name == \"setup\":\n",
    "        project_root = current.parent.parent\n",
    "    # Check if we're in notebooks/ (go up 1 level)\n",
    "    elif current.name == \"notebooks\":\n",
    "        project_root = current.parent\n",
    "    else:\n",
    "        # Try going up from current directory\n",
    "        project_root = current\n",
    "        for parent in current.parents:\n",
    "            if (parent / \"src\" / \"api\").exists() and (parent / \"scripts\" / \"setup\").exists():\n",
    "                project_root = parent\n",
    "                break\n",
    "    \n",
    "    # Change to project root and store it\n",
    "    os.chdir(project_root)\n",
    "    builtins.__project_root__ = project_root\n",
    "    return project_root\n",
    "\n",
    "\n",
    "import getpass\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "def setup_api_keys():\n",
    "    \"\"\"Interactive setup for API keys (NVIDIA and/or Brev).\"\"\"\n",
    "    # Get project root (works from any directory)\n",
    "    project_root = get_project_root()\n",
    "    print(\"üîë API Key Configuration\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Check if .env.example exists\n",
    "    env_example = project_root / \".env.example\"\n",
    "    if not env_example.exists():\n",
    "        print(\"‚ùå .env.example not found!\")\n",
    "        print(\"   Please ensure you're in the project root directory.\")\n",
    "        return False\n",
    "    \n",
    "    # Check if .env already exists\n",
    "    env_file = project_root / \".env\"\n",
    "    if env_file.exists():\n",
    "        print(\"‚úÖ .env file already exists\")\n",
    "        overwrite = input(\"\\n‚ùì Update API keys in existing .env? (y/N): \").strip().lower()\n",
    "        if overwrite != 'y':\n",
    "            print(\"üìù Skipping API key setup. Using existing .env file.\")\n",
    "            return True\n",
    "    else:\n",
    "        print(\"üìù Creating .env file from .env.example...\")\n",
    "        import shutil\n",
    "        shutil.copy(env_example, env_file)\n",
    "        print(\"‚úÖ .env file created\")\n",
    "    \n",
    "    # Ask about deployment option\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"üöÄ NIM Deployment Options:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\n1. Cloud Endpoints (Default - Easiest)\")\n",
    "    print(\"   ‚Ä¢ Use NVIDIA's cloud-hosted NIM services\")\n",
    "    print(\"   ‚Ä¢ No installation required\")\n",
    "    print(\"   ‚Ä¢ Requires API keys (configured below)\")\n",
    "    print(\"\\n2. Self-Hosted NIMs (Advanced)\")\n",
    "    print(\"   ‚Ä¢ Install NIMs on your own infrastructure\")\n",
    "    print(\"   ‚Ä¢ Create custom endpoints\")\n",
    "    print(\"   ‚Ä¢ Better for production, data privacy, cost control\")\n",
    "    print(\"   ‚Ä¢ See DEPLOYMENT.md for self-hosting instructions\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    deployment_choice = input(\"\\n‚ùì Using cloud endpoints or self-hosted NIMs? (1=Cloud, 2=Self-hosted, default: 1): \").strip() or \"1\"\n",
    "    \n",
    "    if deployment_choice == \"2\":\n",
    "        print(\"\\n‚úÖ Self-hosted NIMs selected\")\n",
    "        print(\"   ‚Ä¢ You can skip API key configuration if your NIMs don't require authentication\")\n",
    "        print(\"   ‚Ä¢ Configure endpoint URLs in Step 5 (Environment Variables Setup)\")\n",
    "        print(\"   ‚Ä¢ Example: LLM_NIM_URL=http://your-server:8000/v1\")\n",
    "        skip_keys = input(\"\\n‚ùì Skip API key configuration? (y/N): \").strip().lower()\n",
    "        if skip_keys == 'y':\n",
    "            print(\"üìù Skipping API key setup. Configure endpoints in Step 5.\")\n",
    "            return True\n",
    "    \n",
    "    # Get API key configuration choice (for cloud endpoints)\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"üìã API Key Configuration Options (for Cloud Endpoints):\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\nOption 1: Use NVIDIA API Key for Everything (Recommended)\")\n",
    "    print(\"  ‚Ä¢ Set NVIDIA_API_KEY with NVIDIA API key (nvapi-...)\")\n",
    "    print(\"  ‚Ä¢ Leave EMBEDDING_API_KEY unset\")\n",
    "    print(\"  ‚Ä¢ Works with both endpoints\")\n",
    "    print(\"\\nOption 2: Use Brev API Key for LLM + NVIDIA API Key for Embedding\")\n",
    "    print(\"  ‚Ä¢ Set NVIDIA_API_KEY with Brev API key (brev_api_...)\")\n",
    "    print(\"  ‚Ä¢ MUST set EMBEDDING_API_KEY with NVIDIA API key (nvapi-...)\")\n",
    "    print(\"  ‚Ä¢ Embedding service always requires NVIDIA API key\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    choice = input(\"\\n‚ùì Which option? (1 or 2, default: 1): \").strip() or \"1\"\n",
    "    \n",
    "    # Get NVIDIA_API_KEY\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    if choice == \"1\":\n",
    "        print(\"üìã Getting NVIDIA API Key:\")\n",
    "        print(\"1. Visit: https://build.nvidia.com/\")\n",
    "        print(\"2. Sign up or log in\")\n",
    "        print(\"3. Go to 'API Keys' section\")\n",
    "        print(\"4. Create a new API key (starts with 'nvapi-')\")\n",
    "        print(\"5. Copy the API key\")\n",
    "        print(\"=\" * 60)\n",
    "        api_key = getpass.getpass(\"\\nüîë Enter your NVIDIA API key (nvapi-...): \").strip()\n",
    "        embedding_key = None  # Will use NVIDIA_API_KEY\n",
    "        brev_model = None  # Not needed for Option 1\n",
    "    else:\n",
    "        print(\"üìã Getting Brev API Key for LLM:\")\n",
    "        print(\"1. Visit: https://brev.nvidia.com/ (Brev account dashboard)\")\n",
    "        print(\"2. Navigate to API Keys section\")\n",
    "        print(\"3. Create or copy your Brev API key (starts with 'brev_api_')\")\n",
    "        print(\"=\" * 60)\n",
    "        api_key = getpass.getpass(\"\\nüîë Enter your Brev API key (brev_api_...): \").strip()\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"üìã Getting NVIDIA API Key for Embedding (REQUIRED):\")\n",
    "        print(\"1. Visit: https://build.nvidia.com/\")\n",
    "        print(\"2. Sign up or log in\")\n",
    "        print(\"3. Go to 'API Keys' section\")\n",
    "        print(\"4. Create a new API key (starts with 'nvapi-')\")\n",
    "        print(\"5. Copy the API key\")\n",
    "        print(\"=\" * 60)\n",
    "        print(\"‚ö†Ô∏è  IMPORTANT: Embedding service REQUIRES NVIDIA API key!\")\n",
    "        embedding_key = getpass.getpass(\"\\nüîë Enter your NVIDIA API key for Embedding (nvapi-...): \").strip()\n",
    "        \n",
    "        # Prompt for Brev model name (required for Option 2)\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"üìã Getting Brev Model Name (REQUIRED):\")\n",
    "        print(\"=\" * 60)\n",
    "        print(\"The Brev model name changes frequently and is unique to your deployment.\")\n",
    "        print(\"Format: nvcf:nvidia/llama-3.3-nemotron-super-49b-v1:dep-XXXXXXXXXXXXX\")\n",
    "        print(\"\\nüí° Where to find it:\")\n",
    "        print(\"   1. Log in to your Brev account: https://brev.nvidia.com/\")\n",
    "        print(\"   2. Navigate to your deployment/endpoint\")\n",
    "        print(\"   3. Look for the 'Model' or 'Model ID' field\")\n",
    "        print(\"   4. Copy the full model identifier (starts with 'nvcf:')\")\n",
    "        print(\"=\" * 60)\n",
    "        print(\"\\nExample: nvcf:nvidia/llama-3.3-nemotron-super-49b-v1:dep-36xgucddX7uMu6iIgA862CZUcsZ\")\n",
    "        brev_model = input(\"\\nüîë Enter your Brev model name (nvcf:...): \").strip()\n",
    "        \n",
    "        if not brev_model:\n",
    "            print(\"‚ùå Brev model name is required for Option 2.\")\n",
    "            print(\"   You can set it later in the .env file as LLM_MODEL\")\n",
    "            return False\n",
    "        \n",
    "        if not brev_model.startswith(\"nvcf:\"):\n",
    "            print(\"‚ö†Ô∏è  Warning: Brev model name should start with 'nvcf:'\")\n",
    "            confirm = input(\"   Continue anyway? (y/N): \").strip().lower()\n",
    "            if confirm != 'y':\n",
    "                return False\n",
    "    \n",
    "    if not api_key:\n",
    "        print(\"‚ùå No API key provided. Skipping API key setup.\")\n",
    "        print(\"   You can set it later in the .env file or environment variables.\")\n",
    "        return False\n",
    "    \n",
    "    if api_key.lower() in [\"your_nvidia_api_key_here\", \"your-api-key-here\", \"\"]:\n",
    "        print(\"‚ùå Please enter your actual API key, not the placeholder.\")\n",
    "        return False\n",
    "    \n",
    "    # Validate key formats\n",
    "    if choice == \"1\" and not api_key.startswith(\"nvapi-\"):\n",
    "        print(\"‚ö†Ô∏è  Warning: NVIDIA API key should start with 'nvapi-'\")\n",
    "        confirm = input(\"   Continue anyway? (y/N): \").strip().lower()\n",
    "        if confirm != 'y':\n",
    "            return False\n",
    "    elif choice == \"2\":\n",
    "        if not api_key.startswith(\"brev_api_\"):\n",
    "            print(\"‚ö†Ô∏è  Warning: Brev API key should start with 'brev_api_'\")\n",
    "            confirm = input(\"   Continue anyway? (y/N): \").strip().lower()\n",
    "            if confirm != 'y':\n",
    "                return False\n",
    "        if not embedding_key or not embedding_key.startswith(\"nvapi-\"):\n",
    "            print(\"‚ùå Embedding service REQUIRES NVIDIA API key (must start with 'nvapi-')\")\n",
    "            return False\n",
    "    \n",
    "    # Update .env file\n",
    "    try:\n",
    "        with open(env_file, 'r') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # Replace NVIDIA_API_KEY\n",
    "        content = re.sub(\n",
    "            r'^NVIDIA_API_KEY=.*$',\n",
    "            f'NVIDIA_API_KEY={api_key}',\n",
    "            content,\n",
    "            flags=re.MULTILINE\n",
    "        )\n",
    "        \n",
    "        # Update EMBEDDING_API_KEY if provided\n",
    "        if embedding_key:\n",
    "            content = re.sub(\n",
    "                r'^EMBEDDING_API_KEY=.*$',\n",
    "                f'EMBEDDING_API_KEY={embedding_key}',\n",
    "                content,\n",
    "                flags=re.MULTILINE\n",
    "            )\n",
    "        else:\n",
    "            # Remove EMBEDDING_API_KEY line if using Option 1 (will use NVIDIA_API_KEY)\n",
    "            content = re.sub(r'^EMBEDDING_API_KEY=.*$\\n?', '', content, flags=re.MULTILINE)\n",
    "        \n",
    "        # Update LLM_MODEL if Brev model is provided (Option 2)\n",
    "        if brev_model:\n",
    "            # Check if LLM_MODEL exists in content, if not add it\n",
    "            if re.search(r'^LLM_MODEL=.*$', content, flags=re.MULTILINE):\n",
    "                content = re.sub(\n",
    "                    r'^LLM_MODEL=.*$',\n",
    "                    f'LLM_MODEL={brev_model}',\n",
    "                    content,\n",
    "                    flags=re.MULTILINE\n",
    "                )\n",
    "            else:\n",
    "                # Add LLM_MODEL after NVIDIA_API_KEY if it doesn't exist\n",
    "                content = re.sub(\n",
    "                    r'^(NVIDIA_API_KEY=.*)$',\n",
    "                    rf'\\1\\nLLM_MODEL={brev_model}',\n",
    "                    content,\n",
    "                    flags=re.MULTILINE\n",
    "                )\n",
    "        \n",
    "        # Now ask for each NVIDIA service API key one by one\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"üìã Configure NVIDIA Service API Keys\")\n",
    "        print(\"=\" * 60)\n",
    "        print(\"\\nüí° Each service can use the same NVIDIA API key or different keys.\")\n",
    "        print(\"   You can press Enter to skip a key (it will use NVIDIA_API_KEY as fallback).\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Define service keys with descriptions\n",
    "        service_keys = [\n",
    "            {\n",
    "                'name': 'RAIL_API_KEY',\n",
    "                'description': 'NeMo Guardrails - Content safety and compliance validation',\n",
    "                'required': False\n",
    "            },\n",
    "            {\n",
    "                'name': 'NEMO_RETRIEVER_API_KEY',\n",
    "                'description': 'NeMo Retriever - Document preprocessing and structure analysis',\n",
    "                'required': False\n",
    "            },\n",
    "            {\n",
    "                'name': 'NEMO_OCR_API_KEY',\n",
    "                'description': 'NeMo OCR - Intelligent OCR with layout understanding',\n",
    "                'required': False\n",
    "            },\n",
    "            {\n",
    "                'name': 'NEMO_PARSE_API_KEY',\n",
    "                'description': 'Nemotron Parse - Advanced document parsing and extraction',\n",
    "                'required': False\n",
    "            },\n",
    "            {\n",
    "                'name': 'LLAMA_NANO_VL_API_KEY',\n",
    "                'description': 'Small LLM (Nemotron Nano VL) - Structured data extraction and entity recognition',\n",
    "                'required': False\n",
    "            },\n",
    "            {\n",
    "                'name': 'LLAMA_70B_API_KEY',\n",
    "                'description': 'Large LLM Judge (Llama 3.3 49B) - Quality validation and confidence scoring',\n",
    "                'required': False\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        configured_keys = []\n",
    "        for service in service_keys:\n",
    "            print(f\"\\nüîë {service['name']}\")\n",
    "            print(f\"   Purpose: {service['description']}\")\n",
    "            print(f\"   Get from: https://build.nvidia.com/ (same as NVIDIA API key)\")\n",
    "            \n",
    "            # Suggest using the NVIDIA API key if available\n",
    "            suggested_key = embedding_key if embedding_key else (api_key if api_key.startswith(\"nvapi-\") else \"\")\n",
    "            if suggested_key:\n",
    "                print(f\"   üí° Suggested: Use your NVIDIA API key (starts with 'nvapi-')\")\n",
    "                user_key = getpass.getpass(f\"   Enter API key (or press Enter to use NVIDIA_API_KEY): \").strip()\n",
    "            else:\n",
    "                user_key = getpass.getpass(f\"   Enter API key (or press Enter to skip): \").strip()\n",
    "            \n",
    "            # Validate key format if provided\n",
    "            if user_key:\n",
    "                if not user_key.startswith(\"nvapi-\"):\n",
    "                    print(\"   ‚ö†Ô∏è  Warning: NVIDIA API key should start with 'nvapi-'\")\n",
    "                    confirm = input(\"   Continue anyway? (y/N): \").strip().lower()\n",
    "                    if confirm != 'y':\n",
    "                        user_key = \"\"\n",
    "                else:\n",
    "                    # Update the .env file with this key\n",
    "                    content = re.sub(\n",
    "                        rf'^{service[\"name\"]}=.*$',\n",
    "                        f'{service[\"name\"]}={user_key}',\n",
    "                        content,\n",
    "                        flags=re.MULTILINE\n",
    "                    )\n",
    "                    configured_keys.append(service['name'])\n",
    "                    print(f\"   ‚úÖ {service['name']} configured\")\n",
    "            else:\n",
    "                print(f\"   ‚è≠Ô∏è  Skipped (will use NVIDIA_API_KEY as fallback)\")\n",
    "        \n",
    "        with open(env_file, 'w') as f:\n",
    "            f.write(content)\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"‚úÖ API keys configured in .env file\")\n",
    "        print(\"=\" * 60)\n",
    "        if choice == \"1\":\n",
    "            print(\"   ‚Ä¢ NVIDIA_API_KEY: Set (will be used for all services)\")\n",
    "        else:\n",
    "            print(\"   ‚Ä¢ NVIDIA_API_KEY: Set (Brev API key for LLM)\")\n",
    "            print(\"   ‚Ä¢ EMBEDDING_API_KEY: Set (NVIDIA API key for Embedding)\")\n",
    "            if brev_model:\n",
    "                print(f\"   ‚Ä¢ LLM_MODEL: Set ({brev_model[:50]}...)\")\n",
    "        \n",
    "        if configured_keys:\n",
    "            print(f\"\\n   ‚Ä¢ Service-specific keys configured ({len(configured_keys)}):\")\n",
    "            for key in configured_keys:\n",
    "                print(f\"     - {key}\")\n",
    "        else:\n",
    "            print(\"\\n   ‚Ä¢ Service-specific keys: Using NVIDIA_API_KEY as fallback\")\n",
    "        \n",
    "        print(\"\\nüí° The API keys are stored in .env file (not committed to git)\")\n",
    "        print(\"üí° Services without specific keys will use NVIDIA_API_KEY automatically\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error updating .env file: {e}\")\n",
    "        return False\n",
    "\n",
    "# Run the setup\n",
    "setup_api_keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Environment Variables Setup\n",
    "\n",
    "Now let's verify and configure other important environment variables. The `.env` file should already be created from the previous step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_project_root():\n",
    "    \"\"\"Get project root directory, detecting it if needed.\n",
    "    \n",
    "    This function works regardless of where the notebook is opened from.\n",
    "    It stores the result in builtins so it persists across cells.\n",
    "    \"\"\"\n",
    "    import builtins\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    \n",
    "    # Check if already stored\n",
    "    if hasattr(builtins, '__project_root__'):\n",
    "        return builtins.__project_root__\n",
    "    \n",
    "    # Try to find project root\n",
    "    current = Path.cwd()\n",
    "    \n",
    "    # Check if we're already in project root\n",
    "    if (current / \"src\" / \"api\").exists() and (current / \"scripts\" / \"setup\").exists():\n",
    "        project_root = current\n",
    "    # Check if we're in notebooks/setup/ (go up 2 levels)\n",
    "    elif (current / \"complete_setup_guide.ipynb\").exists() or current.name == \"setup\":\n",
    "        project_root = current.parent.parent\n",
    "    # Check if we're in notebooks/ (go up 1 level)\n",
    "    elif current.name == \"notebooks\":\n",
    "        project_root = current.parent\n",
    "    else:\n",
    "        # Try going up from current directory\n",
    "        project_root = current\n",
    "        for parent in current.parents:\n",
    "            if (parent / \"src\" / \"api\").exists() and (parent / \"scripts\" / \"setup\").exists():\n",
    "                project_root = parent\n",
    "                break\n",
    "    \n",
    "    # Change to project root and store it\n",
    "    os.chdir(project_root)\n",
    "    builtins.__project_root__ = project_root\n",
    "    return project_root\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import re\n",
    "\n",
    "def check_env_file():\n",
    "    \"\"\"Check and display environment variable configuration.\"\"\"\n",
    "    # Get project root (works from any directory)\n",
    "    project_root = get_project_root()\n",
    "    \n",
    "    # Get project root (works even if Step 2 wasn't run)\n",
    "    import builtins\n",
    "    if hasattr(builtins, '__project_root__'):\n",
    "        project_root = builtins.__project_root__\n",
    "    elif hasattr(builtins, '__find_project_root__'):\n",
    "        project_root = builtins.__find_project_root__()\n",
    "        os.chdir(project_root)\n",
    "        builtins.__project_root__ = project_root\n",
    "    else:\n",
    "        # Fallback: try to find project root\n",
    "        current = Path.cwd()\n",
    "        # Check if we're in notebooks/setup/ (go up 2 levels)\n",
    "        if (current / \"complete_setup_guide.ipynb\").exists() or current.name == \"setup\":\n",
    "            project_root = current.parent.parent\n",
    "        elif current.name == \"notebooks\":\n",
    "            project_root = current.parent\n",
    "        else:\n",
    "            # Try going up from current directory\n",
    "            for parent in current.parents:\n",
    "                if (parent / \"src\" / \"api\").exists() and (parent / \"scripts\" / \"setup\").exists():\n",
    "                    project_root = parent\n",
    "                    break\n",
    "            else:\n",
    "                project_root = current\n",
    "        os.chdir(project_root)\n",
    "        builtins.__project_root__ = project_root\n",
    "    \n",
    "    env_file = project_root / \".env\"\n",
    "    env_example = project_root / \".env.example\"\n",
    "    \n",
    "    if not env_file.exists():\n",
    "        if env_example.exists():\n",
    "            print(\"üìù Creating .env file from .env.example...\")\n",
    "            import shutil\n",
    "            shutil.copy(env_example, env_file)\n",
    "            print(\"‚úÖ .env file created\")\n",
    "        else:\n",
    "            print(\"‚ùå Neither .env nor .env.example found!\")\n",
    "            return False\n",
    "    \n",
    "    # Load and display key variables\n",
    "    print(\"üìã Environment Variables Configuration\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    with open(env_file, 'r') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Extract key variables\n",
    "    key_vars = {\n",
    "        'NVIDIA_API_KEY': 'NVIDIA API Key (for NIM services)',\n",
    "        'LLM_NIM_URL': 'LLM NIM Endpoint',\n",
    "        'EMBEDDING_NIM_URL': 'Embedding NIM Endpoint',\n",
    "        'POSTGRES_PASSWORD': 'Database Password',\n",
    "        'JWT_SECRET_KEY': 'JWT Secret Key (for authentication)',\n",
    "        'DEFAULT_ADMIN_PASSWORD': 'Default Admin Password',\n",
    "        'DB_HOST': 'Database Host',\n",
    "        'DB_PORT': 'Database Port',\n",
    "    }\n",
    "    \n",
    "    print(\"\\nüîç Current Configuration:\\n\")\n",
    "    for var, description in key_vars.items():\n",
    "        match = re.search(rf'^{var}=(.*)$', content, re.MULTILINE)\n",
    "        if match:\n",
    "            value = match.group(1).strip()\n",
    "            # Mask sensitive values\n",
    "            if 'PASSWORD' in var or 'SECRET' in var or 'API_KEY' in var:\n",
    "                if value and value not in ['changeme', 'your_nvidia_api_key_here', '']:\n",
    "                    display_value = value[:8] + \"...\" if len(value) > 8 else \"***\"\n",
    "                else:\n",
    "                    display_value = \"‚ö†Ô∏è  NOT SET (using default/placeholder)\"\n",
    "            else:\n",
    "                display_value = value if value else \"‚ö†Ô∏è  NOT SET\"\n",
    "            print(f\"  {var:25} = {display_value:30} # {description}\")\n",
    "        else:\n",
    "            print(f\"  {var:25} = ‚ö†Ô∏è  NOT FOUND              # {description}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"\\n‚úÖ Environment file check complete!\")\n",
    "    print(\"\\nüí° Important Notes:\")\n",
    "    print(\"   - For production, change all default passwords and secrets\")\n",
    "    print(\"   - NVIDIA_API_KEY is required for AI features\")\n",
    "    print(\"   - JWT_SECRET_KEY is required in production\")\n",
    "    print(\"\\nüìù To edit: nano .env  (or your preferred editor)\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Check environment file\n",
    "check_env_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Infrastructure Services\n",
    "\n",
    "The application requires several infrastructure services:\n",
    "- **TimescaleDB** (PostgreSQL with time-series extensions) - Database\n",
    "- **Redis** - Caching layer\n",
    "- **Milvus** - Vector database for embeddings\n",
    "- **Kafka** - Message broker\n",
    "\n",
    "We'll use Docker Compose to start these services.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_project_root():\n",
    "    \"\"\"Get project root directory, detecting it if needed.\n",
    "    \n",
    "    This function works regardless of where the notebook is opened from.\n",
    "    It stores the result in builtins so it persists across cells.\n",
    "    \"\"\"\n",
    "    import builtins\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    \n",
    "    # Check if already stored\n",
    "    if hasattr(builtins, '__project_root__'):\n",
    "        return builtins.__project_root__\n",
    "    \n",
    "    # Try to find project root\n",
    "    current = Path.cwd()\n",
    "    \n",
    "    # Check if we're already in project root\n",
    "    if (current / \"src\" / \"api\").exists() and (current / \"scripts\" / \"setup\").exists():\n",
    "        project_root = current\n",
    "    # Check if we're in notebooks/setup/ (go up 2 levels)\n",
    "    elif (current / \"complete_setup_guide.ipynb\").exists() or current.name == \"setup\":\n",
    "        project_root = current.parent.parent\n",
    "    # Check if we're in notebooks/ (go up 1 level)\n",
    "    elif current.name == \"notebooks\":\n",
    "        project_root = current.parent\n",
    "    else:\n",
    "        # Try going up from current directory\n",
    "        project_root = current\n",
    "        for parent in current.parents:\n",
    "            if (parent / \"src\" / \"api\").exists() and (parent / \"scripts\" / \"setup\").exists():\n",
    "                project_root = parent\n",
    "                break\n",
    "    \n",
    "    # Change to project root and store it\n",
    "    os.chdir(project_root)\n",
    "    builtins.__project_root__ = project_root\n",
    "    return project_root\n",
    "\n",
    "\n",
    "import subprocess\n",
    "import time\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "def check_docker_running():\n",
    "    \"\"\"Check if Docker is running.\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"docker\", \"info\"],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=5\n",
    "        )\n",
    "        return result.returncode == 0\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def start_infrastructure():\n",
    "    \"\"\"Start infrastructure services using Docker Compose (matches dev_up.sh behavior).\"\"\"\n",
    "    print(\"üê≥ Starting Infrastructure Services\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if not check_docker_running():\n",
    "        print(\"‚ùå Docker is not running!\")\n",
    "        print(\"   Please start Docker Desktop or Docker daemon and try again.\")\n",
    "        return False\n",
    "    \n",
    "    # Get project root (works from any directory)\n",
    "    project_root = get_project_root()\n",
    "    compose_file = project_root / \"deploy/compose/docker-compose.dev.yaml\"\n",
    "    env_file = project_root / \".env\"\n",
    "    \n",
    "    if not compose_file.exists():\n",
    "        print(f\"‚ùå Docker Compose file not found: {compose_file}\")\n",
    "        return False\n",
    "    \n",
    "    # 1. Load environment variables from .env file (CRITICAL for TimescaleDB)\n",
    "    print(\"\\n1Ô∏è‚É£ Loading environment variables from .env file...\")\n",
    "    env_vars = {}\n",
    "    if env_file.exists():\n",
    "        print(f\"   Found .env file: {env_file}\")\n",
    "        try:\n",
    "            with open(env_file, 'r') as f:\n",
    "                for line in f:\n",
    "                    line = line.strip()\n",
    "                    if line and not line.startswith('#') and '=' in line:\n",
    "                        key, value = line.split('=', 1)\n",
    "                        key = key.strip()\n",
    "                        value = value.strip().strip('\"').strip(\"'\")\n",
    "                        env_vars[key] = value\n",
    "                        # Also set in os.environ so subprocess inherits it\n",
    "                        os.environ[key] = value\n",
    "            print(f\"   ‚úÖ Loaded {len(env_vars)} environment variables\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è  Warning: Could not load .env file: {e}\")\n",
    "            print(\"   Using default values (may cause issues)\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è  Warning: .env file not found!\")\n",
    "        print(\"   TimescaleDB may hang without POSTGRES_PASSWORD\")\n",
    "        print(\"   Make sure to create .env file (see Step 5)\")\n",
    "    \n",
    "    # 2. Detect docker compose command\n",
    "    print(\"\\n2Ô∏è‚É£ Detecting Docker Compose command...\")\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"docker\", \"compose\", \"version\"],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=5\n",
    "        )\n",
    "        if result.returncode == 0:\n",
    "            compose_cmd = [\"docker\", \"compose\"]\n",
    "            print(\"   ‚úÖ Using: docker compose (plugin)\")\n",
    "        else:\n",
    "            compose_cmd = [\"docker-compose\"]\n",
    "            print(\"   ‚úÖ Using: docker-compose (standalone)\")\n",
    "    except:\n",
    "        compose_cmd = [\"docker-compose\"]\n",
    "        print(\"   ‚úÖ Using: docker-compose (standalone)\")\n",
    "    \n",
    "    # 3. Configure TimescaleDB port (5432 -> 5435)\n",
    "    print(\"\\n3Ô∏è‚É£ Configuring TimescaleDB port 5435...\")\n",
    "    try:\n",
    "        with open(compose_file, 'r') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # Check if port is already 5435\n",
    "        if \"5435:5432\" in content:\n",
    "            print(\"   ‚úÖ Port already configured to 5435\")\n",
    "        elif \"5432:5432\" in content:\n",
    "            # Update port mapping\n",
    "            content = content.replace(\"5432:5432\", \"5435:5432\")\n",
    "            with open(compose_file, 'w') as f:\n",
    "                f.write(content)\n",
    "            print(\"   ‚úÖ Updated port mapping: 5432 -> 5435\")\n",
    "        \n",
    "        # Update .env file with PGPORT\n",
    "        if env_file.exists():\n",
    "            with open(env_file, 'r') as f:\n",
    "                env_content = f.read()\n",
    "            \n",
    "            if \"PGPORT=\" in env_content:\n",
    "                import re\n",
    "                env_content = re.sub(r'^PGPORT=.*$', 'PGPORT=5435', env_content, flags=re.MULTILINE)\n",
    "            else:\n",
    "                env_content += \"\\nPGPORT=5435\\n\"\n",
    "            \n",
    "            with open(env_file, 'w') as f:\n",
    "                f.write(env_content)\n",
    "            print(\"   ‚úÖ Updated .env with PGPORT=5435\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è  Warning: Could not configure port: {e}\")\n",
    "    \n",
    "    # 4. Clean up existing containers\n",
    "    print(\"\\n4Ô∏è‚É£ Cleaning up existing containers...\")\n",
    "    try:\n",
    "        subprocess.run(\n",
    "            compose_cmd + [\"-f\", str(compose_file), \"down\", \"--remove-orphans\"],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=30\n",
    "        )\n",
    "        # Also try to remove the container directly\n",
    "        subprocess.run(\n",
    "            [\"docker\", \"rm\", \"-f\", \"wosa-timescaledb\"],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=10\n",
    "        )\n",
    "        print(\"   ‚úÖ Cleanup complete\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è  Warning during cleanup: {e}\")\n",
    "    \n",
    "    # 5. Start services with environment variables\n",
    "    print(\"\\n5Ô∏è‚É£ Starting infrastructure services...\")\n",
    "    print(\"   This may take a few minutes on first run (downloading images)...\")\n",
    "    \n",
    "    # Prepare environment for subprocess (inherit current + .env vars)\n",
    "    subprocess_env = os.environ.copy()\n",
    "    subprocess_env.update(env_vars)\n",
    "    \n",
    "    result = subprocess.run(\n",
    "        compose_cmd + [\n",
    "            \"-f\", str(compose_file),\n",
    "            \"up\", \"-d\"\n",
    "        ],\n",
    "        cwd=str(project_root),\n",
    "        env=subprocess_env,\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"   ‚úÖ Infrastructure services started\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå Failed to start services\")\n",
    "        print(f\"   Error: {result.stderr}\")\n",
    "        if \"POSTGRES_PASSWORD\" in result.stderr or \"password\" in result.stderr.lower():\n",
    "            print(\"\\n   üí° Tip: Make sure .env file has POSTGRES_PASSWORD set (see Step 5)\")\n",
    "        return False\n",
    "    \n",
    "    # 6. Wait for TimescaleDB to be ready\n",
    "    print(\"\\n6Ô∏è‚É£ Waiting for TimescaleDB to be ready...\")\n",
    "    print(\"   (This may take 30-60 seconds)\")\n",
    "    \n",
    "    postgres_user = env_vars.get(\"POSTGRES_USER\", \"warehouse\")\n",
    "    postgres_db = env_vars.get(\"POSTGRES_DB\", \"warehouse\")\n",
    "    \n",
    "    max_wait = 60\n",
    "    waited = 0\n",
    "    while waited < max_wait:\n",
    "        try:\n",
    "            result = subprocess.run(\n",
    "                [\"docker\", \"exec\", \"wosa-timescaledb\", \"pg_isready\", \n",
    "                 \"-U\", postgres_user, \"-d\", postgres_db],\n",
    "                capture_output=True,\n",
    "                timeout=5\n",
    "            )\n",
    "            if result.returncode == 0:\n",
    "                print(f\"   ‚úÖ TimescaleDB is ready on port 5435\")\n",
    "                break\n",
    "        except subprocess.TimeoutExpired:\n",
    "            pass\n",
    "        except Exception:\n",
    "            pass\n",
    "        time.sleep(2)\n",
    "        waited += 2\n",
    "        if waited % 10 == 0:\n",
    "            print(f\"   Waiting... ({waited}s)\")\n",
    "    \n",
    "    if waited >= max_wait:\n",
    "        print(\"   ‚ö†Ô∏è  TimescaleDB may not be ready yet. Continuing anyway...\")\n",
    "        print(\"   You can check manually: docker exec wosa-timescaledb pg_isready -U warehouse\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"‚úÖ Infrastructure services are running!\")\n",
    "    print(\"\\nüìã Service Endpoints:\")\n",
    "    print(f\"   ‚Ä¢ TimescaleDB: postgresql://{postgres_user}:***@localhost:5435/{postgres_db}\")\n",
    "    print(\"   ‚Ä¢ Redis: localhost:6379\")\n",
    "    print(\"   ‚Ä¢ Milvus gRPC: localhost:19530\")\n",
    "    print(\"   ‚Ä¢ Milvus HTTP: localhost:9091\")\n",
    "    print(\"   ‚Ä¢ Kafka: localhost:9092\")\n",
    "    print(\"   ‚Ä¢ MinIO: localhost:9000 (console: localhost:9001)\")\n",
    "    print(\"   ‚Ä¢ etcd: localhost:2379\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Uncomment to start infrastructure automatically\n",
    "# start_infrastructure()\n",
    "print(\"üí° To start infrastructure services, run:\")\n",
    "print(\"   ./scripts/setup/dev_up.sh\")\n",
    "print(\"\\n   Or uncomment the start_infrastructure() call above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Database Setup\n",
    "\n",
    "Now we'll run database migrations to set up the schema. This includes:\n",
    "- Core schema\n",
    "- Equipment schema\n",
    "- Document schema\n",
    "- Inventory movements schema\n",
    "- Model tracking tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_project_root():\n",
    "    \"\"\"Get project root directory, detecting it if needed.\"\"\"\n",
    "    import builtins\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    \n",
    "    # Check if already stored\n",
    "    if hasattr(builtins, '__project_root__'):\n",
    "        return builtins.__project_root__\n",
    "    \n",
    "    # Try to find it\n",
    "    current = Path.cwd()\n",
    "    \n",
    "    # Check if we're already in project root\n",
    "    if (current / \"src\" / \"api\").exists() and (current / \"scripts\" / \"setup\").exists():\n",
    "        project_root = current\n",
    "    # Check if we're in notebooks/setup/ (go up 2 levels)\n",
    "    elif (current / \"complete_setup_guide.ipynb\").exists() or current.name == \"setup\":\n",
    "        project_root = current.parent.parent\n",
    "    # Check if we're in notebooks/ (go up 1 level)\n",
    "    elif current.name == \"notebooks\":\n",
    "        project_root = current.parent\n",
    "    else:\n",
    "        # Try going up from current directory\n",
    "        project_root = current\n",
    "        for parent in current.parents:\n",
    "            if (parent / \"src\" / \"api\").exists() and (parent / \"scripts\" / \"setup\").exists():\n",
    "                project_root = parent\n",
    "                break\n",
    "    \n",
    "    # Change to project root and store it\n",
    "    os.chdir(project_root)\n",
    "    builtins.__project_root__ = project_root\n",
    "    return project_root\n",
    "\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "def run_migration(sql_file):\n",
    "    # Get project root for file paths\n",
    "    project_root = get_project_root()\n",
    "    \n",
    "    \"\"\"Run a single SQL migration file.\n",
    "    \n",
    "    Tries methods in order:\n",
    "    1. docker compose exec (recommended - no psql client needed)\n",
    "       - Tries 'docker compose' (V2 plugin) first, then 'docker-compose' (V1 standalone)\n",
    "    2. docker exec (fallback)\n",
    "    3. psql from host (requires PostgreSQL client installed)\n",
    "    \"\"\"\n",
    "    db_host = os.getenv(\"DB_HOST\", \"localhost\")\n",
    "    db_port = os.getenv(\"DB_PORT\", \"5435\")\n",
    "    db_user = os.getenv(\"POSTGRES_USER\", \"warehouse\")\n",
    "    db_password = os.getenv(\"POSTGRES_PASSWORD\", \"changeme\")\n",
    "    db_name = os.getenv(\"POSTGRES_DB\", \"warehouse\")\n",
    "    \n",
    "    sql_path = project_root / sql_file if not Path(sql_file).is_absolute() else Path(sql_file)\n",
    "    if not sql_path.exists():\n",
    "        return False, f\"File not found: {sql_file}\"\n",
    "    \n",
    "    # Method 1: Try docker compose exec first (recommended)\n",
    "    # Check if docker compose (V2) or docker-compose (V1) is available\n",
    "    compose_cmd = None\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"docker\", \"compose\", \"version\"],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=5\n",
    "        )\n",
    "        if result.returncode == 0:\n",
    "            compose_cmd = [\"docker\", \"compose\"]\n",
    "    except:\n",
    "        try:\n",
    "            result = subprocess.run(\n",
    "                [\"docker-compose\", \"version\"],\n",
    "                capture_output=True,\n",
    "                text=True,\n",
    "                timeout=5\n",
    "            )\n",
    "            if result.returncode == 0:\n",
    "                compose_cmd = [\"docker-compose\"]\n",
    "        except:\n",
    "            pass  # Neither available, try next method\n",
    "    \n",
    "    if compose_cmd:\n",
    "        try:\n",
    "            result = subprocess.run(\n",
    "                compose_cmd + [\n",
    "                    \"-f\", str(project_root / \"deploy/compose/docker-compose.dev.yaml\"),\n",
    "                    \"exec\", \"-T\", \"timescaledb\",\n",
    "                    \"psql\", \"-U\", db_user, \"-d\", db_name\n",
    "                ],\n",
    "                input=sql_path.read_text(),\n",
    "                capture_output=True,\n",
    "                text=True,\n",
    "                timeout=30\n",
    "            )\n",
    "            if result.returncode == 0:\n",
    "                return True, \"Success\"\n",
    "        except FileNotFoundError:\n",
    "            pass  # docker compose/docker-compose not found, try next method\n",
    "        except Exception as e:\n",
    "            pass  # Try next method\n",
    "    \n",
    "    # Method 2: Try docker exec (fallback)\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\n",
    "                \"docker\", \"exec\", \"-i\", \"wosa-timescaledb\",\n",
    "                \"psql\", \"-U\", db_user, \"-d\", db_name\n",
    "            ],\n",
    "            input=sql_path.read_text(),\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=30\n",
    "        )\n",
    "        if result.returncode == 0:\n",
    "            return True, \"Success\"\n",
    "    except FileNotFoundError:\n",
    "        pass  # docker not found, try next method\n",
    "    except Exception as e:\n",
    "        pass  # Try next method\n",
    "    \n",
    "    # Method 3: Fall back to psql from host (requires PostgreSQL client)\n",
    "    try:\n",
    "        env = os.environ.copy()\n",
    "        env[\"PGPASSWORD\"] = db_password\n",
    "        result = subprocess.run(\n",
    "            [\n",
    "                \"psql\",\n",
    "                \"-h\", db_host,\n",
    "                \"-p\", db_port,\n",
    "                \"-U\", db_user,\n",
    "                \"-d\", db_name,\n",
    "                \"-f\", str(sql_path)\n",
    "            ],\n",
    "            env=env,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=30\n",
    "        )\n",
    "        if result.returncode == 0:\n",
    "            return True, \"Success\"\n",
    "        else:\n",
    "            return False, result.stderr\n",
    "    except FileNotFoundError:\n",
    "        return False, \"psql not found. Install PostgreSQL client or use Docker Compose method.\"\n",
    "    except Exception as e:\n",
    "        return False, f\"All methods failed: {str(e)}\"\n",
    "\n",
    "def setup_database():\n",
    "    \"\"\"Run all database migrations.\"\"\"\n",
    "    print(\"üóÑÔ∏è  Database Setup and Migrations\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    migrations = [\n",
    "        (\"data/postgres/000_schema.sql\", \"Core schema\"),\n",
    "        (\"data/postgres/001_equipment_schema.sql\", \"Equipment schema\"),\n",
    "        (\"data/postgres/002_document_schema.sql\", \"Document schema\"),\n",
    "        (\"data/postgres/004_inventory_movements_schema.sql\", \"Inventory movements schema\"),\n",
    "        (\"scripts/setup/create_model_tracking_tables.sql\", \"Model tracking tables\"),\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nüìã Running migrations...\\n\")\n",
    "    \n",
    "    for sql_file, description in migrations:\n",
    "        print(f\"  üîÑ {description}...\", end=\" \")\n",
    "        success, message = run_migration(sql_file)\n",
    "        if success:\n",
    "            print(\"‚úÖ\")\n",
    "        else:\n",
    "            print(f\"‚ùå\\n     Error: {message}\")\n",
    "            print(f\"\\nüí° Try running manually:\")\n",
    "            print(f\"   # Using Docker Compose (recommended):\")\n",
    "            # Determine which compose command to show\n",
    "            compose_cmd = \"docker compose\"\n",
    "            try:\n",
    "                subprocess.run([\"docker\", \"compose\", \"version\"], capture_output=True, timeout=2, check=True)\n",
    "            except:\n",
    "                compose_cmd = \"docker-compose\"\n",
    "            print(f\"   {compose_cmd} -f deploy/compose/docker-compose.dev.yaml exec -T timescaledb psql -U warehouse -d warehouse < {sql_file}\")\n",
    "            print(f\"   # Or using psql (requires PostgreSQL client):\")\n",
    "            print(f\"   PGPASSWORD=${{POSTGRES_PASSWORD:-changeme}} psql -h localhost -p 5435 -U warehouse -d warehouse -f {sql_file}\")\n",
    "            return False\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"‚úÖ Database migrations completed successfully!\")\n",
    "    return True\n",
    "\n",
    "# Run migrations\n",
    "setup_database()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Create Default Users\n",
    "\n",
    "Create the default admin user for accessing the application.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_project_root():\n",
    "    \"\"\"Get project root directory, detecting it if needed.\n",
    "    \n",
    "    This function works regardless of where the notebook is opened from.\n",
    "    It stores the result in builtins so it persists across cells.\n",
    "    \"\"\"\n",
    "    import builtins\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    \n",
    "    # Check if already stored\n",
    "    if hasattr(builtins, '__project_root__'):\n",
    "        return builtins.__project_root__\n",
    "    \n",
    "    # Try to find project root\n",
    "    current = Path.cwd()\n",
    "    \n",
    "    # Check if we're already in project root\n",
    "    if (current / \"src\" / \"api\").exists() and (current / \"scripts\" / \"setup\").exists():\n",
    "        project_root = current\n",
    "    # Check if we're in notebooks/setup/ (go up 2 levels)\n",
    "    elif (current / \"complete_setup_guide.ipynb\").exists() or current.name == \"setup\":\n",
    "        project_root = current.parent.parent\n",
    "    # Check if we're in notebooks/ (go up 1 level)\n",
    "    elif current.name == \"notebooks\":\n",
    "        project_root = current.parent\n",
    "    else:\n",
    "        # Try going up from current directory\n",
    "        project_root = current\n",
    "        for parent in current.parents:\n",
    "            if (parent / \"src\" / \"api\").exists() and (parent / \"scripts\" / \"setup\").exists():\n",
    "                project_root = parent\n",
    "                break\n",
    "    \n",
    "    # Change to project root and store it\n",
    "    os.chdir(project_root)\n",
    "    builtins.__project_root__ = project_root\n",
    "    return project_root\n",
    "\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def create_default_users():\n",
    "    \"\"\"Create default admin user.\"\"\"\n",
    "    # Get project root (works from any directory)\n",
    "    project_root = get_project_root()\n",
    "    print(\"üë§ Creating Default Users\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    script_path = project_root / \"scripts/setup/create_default_users.py\"\n",
    "    if not script_path.exists():\n",
    "        print(f\"‚ùå Script not found: {script_path}\")\n",
    "        return False\n",
    "    \n",
    "    # Determine Python path\n",
    "    if sys.platform == \"win32\":\n",
    "        python_path = Path(\"env\") / \"Scripts\" / \"python.exe\"\n",
    "    else:\n",
    "        python_path = Path(\"env\") / \"bin\" / \"python\"\n",
    "    \n",
    "    if not python_path.exists():\n",
    "        print(f\"‚ùå Python not found at: {python_path}\")\n",
    "        print(\"   Make sure virtual environment is set up (Step 3)\")\n",
    "        return False\n",
    "    \n",
    "    print(\"\\nüîÑ Running user creation script...\")\n",
    "    result = subprocess.run(\n",
    "        [str(python_path), str(script_path)],\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"‚úÖ Default users created successfully\")\n",
    "        print(\"\\nüìã Default Credentials:\")\n",
    "        print(\"   Username: admin\")\n",
    "        print(\"   Password: (check DEFAULT_ADMIN_PASSWORD in .env, default: 'changeme')\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"‚ùå Failed to create users: {result.stderr}\")\n",
    "        print(\"\\nüí° Try running manually:\")\n",
    "        print(f\"   source env/bin/activate  # or env\\\\Scripts\\\\activate on Windows\")\n",
    "        print(f\"   python {script_path}\")\n",
    "        return False\n",
    "\n",
    "# Create users\n",
    "create_default_users()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Generate Demo Data (Optional)\n",
    "\n",
    "Generate sample data for testing and demonstration purposes. This includes:\n",
    "- Equipment assets\n",
    "- Inventory items\n",
    "- Historical demand data (for forecasting)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def generate_demo_data():\n",
    "    \"\"\"Generate demo data for testing.\"\"\"\n",
    "    print(\"üìä Generating Demo Data\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Determine Python path\n",
    "    if sys.platform == \"win32\":\n",
    "        python_path = Path(\"env\") / \"Scripts\" / \"python.exe\"\n",
    "    else:\n",
    "        python_path = Path(\"env\") / \"bin\" / \"python\"\n",
    "    \n",
    "    if not python_path.exists():\n",
    "        print(f\"‚ùå Python not found at: {python_path}\")\n",
    "        return False\n",
    "    \n",
    "    scripts = [\n",
    "        (\"scripts/data/quick_demo_data.py\", \"Quick demo data (equipment, inventory)\"),\n",
    "        (\"scripts/data/generate_historical_demand.py\", \"Historical demand data (for forecasting)\"),\n",
    "    ]\n",
    "    \n",
    "    for script_path, description in scripts:\n",
    "        script = Path(script_path)\n",
    "        if not script.exists():\n",
    "            print(f\"‚ö†Ô∏è  Script not found: {script_path} (skipping)\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nüîÑ {description}...\")\n",
    "        result = subprocess.run(\n",
    "            [str(python_path), str(script)],\n",
    "            capture_output=True,\n",
    "            text=True\n",
    "        )\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(f\"‚úÖ {description} generated\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  {description} had issues: {result.stderr[:200]}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"‚úÖ Demo data generation complete!\")\n",
    "    print(\"\\nüí° You can skip this step if you don't need demo data.\")\n",
    "    return True\n",
    "\n",
    "# Generate demo data\n",
    "generate_demo_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: üöÄ (Optional) Install RAPIDS GPU Acceleration\n",
    "\n",
    "**This step is OPTIONAL** but highly recommended if you have an NVIDIA GPU. RAPIDS enables **10-100x faster forecasting** with GPU acceleration.\n",
    "\n",
    "### Benefits\n",
    "- ‚ö° **10-100x faster** training and inference\n",
    "- üéØ **Automatic GPU detection** - Falls back to CPU if GPU unavailable\n",
    "- üîÑ **Zero code changes** - Works automatically when installed\n",
    "- üìä **Full model support** - Random Forest, Linear Regression, SVR via cuML; XGBoost via CUDA\n",
    "\n",
    "### Requirements\n",
    "- **NVIDIA GPU** with CUDA 12.x support\n",
    "- **CUDA Compute Capability 7.0+** (Volta, Turing, Ampere, Ada, Hopper)\n",
    "- **16GB+ GPU memory** (recommended)\n",
    "- **Python 3.9-3.11**\n",
    "\n",
    "**Note**: If you don't have a GPU or prefer not to install RAPIDS, you can skip this step. The application will work perfectly on CPU with automatic fallback.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def check_gpu_availability():\n",
    "    \"\"\"Check if NVIDIA GPU is available.\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['nvidia-smi'],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=5\n",
    "        )\n",
    "        if result.returncode == 0:\n",
    "            return True, result.stdout\n",
    "        return False, None\n",
    "    except (FileNotFoundError, subprocess.TimeoutExpired):\n",
    "        return False, None\n",
    "\n",
    "def check_rapids_installed():\n",
    "    \"\"\"Check if RAPIDS is already installed.\"\"\"\n",
    "    try:\n",
    "        import cudf\n",
    "        import cuml\n",
    "        return True, f\"cuDF {cudf.__version__}, cuML {cuml.__version__}\"\n",
    "    except ImportError:\n",
    "        return False, None\n",
    "\n",
    "def install_rapids():\n",
    "    \"\"\"Install RAPIDS cuDF and cuML.\"\"\"\n",
    "    print(\"üì¶ Installing RAPIDS cuDF and cuML...\")\n",
    "    print(\"   This may take several minutes (packages are ~2GB)...\")\n",
    "    \n",
    "    try:\n",
    "        # Install RAPIDS\n",
    "        result = subprocess.run(\n",
    "            [\n",
    "                sys.executable, '-m', 'pip', 'install',\n",
    "                '--extra-index-url=https://pypi.nvidia.com',\n",
    "                'cudf-cu12', 'cuml-cu12'\n",
    "            ],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=1800  # 30 minutes timeout\n",
    "        )\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            return True, \"RAPIDS installed successfully\"\n",
    "        else:\n",
    "            return False, f\"Installation failed: {result.stderr}\"\n",
    "    except subprocess.TimeoutExpired:\n",
    "        return False, \"Installation timed out (took longer than 30 minutes)\"\n",
    "    except Exception as e:\n",
    "        return False, f\"Installation error: {str(e)}\"\n",
    "\n",
    "# Check GPU availability\n",
    "print(\"üîç Checking GPU Availability...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "gpu_available, gpu_info = check_gpu_availability()\n",
    "if gpu_available:\n",
    "    print(\"‚úÖ NVIDIA GPU detected!\")\n",
    "    print(\"\\nGPU Information:\")\n",
    "    print(gpu_info.split('\\n')[0:5])  # Show first few lines\n",
    "    print(\"\\nüí° You can install RAPIDS for GPU acceleration!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  NVIDIA GPU not detected or nvidia-smi not available\")\n",
    "    print(\"   RAPIDS installation is optional - the system will use CPU fallback\")\n",
    "\n",
    "# Check if RAPIDS is already installed\n",
    "print(\"\\nüîç Checking RAPIDS Installation...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "rapids_installed, rapids_version = check_rapids_installed()\n",
    "if rapids_installed:\n",
    "    print(f\"‚úÖ RAPIDS is already installed: {rapids_version}\")\n",
    "    print(\"   GPU acceleration will be enabled automatically!\")\n",
    "else:\n",
    "    print(\"‚ùå RAPIDS is not installed\")\n",
    "    print(\"   The system will use CPU fallback (still works great!)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"\\nüìù Next Steps:\")\n",
    "if not rapids_installed and gpu_available:\n",
    "    print(\"   ‚Ä¢ Run the next cell to install RAPIDS (optional but recommended)\")\n",
    "    print(\"   ‚Ä¢ Or skip to start the backend server\")\n",
    "elif not gpu_available:\n",
    "    print(\"   ‚Ä¢ GPU not detected - skipping RAPIDS installation\")\n",
    "    print(\"   ‚Ä¢ System will use CPU fallback (works perfectly!)\")\n",
    "    print(\"   ‚Ä¢ Proceed to start the backend server\")\n",
    "else:\n",
    "    print(\"   ‚Ä¢ RAPIDS is already installed - proceed to start the backend server\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Install RAPIDS for GPU acceleration\n",
    "# Uncomment and run this cell if you want to install RAPIDS\n",
    "\n",
    "# Check if we should install\n",
    "gpu_available, _ = check_gpu_availability()\n",
    "rapids_installed, _ = check_rapids_installed()\n",
    "\n",
    "if rapids_installed:\n",
    "    print(\"‚úÖ RAPIDS is already installed - no need to reinstall!\")\n",
    "elif not gpu_available:\n",
    "    print(\"‚ö†Ô∏è  GPU not detected. RAPIDS installation is not recommended.\")\n",
    "    print(\"   The system will work perfectly with CPU fallback.\")\n",
    "    print(\"   If you're sure you have a GPU, you can still install RAPIDS.\")\n",
    "    print(\"\\n   To install anyway, uncomment the install_rapids() call below.\")\n",
    "else:\n",
    "    print(\"üöÄ Ready to install RAPIDS!\")\n",
    "    print(\"   This will install:\")\n",
    "    print(\"   ‚Ä¢ cuDF (GPU-accelerated DataFrames)\")\n",
    "    print(\"   ‚Ä¢ cuML (GPU-accelerated Machine Learning)\")\n",
    "    print(\"   ‚Ä¢ Estimated time: 5-15 minutes\")\n",
    "    print(\"   ‚Ä¢ Estimated size: ~2GB\")\n",
    "    print(\"\\n   Uncomment the line below to proceed with installation:\")\n",
    "    print(\"   install_rapids()\")\n",
    "\n",
    "# Uncomment the line below to install RAPIDS:\n",
    "# success, message = install_rapids()\n",
    "# if success:\n",
    "#     print(f\"‚úÖ {message}\")\n",
    "#     print(\"\\nüîç Verifying installation...\")\n",
    "#     rapids_installed, rapids_version = check_rapids_installed()\n",
    "#     if rapids_installed:\n",
    "#         print(f\"‚úÖ RAPIDS verified: {rapids_version}\")\n",
    "#         print(\"   GPU acceleration will be enabled automatically!\")\n",
    "#     else:\n",
    "#         print(\"‚ö†Ô∏è  Installation completed but verification failed\")\n",
    "# else:\n",
    "#     print(f\"‚ùå {message}\")\n",
    "#     print(\"\\nüí° Don't worry! The system will work perfectly with CPU fallback.\")\n",
    "#     print(\"   You can try installing RAPIDS later if needed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Start Backend Server\n",
    "\n",
    "Now we'll start the FastAPI backend server. The server will run on port 8001 by default.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "def check_port(port):\n",
    "    \"\"\"Check if a port is in use.\"\"\"\n",
    "    import socket\n",
    "    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    result = sock.connect_ex(('localhost', port))\n",
    "    sock.close()\n",
    "    return result == 0\n",
    "\n",
    "def start_backend():\n",
    "    \"\"\"Start the backend server.\"\"\"\n",
    "    print(\"üöÄ Starting Backend Server\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    port = 8001\n",
    "    \n",
    "    # Check if port is already in use\n",
    "    if check_port(port):\n",
    "        print(f\"‚ö†Ô∏è  Port {port} is already in use!\")\n",
    "        print(\"   The backend may already be running.\")\n",
    "        print(f\"   Check: http://localhost:{port}/health\")\n",
    "        return True\n",
    "    \n",
    "    # Determine Python path and environment\n",
    "    # Check if we're already in the venv\n",
    "    in_venv = hasattr(sys, 'real_prefix') or (hasattr(sys, 'base_prefix') and sys.base_prefix != sys.prefix)\n",
    "    \n",
    "    if in_venv and ('env' in str(sys.prefix) or 'venv' in str(sys.prefix)):\n",
    "        # Already in venv, use current Python\n",
    "        python_path = Path(sys.executable)\n",
    "        venv_path = Path(sys.prefix)\n",
    "        print(f\"‚úÖ Using virtual environment: {venv_path}\")\n",
    "    else:\n",
    "        # Not in venv, use venv Python\n",
    "        if sys.platform == \"win32\":\n",
    "            python_path = Path(\"env\") / \"Scripts\" / \"python.exe\"\n",
    "            venv_path = Path(\"env\")\n",
    "        else:\n",
    "            python_path = Path(\"env\") / \"bin\" / \"python\"\n",
    "            venv_path = Path(\"env\")\n",
    "        \n",
    "        if not python_path.exists():\n",
    "            print(f\"‚ùå Python not found at: {python_path}\")\n",
    "            print(\"   Make sure virtual environment is set up (Step 3)\")\n",
    "            return False\n",
    "        \n",
    "        print(f\"‚úÖ Using virtual environment: {venv_path.absolute()}\")\n",
    "    \n",
    "    print(f\"\\nüîÑ Starting FastAPI server on port {port}...\")\n",
    "    print(\"   This will run in the background.\")\n",
    "    print(\"   To stop: Find the process and kill it, or restart the kernel.\")\n",
    "    print(\"\\nüìã Server Endpoints:\")\n",
    "    print(f\"   ‚Ä¢ API: http://localhost:{port}\")\n",
    "    print(f\"   ‚Ä¢ Docs: http://localhost:{port}/docs\")\n",
    "    print(f\"   ‚Ä¢ Health: http://localhost:{port}/health\")\n",
    "    \n",
    "    # Start server in background\n",
    "    import threading\n",
    "    import os\n",
    "    \n",
    "    def run_server():\n",
    "        # Prepare environment variables for the subprocess\n",
    "        env = os.environ.copy()\n",
    "        env['VIRTUAL_ENV'] = str(venv_path.absolute())\n",
    "        \n",
    "        # Update PATH to include venv bin directory\n",
    "        if sys.platform == \"win32\":\n",
    "            venv_bin = venv_path / \"Scripts\"\n",
    "        else:\n",
    "            venv_bin = venv_path / \"bin\"\n",
    "        \n",
    "        # Prepend venv bin to PATH\n",
    "        current_path = env.get('PATH', '')\n",
    "        env['PATH'] = f\"{venv_bin.absolute()}{os.pathsep}{current_path}\"\n",
    "        \n",
    "        # Set PYTHONPATH to include project root\n",
    "        project_root = Path.cwd().absolute()\n",
    "        pythonpath = env.get('PYTHONPATH', '')\n",
    "        if pythonpath:\n",
    "            env['PYTHONPATH'] = f\"{project_root}{os.pathsep}{pythonpath}\"\n",
    "        else:\n",
    "            env['PYTHONPATH'] = str(project_root)\n",
    "        \n",
    "        subprocess.run(\n",
    "            [\n",
    "                str(python_path),\n",
    "                \"-m\", \"uvicorn\",\n",
    "                \"src.api.app:app\",\n",
    "                \"--reload\",\n",
    "                \"--port\", str(port),\n",
    "                \"--host\", \"0.0.0.0\"\n",
    "            ],\n",
    "            cwd=Path.cwd(),\n",
    "            env=env\n",
    "        )\n",
    "    \n",
    "    server_thread = threading.Thread(target=run_server, daemon=True)\n",
    "    server_thread.start()\n",
    "    \n",
    "    # Wait a bit and check if server started\n",
    "    print(\"\\n‚è≥ Waiting for server to start...\")\n",
    "    for i in range(10):\n",
    "        time.sleep(1)\n",
    "        if check_port(port):\n",
    "            print(f\"‚úÖ Backend server is running on port {port}!\")\n",
    "            return True\n",
    "        print(f\"   Waiting... ({i+1}/10)\")\n",
    "    \n",
    "    print(\"‚ö†Ô∏è  Server may still be starting. Check manually:\")\n",
    "    print(f\"   curl http://localhost:{port}/health\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "print(\"üí° To start the backend server, you have two options:\")\n",
    "print(\"\\n1Ô∏è‚É£  Run in this notebook (uncomment below):\")\n",
    "print(\"   # start_backend()\")\n",
    "print(\"\\n2Ô∏è‚É£  Run in a separate terminal (recommended):\")\n",
    "print(\"   ./scripts/start_server.sh\")\n",
    "print(\"\\n   Or manually:\")\n",
    "print(\"   source env/bin/activate\")\n",
    "print(\"   python -m uvicorn src.api.app:app --reload --port 8001 --host 0.0.0.0\")\n",
    "\n",
    "# Uncomment the line below to start the backend server in this notebook\n",
    "# start_backend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Start Frontend\n",
    "\n",
    "The frontend is a React application that runs on port 3001. You'll need to install Node.js dependencies first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "def setup_frontend():\n",
    "    \"\"\"Setup and start the frontend.\"\"\"\n",
    "    print(\"üé® Frontend Setup and Start\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    frontend_dir = Path(\"src/ui/web\")\n",
    "    if not frontend_dir.exists():\n",
    "        print(f\"‚ùå Frontend directory not found: {frontend_dir}\")\n",
    "        return False\n",
    "    \n",
    "    # Check if node_modules exists\n",
    "    node_modules = frontend_dir / \"node_modules\"\n",
    "    if not node_modules.exists():\n",
    "        print(\"\\nüì¶ Installing Node.js dependencies...\")\n",
    "        print(\"   This may take a few minutes...\")\n",
    "        \n",
    "        result = subprocess.run(\n",
    "            [\"npm\", \"install\"],\n",
    "            cwd=frontend_dir,\n",
    "            capture_output=True,\n",
    "            text=True\n",
    "        )\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"‚úÖ Dependencies installed\")\n",
    "        else:\n",
    "            print(f\"‚ùå Failed to install dependencies: {result.stderr}\")\n",
    "            return False\n",
    "    else:\n",
    "        print(\"‚úÖ Node.js dependencies already installed\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"‚úÖ Frontend setup complete!\")\n",
    "    print(\"\\nüìã To start the frontend, run in a separate terminal:\")\n",
    "    print(f\"   cd {frontend_dir}\")\n",
    "    print(\"   npm start\")\n",
    "    print(\"\\n   The frontend will be available at: http://localhost:3001\")\n",
    "    print(\"   Default login: admin / (check DEFAULT_ADMIN_PASSWORD in .env)\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Setup frontend\n",
    "setup_frontend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 13: Verification\n",
    "\n",
    "Let's verify that everything is set up correctly and the services are running.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import subprocess\n",
    "import socket\n",
    "from pathlib import Path\n",
    "\n",
    "def check_service(host, port, name):\n",
    "    \"\"\"Check if a service is running on a port.\"\"\"\n",
    "    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    sock.settimeout(2)\n",
    "    result = sock.connect_ex((host, port))\n",
    "    sock.close()\n",
    "    return result == 0\n",
    "\n",
    "def verify_setup():\n",
    "    \"\"\"Verify the complete setup.\"\"\"\n",
    "    print(\"‚úÖ Verification Checklist\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    checks = {\n",
    "        \"Virtual Environment\": Path(\"env\").exists(),\n",
    "        \"Environment File\": Path(\".env\").exists(),\n",
    "        \"Backend Port (8001)\": check_service(\"localhost\", 8001, \"Backend\"),\n",
    "        \"Frontend Port (3001)\": check_service(\"localhost\", 3001, \"Frontend\"),\n",
    "        \"TimescaleDB (5435)\": check_service(\"localhost\", 5435, \"TimescaleDB\"),\n",
    "        \"Redis (6379)\": check_service(\"localhost\", 6379, \"Redis\"),\n",
    "        \"Milvus (19530)\": check_service(\"localhost\", 19530, \"Milvus\"),\n",
    "    }\n",
    "    \n",
    "    print(\"\\nüîç Service Status:\\n\")\n",
    "    for service, status in checks.items():\n",
    "        status_icon = \"‚úÖ\" if status else \"‚ùå\"\n",
    "        print(f\"  {status_icon} {service:25} {'Running' if status else 'Not Running'}\")\n",
    "    \n",
    "    # Test backend health endpoint\n",
    "    print(\"\\nüè• Backend Health Check:\")\n",
    "    try:\n",
    "        response = requests.get(\"http://localhost:8001/health\", timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            print(\"  ‚úÖ Backend is healthy\")\n",
    "            health_data = response.json()\n",
    "            if isinstance(health_data, dict):\n",
    "                print(f\"     Status: {health_data.get('status', 'unknown')}\")\n",
    "        else:\n",
    "            print(f\"  ‚ö†Ô∏è  Backend returned status {response.status_code}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"  ‚ùå Backend health check failed: {e}\")\n",
    "    \n",
    "    # Test API endpoint\n",
    "    print(\"\\nüîå API Endpoint Check:\")\n",
    "    try:\n",
    "        response = requests.get(\"http://localhost:8001/api/v1/version\", timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            print(\"  ‚úÖ API is accessible\")\n",
    "            version_data = response.json()\n",
    "            if isinstance(version_data, dict):\n",
    "                print(f\"     Version: {version_data.get('version', 'unknown')}\")\n",
    "        else:\n",
    "            print(f\"  ‚ö†Ô∏è  API returned status {response.status_code}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"  ‚ùå API check failed: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    \n",
    "    all_checks = all(checks.values())\n",
    "    if all_checks:\n",
    "        print(\"üéâ All checks passed! Your setup is complete!\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Some checks failed. Please review the status above.\")\n",
    "    \n",
    "    print(\"\\nüìã Access Points:\")\n",
    "    print(\"   ‚Ä¢ Frontend: http://localhost:3001\")\n",
    "    print(\"   ‚Ä¢ Backend API: http://localhost:8001\")\n",
    "    print(\"   ‚Ä¢ API Docs: http://localhost:8001/docs\")\n",
    "    print(\"   ‚Ä¢ Health Check: http://localhost:8001/health\")\n",
    "    \n",
    "    return all_checks\n",
    "\n",
    "# Run verification\n",
    "verify_setup()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 14: Troubleshooting\n",
    "\n",
    "### Common Issues and Solutions\n",
    "\n",
    "#### 1. Port Already in Use\n",
    "\n",
    "If a port is already in use, you can either:\n",
    "- Stop the existing service\n",
    "- Change the port in the configuration\n",
    "\n",
    "**Backend (port 8001):**\n",
    "```bash\n",
    "# Find and kill process\n",
    "lsof -ti:8001 | xargs kill -9\n",
    "# Or change port: export PORT=8002\n",
    "```\n",
    "\n",
    "**Frontend (port 3001):**\n",
    "```bash\n",
    "# Find and kill process\n",
    "lsof -ti:3001 | xargs kill -9\n",
    "# Or change port: PORT=3002 npm start\n",
    "```\n",
    "\n",
    "#### 2. Database Connection Errors\n",
    "\n",
    "**Check if TimescaleDB is running:**\n",
    "```bash\n",
    "docker ps | grep timescaledb\n",
    "```\n",
    "\n",
    "**Test connection:**\n",
    "```bash\n",
    "PGPASSWORD=${POSTGRES_PASSWORD:-changeme} psql -h localhost -p 5435 -U warehouse -d warehouse -c \"SELECT 1;\"\n",
    "```\n",
    "\n",
    "#### 3. Missing Dependencies\n",
    "\n",
    "**Python:**\n",
    "```bash\n",
    "source env/bin/activate\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "**Node.js:**\n",
    "```bash\n",
    "cd src/ui/web\n",
    "npm install\n",
    "```\n",
    "\n",
    "#### 4. NVIDIA API Key Issues\n",
    "\n",
    "- Verify your API key at https://build.nvidia.com/\n",
    "- Check that `NVIDIA_API_KEY` is set in `.env`\n",
    "- Test the API key with a curl command (see DEPLOYMENT.md)\n",
    "\n",
    "#### 5. Node.js Version Issues\n",
    "\n",
    "If you see `Cannot find module 'node:path'`:\n",
    "- Upgrade to Node.js 18.17.0+ (recommended: 20.0.0+)\n",
    "- Check version: `node --version`\n",
    "- Use nvm to switch versions: `nvm use 20`\n",
    "\n",
    "### Getting Help\n",
    "\n",
    "- **Documentation**: See `DEPLOYMENT.md` for detailed deployment guide\n",
    "- **Issues**: Check GitHub Issues for known problems\n",
    "- **Logs**: Check service logs for error messages\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. ‚úÖ Access the frontend at http://localhost:3001\n",
    "2. ‚úÖ Log in with admin credentials\n",
    "3. ‚úÖ Explore the features:\n",
    "   - Chat Assistant\n",
    "   - Equipment Management\n",
    "   - Forecasting\n",
    "   - Operations\n",
    "   - Safety\n",
    "   - Document Extraction\n",
    "\n",
    "**Congratulations! Your Warehouse Operational Assistant is now set up and running! üéâ**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Summary\n",
    "print(\"üìã Setup Summary\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n‚úÖ Completed Steps:\")\n",
    "print(\"   1. Prerequisites verified\")\n",
    "print(\"   2. Repository setup\")\n",
    "print(\"   3. Environment configured\")\n",
    "print(\"   4. API keys configured\")\n",
    "print(\"   5. Infrastructure services started\")\n",
    "print(\"   6. Database migrations completed\")\n",
    "print(\"   7. Default users created\")\n",
    "print(\"   8. Demo data generated (optional)\")\n",
    "print(\"\\nüöÄ Next Steps:\")\n",
    "print(\"   1. Start backend: ./scripts/start_server.sh\")\n",
    "print(\"   2. Start frontend: cd src/ui/web && npm start\")\n",
    "print(\"   3. Access: http://localhost:3001\")\n",
    "print(\"\\nüìö Documentation:\")\n",
    "print(\"   ‚Ä¢ DEPLOYMENT.md - Detailed deployment guide\")\n",
    "print(\"   ‚Ä¢ README.md - Project overview\")\n",
    "print(\"   ‚Ä¢ docs/ - Additional documentation\")\n",
    "print(\"\\nüéâ Setup complete! Happy coding!\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
