{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Setup Guide - Warehouse Operational Assistant\n",
    "\n",
    "This notebook provides a **complete, step-by-step setup guide** from cloning the repository to running the full application with backend and frontend.\n",
    "\n",
    "## Overview\n",
    "\n",
    "This guide will walk you through:\n",
    "1. ‚úÖ Prerequisites verification\n",
    "2. üì¶ Repository setup\n",
    "3. üîß Environment configuration\n",
    "4. üîë NVIDIA API key setup\n",
    "5. üóÑÔ∏è Database setup and migrations\n",
    "6. üöÄ Starting backend and frontend services\n",
    "7. ‚úÖ Verification and testing\n",
    "\n",
    "**Estimated Time:** 30-45 minutes\n",
    "\n",
    "**Requirements:**\n",
    "- Python 3.9+\n",
    "- Node.js 20.0.0+ (or minimum 18.17.0+)\n",
    "- Docker & Docker Compose (for infrastructure services)\n",
    "- Git\n",
    "- NVIDIA API key (free account at https://build.nvidia.com/)\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Prerequisites Check](#prerequisites-check)\n",
    "2. [Repository Setup](#repository-setup)\n",
    "3. [Environment Setup](#environment-setup)\n",
    "4. [API Key Configuration (NVIDIA & Brev)](#api-key-configuration-nvidia--brev)\n",
    "5. [Environment Variables Setup](#environment-variables-setup)\n",
    "6. [Infrastructure Services](#infrastructure-services)\n",
    "7. [Database Setup](#database-setup)\n",
    "8. [Create Default Users](#create-default-users)\n",
    "9. [Generate Demo Data](#generate-demo-data)\n",
    "10. [üöÄ (Optional) Install RAPIDS GPU Acceleration](#optional-install-rapids-gpu-acceleration)\n",
    "11. [Start Backend Server](#start-backend-server)\n",
    "12. [Start Frontend](#start-frontend)\n",
    "13. [Verification](#verification)\n",
    "14. [Troubleshooting](#troubleshooting)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Prerequisites Check\n",
    "\n",
    "Let's verify that all required tools are installed and meet version requirements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "def check_command(command, min_version=None, version_flag='--version'):\n",
    "    \"\"\"Check if a command exists and optionally verify version.\"\"\"\n",
    "    if not shutil.which(command):\n",
    "        return False, None, f\"‚ùå {command} is not installed\"\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [command, version_flag],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=5\n",
    "        )\n",
    "        version = result.stdout.strip() or result.stderr.strip()\n",
    "        return True, version, f\"‚úÖ {command} found: {version}\"\n",
    "    except Exception as e:\n",
    "        return False, None, f\"‚ö†Ô∏è  {command} found but version check failed: {e}\"\n",
    "\n",
    "def check_python_version():\n",
    "    \"\"\"Check Python version.\"\"\"\n",
    "    version = sys.version_info\n",
    "    version_str = f\"{version.major}.{version.minor}.{version.micro}\"\n",
    "    \n",
    "    if version.major < 3 or (version.major == 3 and version.minor < 9):\n",
    "        return False, version_str, f\"‚ùå Python {version_str} is too old. Required: Python 3.9+\"\n",
    "    return True, version_str, f\"‚úÖ Python {version_str} meets requirements\"\n",
    "\n",
    "def check_node_version():\n",
    "    \"\"\"Check Node.js version.\"\"\"\n",
    "    exists, version, message = check_command('node')\n",
    "    if not exists:\n",
    "        return exists, None, message\n",
    "    \n",
    "    # Extract version number\n",
    "    try:\n",
    "        version_str = version.split()[1] if ' ' in version else version.replace('v', '')\n",
    "        parts = version_str.split('.')\n",
    "        major = int(parts[0])\n",
    "        minor = int(parts[1]) if len(parts) > 1 else 0\n",
    "        patch = int(parts[2]) if len(parts) > 2 else 0\n",
    "        \n",
    "        # Check minimum: 18.17.0, Recommended: 20.0.0+\n",
    "        if major < 18:\n",
    "            return False, version_str, f\"‚ùå Node.js {version_str} is too old. Required: 18.17.0+ (Recommended: 20.0.0+)\"\n",
    "        elif major == 18 and (minor < 17 or (minor == 17 and patch < 0)):\n",
    "            return False, version_str, f\"‚ùå Node.js {version_str} is too old. Required: 18.17.0+ (Recommended: 20.0.0+)\"\n",
    "        elif major == 18:\n",
    "            return True, version_str, f\"‚ö†Ô∏è  Node.js {version_str} meets minimum (18.17.0+). Recommended: 20.0.0+\"\n",
    "        else:\n",
    "            return True, version_str, f\"‚úÖ Node.js {version_str} meets requirements (Recommended: 20.0.0+)\"\n",
    "    except:\n",
    "        return True, version, f\"‚úÖ Node.js found: {version}\"\n",
    "\n",
    "print(\"üîç Checking Prerequisites...\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check Python\n",
    "ok, version, msg = check_python_version()\n",
    "print(msg)\n",
    "\n",
    "# Check Node.js\n",
    "ok, version, msg = check_node_version()\n",
    "print(msg)\n",
    "\n",
    "# Check npm\n",
    "ok, version, msg = check_command('npm')\n",
    "print(msg)\n",
    "\n",
    "# Check Git\n",
    "ok, version, msg = check_command('git')\n",
    "print(msg)\n",
    "\n",
    "# Check Docker\n",
    "ok, version, msg = check_command('docker')\n",
    "print(msg)\n",
    "\n",
    "# Check Docker Compose\n",
    "ok, version, msg = check_command('docker-compose')\n",
    "if not ok:\n",
    "    ok, version, msg = check_command('docker', version_flag='compose version')\n",
    "print(msg)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"\\n‚úÖ Prerequisites check complete!\")\n",
    "print(\"\\nüìù If any checks failed, please install the missing tools before proceeding.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Repository Setup\n",
    "\n",
    "If you haven't cloned the repository yet, follow the instructions below. If you're already in the repository, you can skip this step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osfrom pathlib import Path# Detect project root: navigate from current directory to find project root# This handles cases where notebook is opened from notebooks/setup/ or project rootdef find_project_root():    \"\"\"Find the project root directory.\"\"\"    current = Path.cwd()        # Check if we're already in project root    if (current / \"src\" / \"api\").exists() and (current / \"scripts\" / \"setup\").exists():        return current        # Check if we're in notebooks/setup/ (go up 2 levels)    if (current / \"complete_setup_guide.ipynb\").exists() or current.name == \"setup\":        parent = current.parent.parent        if (parent / \"src\" / \"api\").exists() and (parent / \"scripts\" / \"setup\").exists():            return parent        # Check if we're in notebooks/ (go up 1 level)    if current.name == \"notebooks\":        parent = current.parent        if (parent / \"src\" / \"api\").exists() and (parent / \"scripts\" / \"setup\").exists():            return parent        # Try going up from current directory    for parent in current.parents:        if (parent / \"src\" / \"api\").exists() and (parent / \"scripts\" / \"setup\").exists():            return parent        # Fallback: return current directory    return current# Find and change to project rootproject_root = find_project_root()is_in_repo = (project_root / \"src\" / \"api\").exists() and (project_root / \"scripts\" / \"setup\").exists()if is_in_repo:    # Change to project root so all subsequent operations work correctly    os.chdir(project_root)    # Store project_root globally so other cells can use it    import builtins    builtins.__project_root__ = project_root    builtins.__find_project_root__ = find_project_root    print(\"‚úÖ You're already in the Warehouse Operational Assistant repository!\")    print(f\"   Project root: {project_root}\")    print(f\"   Changed working directory to: {Path.cwd()}\")    print(\"\\nüìù You can skip the cloning step and proceed to environment setup.\")else:    print(\"üì¶ Repository Setup Instructions\")    print(\"=\" * 60)    print(\"\\nTo clone the repository, run the following command in your terminal:\")    print(\"\\n```bash\")    print(\"git clone https://github.com/NVIDIA-AI-Blueprints/Multi-Agent-Intelligent-Warehouse.git\")    print(\"cd Multi-Agent-Intelligent-Warehouse\")    print(\"```\")    print(\"\\n‚ö†Ô∏è  After cloning, restart this notebook from the project root directory.\")    print(\"\\nAlternatively, if you want to clone it now, uncomment and run the cell below:\")    print(f\"\\nüìÅ Current directory: {Path.cwd()}\")print(f\"üìÅ Project root: {project_root}\")print(f\"üìÅ Expected structure: {project_root / 'src' / 'api'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the lines below to clone the repository automatically\n",
    "# WARNING: This will clone to the current directory\n",
    "\n",
    "# import subprocess\n",
    "# \n",
    "# repo_url = \"https://github.com/NVIDIA-AI-Blueprints/Multi-Agent-Intelligent-Warehouse.git\"\n",
    "# repo_name = \"Multi-Agent-Intelligent-Warehouse\"\n",
    "# \n",
    "# if not Path(repo_name).exists():\n",
    "#     print(f\"üì¶ Cloning repository from {repo_url}...\")\n",
    "#     subprocess.run([\"git\", \"clone\", repo_url], check=True)\n",
    "#     print(f\"‚úÖ Repository cloned to {Path.cwd() / repo_name}\")\n",
    "#     print(f\"\\n‚ö†Ô∏è  Please change directory and restart this notebook:\")\n",
    "#     print(f\"   cd {repo_name}\")\n",
    "#     print(f\"   jupyter notebook notebooks/setup/complete_setup_guide.ipynb\")\n",
    "# else:\n",
    "#     print(f\"‚úÖ Repository already exists at {Path.cwd() / repo_name}\")\n",
    "\n",
    "print(\"üí° To clone manually, use the command shown in the previous cell.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Environment Setup\n",
    "\n",
    "This step will:\n",
    "- Create a Python virtual environment\n",
    "- Install all Python dependencies\n",
    "- Verify the installation\n",
    "\n",
    "### ‚ö†Ô∏è Important: Virtual Environment and Jupyter Kernel\n",
    "\n",
    "**Best Practice:** For the smoothest experience, create the virtual environment **before** starting Jupyter:\n",
    "\n",
    "```bash\n",
    "# Option 1: Create venv first, then start Jupyter (RECOMMENDED)\n",
    "python3 -m venv env\n",
    "source env/bin/activate  # or env\\Scripts\\activate on Windows\n",
    "pip install jupyter ipykernel\n",
    "python -m ipykernel install --user --name=warehouse-assistant\n",
    "jupyter notebook notebooks/setup/complete_setup_guide.ipynb\n",
    "# Then select \"warehouse-assistant\" as the kernel\n",
    "```\n",
    "\n",
    "**Alternative:** You can create the venv inside this notebook (see below), but you'll need to:\n",
    "1. Create the venv (this cell)\n",
    "2. Install ipykernel in the new venv\n",
    "3. Restart the kernel and switch to the new venv kernel\n",
    "4. Continue with the rest of the setup\n",
    "\n",
    "**Note:** The next cell will show which Python/kernel you're currently using.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def run_command(cmd, check=True, shell=False):\n",
    "    \"\"\"Run a shell command and return the result.\"\"\"\n",
    "    if isinstance(cmd, str) and not shell:\n",
    "        cmd = cmd.split()\n",
    "    \n",
    "    result = subprocess.run(\n",
    "        cmd,\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        shell=shell,\n",
    "        check=check\n",
    "    )\n",
    "    return result.returncode == 0, result.stdout, result.stderr\n",
    "\n",
    "# Show current kernel info\n",
    "print(\"üîç Current Jupyter Kernel Information\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Working directory: {Path.cwd()}\")\n",
    "\n",
    "# Check if we're already in a virtual environment\n",
    "in_venv = hasattr(sys, 'real_prefix') or (hasattr(sys, 'base_prefix') and sys.base_prefix != sys.prefix)\n",
    "if in_venv:\n",
    "    print(f\"‚úÖ Already running in a virtual environment: {sys.prefix}\")\n",
    "    if 'env' in str(sys.prefix) or 'venv' in str(sys.prefix):\n",
    "        print(\"   This appears to be the project's virtual environment!\")\n",
    "        use_existing = True\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è  This is a different virtual environment\")\n",
    "        use_existing = False\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Not running in a virtual environment (using system Python)\")\n",
    "    use_existing = False\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# Check if virtual environment exists\n",
    "env_path = Path(\"env\")\n",
    "if env_path.exists():\n",
    "    print(\"‚úÖ Virtual environment directory 'env' already exists!\")\n",
    "    \n",
    "    if use_existing:\n",
    "        print(\"‚úÖ You're already using the project's virtual environment - perfect!\")\n",
    "        print(\"   You can skip the venv creation step and proceed.\")\n",
    "        skip_setup = True\n",
    "    else:\n",
    "        print(\"\\nüí° Options:\")\n",
    "        print(\"   1. Switch to the existing venv kernel (recommended)\")\n",
    "        print(\"   2. Recreate the virtual environment\")\n",
    "        print(\"   3. Continue with current kernel (not recommended)\")\n",
    "        \n",
    "        choice = input(\"\\n‚ùì What would you like to do? (1/2/3): \").strip()\n",
    "        \n",
    "        if choice == '1':\n",
    "            print(\"\\nüìù To switch kernels:\")\n",
    "            print(\"   1. Go to: Kernel ‚Üí Change Kernel ‚Üí warehouse-assistant\")\n",
    "            print(\"   2. Or install kernel now:\")\n",
    "            if sys.platform == \"win32\":\n",
    "                python_path = Path(\"env\") / \"Scripts\" / \"python.exe\"\n",
    "            else:\n",
    "                python_path = Path(\"env\") / \"bin\" / \"python\"\n",
    "            \n",
    "            if python_path.exists():\n",
    "                print(f\"   {python_path} -m ipykernel install --user --name=warehouse-assistant\")\n",
    "                install_kernel = input(\"\\n‚ùì Install kernel now? (y/N): \").strip().lower()\n",
    "                if install_kernel == 'y':\n",
    "                    success, _, _ = run_command([str(python_path), \"-m\", \"ipykernel\", \"install\", \"--user\", \"--name=warehouse-assistant\"])\n",
    "                    if success:\n",
    "                        print(\"‚úÖ Kernel installed! Please restart kernel and select 'warehouse-assistant'\")\n",
    "                    else:\n",
    "                        print(\"‚ùå Failed to install kernel\")\n",
    "            skip_setup = True\n",
    "        elif choice == '2':\n",
    "            import shutil\n",
    "            print(\"üóëÔ∏è  Removing existing virtual environment...\")\n",
    "            shutil.rmtree(env_path)\n",
    "            print(\"‚úÖ Removed\")\n",
    "            skip_setup = False\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  Continuing with current kernel (may cause issues)\")\n",
    "            skip_setup = True\n",
    "else:\n",
    "    skip_setup = False\n",
    "\n",
    "if not skip_setup:\n",
    "    print(\"\\nüîß Setting up Python virtual environment...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create virtual environment\n",
    "    print(\"\\n1Ô∏è‚É£ Creating virtual environment...\")\n",
    "    success, stdout, stderr = run_command([sys.executable, \"-m\", \"venv\", \"env\"])\n",
    "    if success:\n",
    "        print(\"‚úÖ Virtual environment created\")\n",
    "    else:\n",
    "        print(f\"‚ùå Failed to create virtual environment: {stderr}\")\n",
    "        raise RuntimeError(\"Virtual environment creation failed\")\n",
    "    \n",
    "    # Determine activation script path\n",
    "    if sys.platform == \"win32\":\n",
    "        activate_script = Path(\"env\") / \"Scripts\" / \"activate\"\n",
    "        pip_path = Path(\"env\") / \"Scripts\" / \"pip\"\n",
    "        python_path = Path(\"env\") / \"Scripts\" / \"python\"\n",
    "    else:\n",
    "        activate_script = Path(\"env\") / \"bin\" / \"activate\"\n",
    "        pip_path = Path(\"env\") / \"bin\" / \"pip\"\n",
    "        python_path = Path(\"env\") / \"bin\" / \"python\"\n",
    "    \n",
    "    # Upgrade pip\n",
    "    print(\"\\n2Ô∏è‚É£ Upgrading pip...\")\n",
    "    success, stdout, stderr = run_command([str(pip_path), \"install\", \"--upgrade\", \"pip\", \"setuptools\", \"wheel\"])\n",
    "    if success:\n",
    "        print(\"‚úÖ pip upgraded\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  pip upgrade had issues: {stderr}\")\n",
    "    \n",
    "    # Install jupyter and ipykernel in the new venv\n",
    "    print(\"\\n3Ô∏è‚É£ Installing Jupyter and ipykernel in new environment...\")\n",
    "    success, stdout, stderr = run_command([str(pip_path), \"install\", \"jupyter\", \"ipykernel\"])\n",
    "    if success:\n",
    "        print(\"‚úÖ Jupyter and ipykernel installed\")\n",
    "        \n",
    "        # Register the kernel\n",
    "        print(\"\\n4Ô∏è‚É£ Registering kernel...\")\n",
    "        success, stdout, stderr = run_command([str(python_path), \"-m\", \"ipykernel\", \"install\", \"--user\", \"--name=warehouse-assistant\"])\n",
    "        if success:\n",
    "            print(\"‚úÖ Kernel 'warehouse-assistant' registered!\")\n",
    "            print(\"\\n‚ö†Ô∏è  IMPORTANT: Please restart the kernel and select 'warehouse-assistant'\")\n",
    "            print(\"   Go to: Kernel ‚Üí Restart Kernel ‚Üí Change Kernel ‚Üí warehouse-assistant\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  Could not register kernel: {stderr}\")\n",
    "            print(\"   You can do this manually later\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Could not install Jupyter: {stderr}\")\n",
    "    \n",
    "    # Install requirements\n",
    "    print(\"\\n5Ô∏è‚É£ Installing Python dependencies...\")\n",
    "    print(\"   This may take a few minutes...\")\n",
    "    success, stdout, stderr = run_command([str(pip_path), \"install\", \"-r\", \"requirements.txt\"])\n",
    "    if success:\n",
    "        print(\"‚úÖ Dependencies installed successfully\")\n",
    "    else:\n",
    "        print(f\"‚ùå Failed to install dependencies: {stderr}\")\n",
    "        print(\"\\nüí° Try running manually:\")\n",
    "        print(f\"   source env/bin/activate  # or env\\\\Scripts\\\\activate on Windows\")\n",
    "        print(\"   pip install -r requirements.txt\")\n",
    "        raise RuntimeError(\"Dependency installation failed\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"‚ö†Ô∏è  IMPORTANT NEXT STEP:\")\n",
    "    print(\"   1. Go to: Kernel ‚Üí Restart Kernel\")\n",
    "    print(\"   2. Then: Kernel ‚Üí Change Kernel ‚Üí warehouse-assistant\")\n",
    "    print(\"   3. Re-run this cell to verify you're in the correct environment\")\n",
    "    print(\"   4. Continue with the rest of the notebook\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"‚úÖ Environment setup complete!\")\n",
    "    print(\"\\nüìù Next: Configure environment variables and API keys\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: API Key Configuration (NVIDIA & Brev)\n",
    "\n",
    "The Warehouse Operational Assistant uses NVIDIA NIMs (NVIDIA Inference Microservices) for AI capabilities. You have **two deployment options** for NIMs:\n",
    "\n",
    "### üöÄ NIM Deployment Options\n",
    "\n",
    "**Option 1: Cloud Endpoints** (Easiest - Default)\n",
    "- Use NVIDIA's cloud-hosted NIM services\n",
    "- **No installation required** - just configure API keys\n",
    "- Quick setup, perfect for development and testing\n",
    "- Endpoints: `api.brev.dev` or `integrate.api.nvidia.com`\n",
    "\n",
    "**Option 2: Self-Hosted NIMs** (Recommended for Production)\n",
    "- **Install NIMs on your own infrastructure** using Docker\n",
    "- **Create custom endpoints** on your servers\n",
    "- Benefits:\n",
    "  - üîí **Data Privacy**: Keep sensitive data on-premises\n",
    "  - üí∞ **Cost Control**: Avoid per-request cloud costs\n",
    "  - ‚öôÔ∏è **Custom Requirements**: Full control over infrastructure\n",
    "  - ‚ö° **Low Latency**: Reduced network latency\n",
    "\n",
    "**Self-Hosting Example:**\n",
    "```bash\n",
    "# Deploy LLM NIM on your server\n",
    "docker run --gpus all -p 8000:8000 \\\n",
    "  nvcr.io/nvidia/nim/llama-3.3-nemotron-super-49b-v1:latest \\\n",
    "  -e NVIDIA_API_KEY=\\\"your-key\\\"\n",
    "```\n",
    "\n",
    "Then configure `LLM_NIM_URL=http://your-server:8000/v1` in Step 5.\n",
    "\n",
    "---\n",
    "\n",
    "### üìã API Key Configuration\n",
    "\n",
    "**NVIDIA API Key** (`nvapi-...`)\n",
    "- **Get from**: https://build.nvidia.com/\n",
    "- **Used for**: All NVIDIA cloud services (LLM, Embedding, Guardrails)\n",
    "- **Format**: Starts with `nvapi-`\n",
    "\n",
    "**Brev API Key** (`brev_api_...`)\n",
    "- **Get from**: https://brev.nvidia.com/ (Brev account dashboard)\n",
    "- **Used for**: Brev-specific endpoints (`api.brev.dev`)\n",
    "- **Format**: Starts with `brev_api_`\n",
    "- **Note**: Some Brev endpoints may also accept NVIDIA API keys\n",
    "\n",
    "---\n",
    "\n",
    "### Configuration Options\n",
    "\n",
    "**Option 1: Use NVIDIA API Key for Everything (Recommended)**\n",
    "- Set `NVIDIA_API_KEY` with NVIDIA API key (`nvapi-...`)\n",
    "- Leave `EMBEDDING_API_KEY` unset\n",
    "- Works with both `api.brev.dev` and `integrate.api.nvidia.com`\n",
    "\n",
    "**Option 2: Use Brev API Key for LLM + NVIDIA API Key for Embedding**\n",
    "- Set `NVIDIA_API_KEY` with Brev API key (`brev_api_...`)\n",
    "- **MUST** set `EMBEDDING_API_KEY` with NVIDIA API key (`nvapi-...`)\n",
    "- Embedding service always requires NVIDIA API key\n",
    "\n",
    "The interactive setup below will guide you through the configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_project_root():\n",
    "    \"\"\"Get project root directory, detecting it if needed.\n",
    "    \n",
    "    This function works regardless of where the notebook is opened from.\n",
    "    It stores the result in builtins so it persists across cells.\n",
    "    \"\"\"\n",
    "    import builtins\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    \n",
    "    # Check if already stored\n",
    "    if hasattr(builtins, '__project_root__'):\n",
    "        return builtins.__project_root__\n",
    "    \n",
    "    # Try to find project root\n",
    "    current = Path.cwd()\n",
    "    \n",
    "    # Check if we're already in project root\n",
    "    if (current / \"src\" / \"api\").exists() and (current / \"scripts\" / \"setup\").exists():\n",
    "        project_root = current\n",
    "    # Check if we're in notebooks/setup/ (go up 2 levels)\n",
    "    elif (current / \"complete_setup_guide.ipynb\").exists() or current.name == \"setup\":\n",
    "        project_root = current.parent.parent\n",
    "    # Check if we're in notebooks/ (go up 1 level)\n",
    "    elif current.name == \"notebooks\":\n",
    "        project_root = current.parent\n",
    "    else:\n",
    "        # Try going up from current directory\n",
    "        project_root = current\n",
    "        for parent in current.parents:\n",
    "            if (parent / \"src\" / \"api\").exists() and (parent / \"scripts\" / \"setup\").exists():\n",
    "                project_root = parent\n",
    "                break\n",
    "    \n",
    "    # Change to project root and store it\n",
    "    os.chdir(project_root)\n",
    "    builtins.__project_root__ = project_root\n",
    "    return project_root\n",
    "\n",
    "\n",
    "import getpassfrom pathlib import Pathimport redef setup_api_keys():\n",
    "    # Get project root (works from any directory)\n",
    "    project_root = get_project_root()    \"\"\"Interactive setup for API keys (NVIDIA and/or Brev).\"\"\"    print(\"üîë API Key Configuration\")    print(\"=\" * 60)        # Check if .env.example exists    env_example = Path(\".env.example\")    if not env_example.exists():        print(\"‚ùå .env.example not found!\")        print(\"   Please ensure you're in the project root directory.\")        return False        # Check if .env already exists    env_file = project_root / \".env\"    if env_file.exists():        print(\"‚úÖ .env file already exists\")        overwrite = input(\"\\n‚ùì Update API keys in existing .env? (y/N): \").strip().lower()        if overwrite != 'y':            print(\"üìù Skipping API key setup. Using existing .env file.\")            return True    else:        print(\"üìù Creating .env file from .env.example...\")        import shutil        shutil.copy(env_example, env_file)        print(\"‚úÖ .env file created\")        # Ask about deployment option    print(\"\\n\" + \"=\" * 60)    print(\"üöÄ NIM Deployment Options:\")    print(\"=\" * 60)    print(\"\\n1. Cloud Endpoints (Default - Easiest)\")    print(\"   ‚Ä¢ Use NVIDIA's cloud-hosted NIM services\")    print(\"   ‚Ä¢ No installation required\")    print(\"   ‚Ä¢ Requires API keys (configured below)\")    print(\"\\n2. Self-Hosted NIMs (Advanced)\")    print(\"   ‚Ä¢ Install NIMs on your own infrastructure\")    print(\"   ‚Ä¢ Create custom endpoints\")    print(\"   ‚Ä¢ Better for production, data privacy, cost control\")    print(\"   ‚Ä¢ See DEPLOYMENT.md for self-hosting instructions\")    print(\"=\" * 60)        deployment_choice = input(\"\\n‚ùì Using cloud endpoints or self-hosted NIMs? (1=Cloud, 2=Self-hosted, default: 1): \").strip() or \"1\"        if deployment_choice == \"2\":        print(\"\\n‚úÖ Self-hosted NIMs selected\")        print(\"   ‚Ä¢ You can skip API key configuration if your NIMs don't require authentication\")        print(\"   ‚Ä¢ Configure endpoint URLs in Step 5 (Environment Variables Setup)\")        print(\"   ‚Ä¢ Example: LLM_NIM_URL=http://your-server:8000/v1\")        skip_keys = input(\"\\n‚ùì Skip API key configuration? (y/N): \").strip().lower()        if skip_keys == 'y':            print(\"üìù Skipping API key setup. Configure endpoints in Step 5.\")            return True        # Get API key configuration choice (for cloud endpoints)    print(\"\\n\" + \"=\" * 60)    print(\"üìã API Key Configuration Options (for Cloud Endpoints):\")    print(\"=\" * 60)    print(\"\\nOption 1: Use NVIDIA API Key for Everything (Recommended)\")    print(\"  ‚Ä¢ Set NVIDIA_API_KEY with NVIDIA API key (nvapi-...)\")    print(\"  ‚Ä¢ Leave EMBEDDING_API_KEY unset\")    print(\"  ‚Ä¢ Works with both endpoints\")    print(\"\\nOption 2: Use Brev API Key for LLM + NVIDIA API Key for Embedding\")    print(\"  ‚Ä¢ Set NVIDIA_API_KEY with Brev API key (brev_api_...)\")    print(\"  ‚Ä¢ MUST set EMBEDDING_API_KEY with NVIDIA API key (nvapi-...)\")    print(\"  ‚Ä¢ Embedding service always requires NVIDIA API key\")    print(\"=\" * 60)        choice = input(\"\\n‚ùì Which option? (1 or 2, default: 1): \").strip() or \"1\"        # Get NVIDIA_API_KEY    print(\"\\n\" + \"=\" * 60)    if choice == \"1\":        print(\"üìã Getting NVIDIA API Key:\")        print(\"1. Visit: https://build.nvidia.com/\")        print(\"2. Sign up or log in\")        print(\"3. Go to 'API Keys' section\")        print(\"4. Create a new API key (starts with 'nvapi-')\")        print(\"5. Copy the API key\")        print(\"=\" * 60)        api_key = getpass.getpass(\"\\nüîë Enter your NVIDIA API key (nvapi-...): \").strip()        embedding_key = None  # Will use NVIDIA_API_KEY    else:        print(\"üìã Getting Brev API Key for LLM:\")        print(\"1. Visit: https://brev.nvidia.com/ (Brev account dashboard)\")        print(\"2. Navigate to API Keys section\")        print(\"3. Create or copy your Brev API key (starts with 'brev_api_')\")        print(\"=\" * 60)        api_key = getpass.getpass(\"\\nüîë Enter your Brev API key (brev_api_...): \").strip()                print(\"\\n\" + \"=\" * 60)        print(\"üìã Getting NVIDIA API Key for Embedding (REQUIRED):\")        print(\"1. Visit: https://build.nvidia.com/\")        print(\"2. Sign up or log in\")        print(\"3. Go to 'API Keys' section\")        print(\"4. Create a new API key (starts with 'nvapi-')\")        print(\"5. Copy the API key\")        print(\"=\" * 60)        print(\"‚ö†Ô∏è  IMPORTANT: Embedding service REQUIRES NVIDIA API key!\")        embedding_key = getpass.getpass(\"\\nüîë Enter your NVIDIA API key for Embedding (nvapi-...): \").strip()        if not api_key:        print(\"‚ùå No API key provided. Skipping API key setup.\")        print(\"   You can set it later in the .env file or environment variables.\")        return False        if api_key.lower() in [\"your_nvidia_api_key_here\", \"your-api-key-here\", \"\"]:        print(\"‚ùå Please enter your actual API key, not the placeholder.\")        return False        # Validate key formats    if choice == \"1\" and not api_key.startswith(\"nvapi-\"):        print(\"‚ö†Ô∏è  Warning: NVIDIA API key should start with 'nvapi-'\")        confirm = input(\"   Continue anyway? (y/N): \").strip().lower()        if confirm != 'y':            return False    elif choice == \"2\":        if not api_key.startswith(\"brev_api_\"):            print(\"‚ö†Ô∏è  Warning: Brev API key should start with 'brev_api_'\")            confirm = input(\"   Continue anyway? (y/N): \").strip().lower()            if confirm != 'y':                return False        if not embedding_key or not embedding_key.startswith(\"nvapi-\"):            print(\"‚ùå Embedding service REQUIRES NVIDIA API key (must start with 'nvapi-')\")            return False        # Update .env file    try:        with open(env_file, 'r') as f:            content = f.read()                # Replace NVIDIA_API_KEY        content = re.sub(            r'^NVIDIA_API_KEY=.*$',            f'NVIDIA_API_KEY={api_key}',            content,            flags=re.MULTILINE        )                # Update EMBEDDING_API_KEY if provided        if embedding_key:            content = re.sub(                r'^EMBEDDING_API_KEY=.*$',                f'EMBEDDING_API_KEY={embedding_key}',                content,                flags=re.MULTILINE            )        else:            # Remove EMBEDDING_API_KEY line if using Option 1 (will use NVIDIA_API_KEY)            content = re.sub(r'^EMBEDDING_API_KEY=.*$\\n?', '', content, flags=re.MULTILINE)                # Also update RAIL_API_KEY if it's a placeholder        if 'RAIL_API_KEY=your_nvidia_api_key_here' in content or 'RAIL_API_KEY=' not in content:            # Use NVIDIA API key for RAIL (always needs NVIDIA key)            rail_key = embedding_key if embedding_key else api_key if api_key.startswith(\"nvapi-\") else \"\"            if rail_key:                content = re.sub(                    r'^RAIL_API_KEY=.*$',                    f'RAIL_API_KEY={rail_key}',                    content,                    flags=re.MULTILINE                )                with open(env_file, 'w') as f:            f.write(content)                print(\"\\n‚úÖ API keys configured in .env file\")        if choice == \"1\":            print(\"   ‚Ä¢ NVIDIA_API_KEY: Set (will be used for all services)\")        else:            print(\"   ‚Ä¢ NVIDIA_API_KEY: Set (Brev API key for LLM)\")            print(\"   ‚Ä¢ EMBEDDING_API_KEY: Set (NVIDIA API key for Embedding)\")        print(\"\\nüí° The API keys are stored in .env file (not committed to git)\")        return True            except Exception as e:        print(f\"‚ùå Error updating .env file: {e}\")        return False# Run the setupsetup_api_keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Environment Variables Setup\n",
    "\n",
    "Now let's verify and configure other important environment variables. The `.env` file should already be created from the previous step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_project_root():\n",
    "    \"\"\"Get project root directory, detecting it if needed.\n",
    "    \n",
    "    This function works regardless of where the notebook is opened from.\n",
    "    It stores the result in builtins so it persists across cells.\n",
    "    \"\"\"\n",
    "    import builtins\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    \n",
    "    # Check if already stored\n",
    "    if hasattr(builtins, '__project_root__'):\n",
    "        return builtins.__project_root__\n",
    "    \n",
    "    # Try to find project root\n",
    "    current = Path.cwd()\n",
    "    \n",
    "    # Check if we're already in project root\n",
    "    if (current / \"src\" / \"api\").exists() and (current / \"scripts\" / \"setup\").exists():\n",
    "        project_root = current\n",
    "    # Check if we're in notebooks/setup/ (go up 2 levels)\n",
    "    elif (current / \"complete_setup_guide.ipynb\").exists() or current.name == \"setup\":\n",
    "        project_root = current.parent.parent\n",
    "    # Check if we're in notebooks/ (go up 1 level)\n",
    "    elif current.name == \"notebooks\":\n",
    "        project_root = current.parent\n",
    "    else:\n",
    "        # Try going up from current directory\n",
    "        project_root = current\n",
    "        for parent in current.parents:\n",
    "            if (parent / \"src\" / \"api\").exists() and (parent / \"scripts\" / \"setup\").exists():\n",
    "                project_root = parent\n",
    "                break\n",
    "    \n",
    "    # Change to project root and store it\n",
    "    os.chdir(project_root)\n",
    "    builtins.__project_root__ = project_root\n",
    "    return project_root\n",
    "\n",
    "\n",
    "from pathlib import Pathimport osimport redef check_env_file():\n",
    "    # Get project root (works from any directory)\n",
    "    project_root = get_project_root()    \"\"\"Check and display environment variable configuration.\"\"\"    # Get project root (works even if Step 2 wasn't run)    import builtins    if hasattr(builtins, '__project_root__'):        project_root = builtins.__project_root__    elif hasattr(builtins, '__find_project_root__'):        project_root = builtins.__find_project_root__()        os.chdir(project_root)        builtins.__project_root__ = project_root    else:        # Fallback: try to find project root        current = Path.cwd()        # Check if we're in notebooks/setup/ (go up 2 levels)        if (current / \"complete_setup_guide.ipynb\").exists() or current.name == \"setup\":            project_root = current.parent.parent        elif current.name == \"notebooks\":            project_root = current.parent        else:            # Try going up from current directory            for parent in current.parents:                if (parent / \"src\" / \"api\").exists() and (parent / \"scripts\" / \"setup\").exists():                    project_root = parent                    break            else:                project_root = current        os.chdir(project_root)        builtins.__project_root__ = project_root        env_file = project_root / \".env\"    env_example = project_root / \".env.example\"        if not env_file.exists():        if env_example.exists():            print(\"üìù Creating .env file from .env.example...\")            import shutil            shutil.copy(env_example, env_file)            print(\"‚úÖ .env file created\")        else:            print(\"‚ùå Neither .env nor .env.example found!\")            return False        # Load and display key variables    print(\"üìã Environment Variables Configuration\")    print(\"=\" * 60)        with open(env_file, 'r') as f:        content = f.read()        # Extract key variables    key_vars = {        'NVIDIA_API_KEY': 'NVIDIA API Key (for NIM services)',        'LLM_NIM_URL': 'LLM NIM Endpoint',        'EMBEDDING_NIM_URL': 'Embedding NIM Endpoint',        'POSTGRES_PASSWORD': 'Database Password',        'JWT_SECRET_KEY': 'JWT Secret Key (for authentication)',        'DEFAULT_ADMIN_PASSWORD': 'Default Admin Password',        'DB_HOST': 'Database Host',        'DB_PORT': 'Database Port',    }        print(\"\\nüîç Current Configuration:\\n\")    for var, description in key_vars.items():        match = re.search(rf'^{var}=(.*)$', content, re.MULTILINE)        if match:            value = match.group(1).strip()            # Mask sensitive values            if 'PASSWORD' in var or 'SECRET' in var or 'API_KEY' in var:                if value and value not in ['changeme', 'your_nvidia_api_key_here', '']:                    display_value = value[:8] + \"...\" if len(value) > 8 else \"***\"                else:                    display_value = \"‚ö†Ô∏è  NOT SET (using default/placeholder)\"            else:                display_value = value if value else \"‚ö†Ô∏è  NOT SET\"            print(f\"  {var:25} = {display_value:30} # {description}\")        else:            print(f\"  {var:25} = ‚ö†Ô∏è  NOT FOUND              # {description}\")        print(\"\\n\" + \"=\" * 60)    print(\"\\n‚úÖ Environment file check complete!\")    print(\"\\nüí° Important Notes:\")    print(\"   - For production, change all default passwords and secrets\")    print(\"   - NVIDIA_API_KEY is required for AI features\")    print(\"   - JWT_SECRET_KEY is required in production\")    print(\"\\nüìù To edit: nano .env  (or your preferred editor)\")        return True# Check environment filecheck_env_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Infrastructure Services\n",
    "\n",
    "The application requires several infrastructure services:\n",
    "- **TimescaleDB** (PostgreSQL with time-series extensions) - Database\n",
    "- **Redis** - Caching layer\n",
    "- **Milvus** - Vector database for embeddings\n",
    "- **Kafka** - Message broker\n",
    "\n",
    "We'll use Docker Compose to start these services.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_project_root():\n",
    "    \"\"\"Get project root directory, detecting it if needed.\n",
    "    \n",
    "    This function works regardless of where the notebook is opened from.\n",
    "    It stores the result in builtins so it persists across cells.\n",
    "    \"\"\"\n",
    "    import builtins\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    \n",
    "    # Check if already stored\n",
    "    if hasattr(builtins, '__project_root__'):\n",
    "        return builtins.__project_root__\n",
    "    \n",
    "    # Try to find project root\n",
    "    current = Path.cwd()\n",
    "    \n",
    "    # Check if we're already in project root\n",
    "    if (current / \"src\" / \"api\").exists() and (current / \"scripts\" / \"setup\").exists():\n",
    "        project_root = current\n",
    "    # Check if we're in notebooks/setup/ (go up 2 levels)\n",
    "    elif (current / \"complete_setup_guide.ipynb\").exists() or current.name == \"setup\":\n",
    "        project_root = current.parent.parent\n",
    "    # Check if we're in notebooks/ (go up 1 level)\n",
    "    elif current.name == \"notebooks\":\n",
    "        project_root = current.parent\n",
    "    else:\n",
    "        # Try going up from current directory\n",
    "        project_root = current\n",
    "        for parent in current.parents:\n",
    "            if (parent / \"src\" / \"api\").exists() and (parent / \"scripts\" / \"setup\").exists():\n",
    "                project_root = parent\n",
    "                break\n",
    "    \n",
    "    # Change to project root and store it\n",
    "    os.chdir(project_root)\n",
    "    builtins.__project_root__ = project_root\n",
    "    return project_root\n",
    "\n",
    "\n",
    "import subprocessimport timefrom pathlib import Pathdef check_docker_running():    \"\"\"Check if Docker is running.\"\"\"    try:        result = subprocess.run(            [\"docker\", \"info\"],            capture_output=True,            text=True,            timeout=5        )        return result.returncode == 0    except:        return Falsedef start_infrastructure():    \"\"\"Start infrastructure services using Docker Compose.\"\"\"    print(\"üê≥ Starting Infrastructure Services\")    print(\"=\" * 60)        if not check_docker_running():        print(\"‚ùå Docker is not running!\")        print(\"   Please start Docker Desktop or Docker daemon and try again.\")        return False        # Get project root (works even if Step 2 wasn't run)    import builtins    if hasattr(builtins, '__project_root__'):        project_root = builtins.__project_root__    elif hasattr(builtins, '__find_project_root__'):        project_root = builtins.__find_project_root__()        os.chdir(project_root)        builtins.__project_root__ = project_root    else:        # Fallback: try to find project root        current = Path.cwd()        # Check if we're in notebooks/setup/ (go up 2 levels)        if (current / \"complete_setup_guide.ipynb\").exists() or current.name == \"setup\":            project_root = current.parent.parent        elif current.name == \"notebooks\":            project_root = current.parent        else:            # Try going up from current directory            for parent in current.parents:                if (parent / \"src\" / \"api\").exists() and (parent / \"scripts\" / \"setup\").exists():                    project_root = parent                    break            else:                project_root = current        os.chdir(project_root)        builtins.__project_root__ = project_root        # Get project root (works from any directory)\n",
    "    project_root = get_project_root()\n",
    "    compose_file = project_root / \"deploy/compose/docker-compose.dev.yaml\"    if not compose_file.exists():        print(f\"‚ùå Docker Compose file not found: {compose_file}\")        return False        print(\"\\n1Ô∏è‚É£ Checking for existing containers...\")    # Check if docker-compose or docker compose is available    try:        result = subprocess.run(            [\"docker\", \"compose\", \"version\"],            capture_output=True,            text=True,            timeout=5        )        compose_cmd = [\"docker\", \"compose\"]    except:        compose_cmd = [\"docker-compose\"]        print(f\"   Using: {' '.join(compose_cmd)}\")        print(\"\\n2Ô∏è‚É£ Starting infrastructure services...\")    print(\"   This may take a few minutes on first run (downloading images)...\")        result = subprocess.run(        compose_cmd + [            \"-f\", str(compose_file),            \"up\", \"-d\"        ],        capture_output=True,        text=True    )        if result.returncode == 0:        print(\"‚úÖ Infrastructure services started\")    else:        print(f\"‚ùå Failed to start services: {result.stderr}\")        return False        print(\"\\n3Ô∏è‚É£ Waiting for services to be ready...\")    print(\"   (This may take 30-60 seconds)\")        # Wait for TimescaleDB    max_wait = 60    waited = 0    while waited < max_wait:        try:            result = subprocess.run(                [\"docker\", \"exec\", \"wosa-timescaledb\", \"pg_isready\", \"-U\", \"warehouse\"],                capture_output=True,                timeout=5            )            if result.returncode == 0:                print(\"‚úÖ TimescaleDB is ready\")                break        except:            pass        time.sleep(2)        waited += 2        if waited % 10 == 0:            print(f\"   Waiting... ({waited}s)\")        if waited >= max_wait:        print(\"‚ö†Ô∏è  TimescaleDB may not be ready yet. Continuing anyway...\")        print(\"\\n\" + \"=\" * 60)    print(\"‚úÖ Infrastructure services are running!\")    print(\"\\nüìã Service Endpoints:\")    print(\"   ‚Ä¢ TimescaleDB: localhost:5435\")    print(\"   ‚Ä¢ Redis: localhost:6379\")    print(\"   ‚Ä¢ Milvus: localhost:19530 (gRPC), localhost:9091 (HTTP)\")    print(\"   ‚Ä¢ Kafka: localhost:9092\")        return True# Uncomment to start infrastructure automatically# start_infrastructure()print(\"üí° To start infrastructure services, run:\")print(\"   ./scripts/setup/dev_up.sh\")print(\"\\n   Or uncomment the start_infrastructure() call above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Database Setup\n",
    "\n",
    "Now we'll run database migrations to set up the schema. This includes:\n",
    "- Core schema\n",
    "- Equipment schema\n",
    "- Document schema\n",
    "- Inventory movements schema\n",
    "- Model tracking tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_project_root():\n",
    "    \"\"\"Get project root directory, detecting it if needed.\"\"\"\n",
    "    import builtins\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    \n",
    "    # Check if already stored\n",
    "    if hasattr(builtins, '__project_root__'):\n",
    "        return builtins.__project_root__\n",
    "    \n",
    "    # Try to find it\n",
    "    current = Path.cwd()\n",
    "    \n",
    "    # Check if we're already in project root\n",
    "    if (current / \"src\" / \"api\").exists() and (current / \"scripts\" / \"setup\").exists():\n",
    "        project_root = current\n",
    "    # Check if we're in notebooks/setup/ (go up 2 levels)\n",
    "    elif (current / \"complete_setup_guide.ipynb\").exists() or current.name == \"setup\":\n",
    "        project_root = current.parent.parent\n",
    "    # Check if we're in notebooks/ (go up 1 level)\n",
    "    elif current.name == \"notebooks\":\n",
    "        project_root = current.parent\n",
    "    else:\n",
    "        # Try going up from current directory\n",
    "        project_root = current\n",
    "        for parent in current.parents:\n",
    "            if (parent / \"src\" / \"api\").exists() and (parent / \"scripts\" / \"setup\").exists():\n",
    "                project_root = parent\n",
    "                break\n",
    "    \n",
    "    # Change to project root and store it\n",
    "    os.chdir(project_root)\n",
    "    builtins.__project_root__ = project_root\n",
    "    return project_root\n",
    "\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "def run_migration(sql_file):\n",
    "    # Get project root for file paths\n",
    "    project_root = get_project_root()\n",
    "    \n",
    "    \"\"\"Run a single SQL migration file.\n",
    "    \n",
    "    Tries methods in order:\n",
    "    1. docker-compose exec (recommended - no psql client needed)\n",
    "    2. docker exec (fallback)\n",
    "    3. psql from host (requires PostgreSQL client installed)\n",
    "    \"\"\"\n",
    "    db_host = os.getenv(\"DB_HOST\", \"localhost\")\n",
    "    db_port = os.getenv(\"DB_PORT\", \"5435\")\n",
    "    db_user = os.getenv(\"POSTGRES_USER\", \"warehouse\")\n",
    "    db_password = os.getenv(\"POSTGRES_PASSWORD\", \"changeme\")\n",
    "    db_name = os.getenv(\"POSTGRES_DB\", \"warehouse\")\n",
    "    \n",
    "    sql_path = project_root / sql_file if not Path(sql_file).is_absolute() else Path(sql_file)\n",
    "    if not sql_path.exists():\n",
    "        return False, f\"File not found: {sql_file}\"\n",
    "    \n",
    "    # Method 1: Try docker-compose exec first (recommended)\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\n",
    "                \"docker-compose\", \"-f\", str(project_root / \"deploy/compose/docker-compose.dev.yaml\"),\n",
    "                \"exec\", \"-T\", \"timescaledb\",\n",
    "                \"psql\", \"-U\", db_user, \"-d\", db_name\n",
    "            ],\n",
    "            input=sql_path.read_text(),\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=30\n",
    "        )\n",
    "        if result.returncode == 0:\n",
    "            return True, \"Success\"\n",
    "    except FileNotFoundError:\n",
    "        pass  # docker-compose not found, try next method\n",
    "    except Exception as e:\n",
    "        pass  # Try next method\n",
    "    \n",
    "    # Method 2: Try docker exec (fallback)\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\n",
    "                \"docker\", \"exec\", \"-i\", \"wosa-timescaledb\",\n",
    "                \"psql\", \"-U\", db_user, \"-d\", db_name\n",
    "            ],\n",
    "            input=sql_path.read_text(),\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=30\n",
    "        )\n",
    "        if result.returncode == 0:\n",
    "            return True, \"Success\"\n",
    "    except FileNotFoundError:\n",
    "        pass  # docker not found, try next method\n",
    "    except Exception as e:\n",
    "        pass  # Try next method\n",
    "    \n",
    "    # Method 3: Fall back to psql from host (requires PostgreSQL client)\n",
    "    try:\n",
    "        env = os.environ.copy()\n",
    "        env[\"PGPASSWORD\"] = db_password\n",
    "        result = subprocess.run(\n",
    "            [\n",
    "                \"psql\",\n",
    "                \"-h\", db_host,\n",
    "                \"-p\", db_port,\n",
    "                \"-U\", db_user,\n",
    "                \"-d\", db_name,\n",
    "                \"-f\", str(sql_path)\n",
    "            ],\n",
    "            env=env,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=30\n",
    "        )\n",
    "        if result.returncode == 0:\n",
    "            return True, \"Success\"\n",
    "        else:\n",
    "            return False, result.stderr\n",
    "    except FileNotFoundError:\n",
    "        return False, \"psql not found. Install PostgreSQL client or use Docker Compose method.\"\n",
    "    except Exception as e:\n",
    "        return False, f\"All methods failed: {str(e)}\"\n",
    "\n",
    "def setup_database():\n",
    "    \"\"\"Run all database migrations.\"\"\"\n",
    "    print(\"üóÑÔ∏è  Database Setup and Migrations\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    migrations = [\n",
    "        (\"data/postgres/000_schema.sql\", \"Core schema\"),\n",
    "        (\"data/postgres/001_equipment_schema.sql\", \"Equipment schema\"),\n",
    "        (\"data/postgres/002_document_schema.sql\", \"Document schema\"),\n",
    "        (\"data/postgres/004_inventory_movements_schema.sql\", \"Inventory movements schema\"),\n",
    "        (\"scripts/setup/create_model_tracking_tables.sql\", \"Model tracking tables\"),\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nüìã Running migrations...\\n\")\n",
    "    \n",
    "    for sql_file, description in migrations:\n",
    "        print(f\"  üîÑ {description}...\", end=\" \")\n",
    "        success, message = run_migration(sql_file)\n",
    "        if success:\n",
    "            print(\"‚úÖ\")\n",
    "        else:\n",
    "            print(f\"‚ùå\\n     Error: {message}\")\n",
    "            print(f\"\\nüí° Try running manually:\")\n",
    "            print(f\"   # Using Docker Compose (recommended):\")\n",
    "            print(f\"   docker-compose -f deploy/compose/docker-compose.dev.yaml exec -T timescaledb psql -U warehouse -d warehouse < {sql_file}\")\n",
    "            print(f\"   # Or using psql (requires PostgreSQL client):\")\n",
    "            print(f\"   PGPASSWORD=${{POSTGRES_PASSWORD:-changeme}} psql -h localhost -p 5435 -U warehouse -d warehouse -f {sql_file}\")\n",
    "            return False\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"‚úÖ Database migrations completed successfully!\")\n",
    "    return True\n",
    "\n",
    "# Run migrations\n",
    "setup_database()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Create Default Users\n",
    "\n",
    "Create the default admin user for accessing the application.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_project_root():\n",
    "    \"\"\"Get project root directory, detecting it if needed.\n",
    "    \n",
    "    This function works regardless of where the notebook is opened from.\n",
    "    It stores the result in builtins so it persists across cells.\n",
    "    \"\"\"\n",
    "    import builtins\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    \n",
    "    # Check if already stored\n",
    "    if hasattr(builtins, '__project_root__'):\n",
    "        return builtins.__project_root__\n",
    "    \n",
    "    # Try to find project root\n",
    "    current = Path.cwd()\n",
    "    \n",
    "    # Check if we're already in project root\n",
    "    if (current / \"src\" / \"api\").exists() and (current / \"scripts\" / \"setup\").exists():\n",
    "        project_root = current\n",
    "    # Check if we're in notebooks/setup/ (go up 2 levels)\n",
    "    elif (current / \"complete_setup_guide.ipynb\").exists() or current.name == \"setup\":\n",
    "        project_root = current.parent.parent\n",
    "    # Check if we're in notebooks/ (go up 1 level)\n",
    "    elif current.name == \"notebooks\":\n",
    "        project_root = current.parent\n",
    "    else:\n",
    "        # Try going up from current directory\n",
    "        project_root = current\n",
    "        for parent in current.parents:\n",
    "            if (parent / \"src\" / \"api\").exists() and (parent / \"scripts\" / \"setup\").exists():\n",
    "                project_root = parent\n",
    "                break\n",
    "    \n",
    "    # Change to project root and store it\n",
    "    os.chdir(project_root)\n",
    "    builtins.__project_root__ = project_root\n",
    "    return project_root\n",
    "\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def create_default_users():\n",
    "    # Get project root (works from any directory)\n",
    "    project_root = get_project_root()\n",
    "    \"\"\"Create default admin user.\"\"\"\n",
    "    print(\"üë§ Creating Default Users\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    script_path = project_root / \"scripts/setup/create_default_users.py\")\n",
    "    if not script_path.exists():\n",
    "        print(f\"‚ùå Script not found: {script_path}\")\n",
    "        return False\n",
    "    \n",
    "    # Determine Python path\n",
    "    if sys.platform == \"win32\":\n",
    "        python_path = Path(\"env\") / \"Scripts\" / \"python.exe\"\n",
    "    else:\n",
    "        python_path = Path(\"env\") / \"bin\" / \"python\"\n",
    "    \n",
    "    if not python_path.exists():\n",
    "        print(f\"‚ùå Python not found at: {python_path}\")\n",
    "        print(\"   Make sure virtual environment is set up (Step 3)\")\n",
    "        return False\n",
    "    \n",
    "    print(\"\\nüîÑ Running user creation script...\")\n",
    "    result = subprocess.run(\n",
    "        [str(python_path), str(script_path)],\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"‚úÖ Default users created successfully\")\n",
    "        print(\"\\nüìã Default Credentials:\")\n",
    "        print(\"   Username: admin\")\n",
    "        print(\"   Password: (check DEFAULT_ADMIN_PASSWORD in .env, default: 'changeme')\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"‚ùå Failed to create users: {result.stderr}\")\n",
    "        print(\"\\nüí° Try running manually:\")\n",
    "        print(f\"   source env/bin/activate  # or env\\\\Scripts\\\\activate on Windows\")\n",
    "        print(f\"   python {script_path}\")\n",
    "        return False\n",
    "\n",
    "# Create users\n",
    "create_default_users()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Generate Demo Data (Optional)\n",
    "\n",
    "Generate sample data for testing and demonstration purposes. This includes:\n",
    "- Equipment assets\n",
    "- Inventory items\n",
    "- Historical demand data (for forecasting)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def generate_demo_data():\n",
    "    \"\"\"Generate demo data for testing.\"\"\"\n",
    "    print(\"üìä Generating Demo Data\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Determine Python path\n",
    "    if sys.platform == \"win32\":\n",
    "        python_path = Path(\"env\") / \"Scripts\" / \"python.exe\"\n",
    "    else:\n",
    "        python_path = Path(\"env\") / \"bin\" / \"python\"\n",
    "    \n",
    "    if not python_path.exists():\n",
    "        print(f\"‚ùå Python not found at: {python_path}\")\n",
    "        return False\n",
    "    \n",
    "    scripts = [\n",
    "        (\"scripts/data/quick_demo_data.py\", \"Quick demo data (equipment, inventory)\"),\n",
    "        (\"scripts/data/generate_historical_demand.py\", \"Historical demand data (for forecasting)\"),\n",
    "    ]\n",
    "    \n",
    "    for script_path, description in scripts:\n",
    "        script = Path(script_path)\n",
    "        if not script.exists():\n",
    "            print(f\"‚ö†Ô∏è  Script not found: {script_path} (skipping)\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nüîÑ {description}...\")\n",
    "        result = subprocess.run(\n",
    "            [str(python_path), str(script)],\n",
    "            capture_output=True,\n",
    "            text=True\n",
    "        )\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(f\"‚úÖ {description} generated\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  {description} had issues: {result.stderr[:200]}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"‚úÖ Demo data generation complete!\")\n",
    "    print(\"\\nüí° You can skip this step if you don't need demo data.\")\n",
    "    return True\n",
    "\n",
    "# Generate demo data\n",
    "generate_demo_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: üöÄ (Optional) Install RAPIDS GPU Acceleration\n",
    "\n",
    "**This step is OPTIONAL** but highly recommended if you have an NVIDIA GPU. RAPIDS enables **10-100x faster forecasting** with GPU acceleration.\n",
    "\n",
    "### Benefits\n",
    "- ‚ö° **10-100x faster** training and inference\n",
    "- üéØ **Automatic GPU detection** - Falls back to CPU if GPU unavailable\n",
    "- üîÑ **Zero code changes** - Works automatically when installed\n",
    "- üìä **Full model support** - Random Forest, Linear Regression, SVR via cuML; XGBoost via CUDA\n",
    "\n",
    "### Requirements\n",
    "- **NVIDIA GPU** with CUDA 12.x support\n",
    "- **CUDA Compute Capability 7.0+** (Volta, Turing, Ampere, Ada, Hopper)\n",
    "- **16GB+ GPU memory** (recommended)\n",
    "- **Python 3.9-3.11**\n",
    "\n",
    "**Note**: If you don't have a GPU or prefer not to install RAPIDS, you can skip this step. The application will work perfectly on CPU with automatic fallback.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def check_gpu_availability():\n",
    "    \"\"\"Check if NVIDIA GPU is available.\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['nvidia-smi'],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=5\n",
    "        )\n",
    "        if result.returncode == 0:\n",
    "            return True, result.stdout\n",
    "        return False, None\n",
    "    except (FileNotFoundError, subprocess.TimeoutExpired):\n",
    "        return False, None\n",
    "\n",
    "def check_rapids_installed():\n",
    "    \"\"\"Check if RAPIDS is already installed.\"\"\"\n",
    "    try:\n",
    "        import cudf\n",
    "        import cuml\n",
    "        return True, f\"cuDF {cudf.__version__}, cuML {cuml.__version__}\"\n",
    "    except ImportError:\n",
    "        return False, None\n",
    "\n",
    "def install_rapids():\n",
    "    \"\"\"Install RAPIDS cuDF and cuML.\"\"\"\n",
    "    print(\"üì¶ Installing RAPIDS cuDF and cuML...\")\n",
    "    print(\"   This may take several minutes (packages are ~2GB)...\")\n",
    "    \n",
    "    try:\n",
    "        # Install RAPIDS\n",
    "        result = subprocess.run(\n",
    "            [\n",
    "                sys.executable, '-m', 'pip', 'install',\n",
    "                '--extra-index-url=https://pypi.nvidia.com',\n",
    "                'cudf-cu12', 'cuml-cu12'\n",
    "            ],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=1800  # 30 minutes timeout\n",
    "        )\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            return True, \"RAPIDS installed successfully\"\n",
    "        else:\n",
    "            return False, f\"Installation failed: {result.stderr}\"\n",
    "    except subprocess.TimeoutExpired:\n",
    "        return False, \"Installation timed out (took longer than 30 minutes)\"\n",
    "    except Exception as e:\n",
    "        return False, f\"Installation error: {str(e)}\"\n",
    "\n",
    "# Check GPU availability\n",
    "print(\"üîç Checking GPU Availability...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "gpu_available, gpu_info = check_gpu_availability()\n",
    "if gpu_available:\n",
    "    print(\"‚úÖ NVIDIA GPU detected!\")\n",
    "    print(\"\\nGPU Information:\")\n",
    "    print(gpu_info.split('\\n')[0:5])  # Show first few lines\n",
    "    print(\"\\nüí° You can install RAPIDS for GPU acceleration!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  NVIDIA GPU not detected or nvidia-smi not available\")\n",
    "    print(\"   RAPIDS installation is optional - the system will use CPU fallback\")\n",
    "\n",
    "# Check if RAPIDS is already installed\n",
    "print(\"\\nüîç Checking RAPIDS Installation...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "rapids_installed, rapids_version = check_rapids_installed()\n",
    "if rapids_installed:\n",
    "    print(f\"‚úÖ RAPIDS is already installed: {rapids_version}\")\n",
    "    print(\"   GPU acceleration will be enabled automatically!\")\n",
    "else:\n",
    "    print(\"‚ùå RAPIDS is not installed\")\n",
    "    print(\"   The system will use CPU fallback (still works great!)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"\\nüìù Next Steps:\")\n",
    "if not rapids_installed and gpu_available:\n",
    "    print(\"   ‚Ä¢ Run the next cell to install RAPIDS (optional but recommended)\")\n",
    "    print(\"   ‚Ä¢ Or skip to start the backend server\")\n",
    "elif not gpu_available:\n",
    "    print(\"   ‚Ä¢ GPU not detected - skipping RAPIDS installation\")\n",
    "    print(\"   ‚Ä¢ System will use CPU fallback (works perfectly!)\")\n",
    "    print(\"   ‚Ä¢ Proceed to start the backend server\")\n",
    "else:\n",
    "    print(\"   ‚Ä¢ RAPIDS is already installed - proceed to start the backend server\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Install RAPIDS for GPU acceleration\n",
    "# Uncomment and run this cell if you want to install RAPIDS\n",
    "\n",
    "# Check if we should install\n",
    "gpu_available, _ = check_gpu_availability()\n",
    "rapids_installed, _ = check_rapids_installed()\n",
    "\n",
    "if rapids_installed:\n",
    "    print(\"‚úÖ RAPIDS is already installed - no need to reinstall!\")\n",
    "elif not gpu_available:\n",
    "    print(\"‚ö†Ô∏è  GPU not detected. RAPIDS installation is not recommended.\")\n",
    "    print(\"   The system will work perfectly with CPU fallback.\")\n",
    "    print(\"   If you're sure you have a GPU, you can still install RAPIDS.\")\n",
    "    print(\"\\n   To install anyway, uncomment the install_rapids() call below.\")\n",
    "else:\n",
    "    print(\"üöÄ Ready to install RAPIDS!\")\n",
    "    print(\"   This will install:\")\n",
    "    print(\"   ‚Ä¢ cuDF (GPU-accelerated DataFrames)\")\n",
    "    print(\"   ‚Ä¢ cuML (GPU-accelerated Machine Learning)\")\n",
    "    print(\"   ‚Ä¢ Estimated time: 5-15 minutes\")\n",
    "    print(\"   ‚Ä¢ Estimated size: ~2GB\")\n",
    "    print(\"\\n   Uncomment the line below to proceed with installation:\")\n",
    "    print(\"   install_rapids()\")\n",
    "\n",
    "# Uncomment the line below to install RAPIDS:\n",
    "# success, message = install_rapids()\n",
    "# if success:\n",
    "#     print(f\"‚úÖ {message}\")\n",
    "#     print(\"\\nüîç Verifying installation...\")\n",
    "#     rapids_installed, rapids_version = check_rapids_installed()\n",
    "#     if rapids_installed:\n",
    "#         print(f\"‚úÖ RAPIDS verified: {rapids_version}\")\n",
    "#         print(\"   GPU acceleration will be enabled automatically!\")\n",
    "#     else:\n",
    "#         print(\"‚ö†Ô∏è  Installation completed but verification failed\")\n",
    "# else:\n",
    "#     print(f\"‚ùå {message}\")\n",
    "#     print(\"\\nüí° Don't worry! The system will work perfectly with CPU fallback.\")\n",
    "#     print(\"   You can try installing RAPIDS later if needed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Start Backend Server\n",
    "\n",
    "Now we'll start the FastAPI backend server. The server will run on port 8001 by default.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "def check_port(port):\n",
    "    \"\"\"Check if a port is in use.\"\"\"\n",
    "    import socket\n",
    "    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    result = sock.connect_ex(('localhost', port))\n",
    "    sock.close()\n",
    "    return result == 0\n",
    "\n",
    "def start_backend():\n",
    "    \"\"\"Start the backend server.\"\"\"\n",
    "    print(\"üöÄ Starting Backend Server\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    port = 8001\n",
    "    \n",
    "    # Check if port is already in use\n",
    "    if check_port(port):\n",
    "        print(f\"‚ö†Ô∏è  Port {port} is already in use!\")\n",
    "        print(\"   The backend may already be running.\")\n",
    "        print(f\"   Check: http://localhost:{port}/health\")\n",
    "        return True\n",
    "    \n",
    "    # Determine Python path\n",
    "    if sys.platform == \"win32\":\n",
    "        python_path = Path(\"env\") / \"Scripts\" / \"python.exe\"\n",
    "    else:\n",
    "        python_path = Path(\"env\") / \"bin\" / \"python\"\n",
    "    \n",
    "    if not python_path.exists():\n",
    "        print(f\"‚ùå Python not found at: {python_path}\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"\\nüîÑ Starting FastAPI server on port {port}...\")\n",
    "    print(\"   This will run in the background.\")\n",
    "    print(\"   To stop: Find the process and kill it, or restart the kernel.\")\n",
    "    print(\"\\nüìã Server Endpoints:\")\n",
    "    print(f\"   ‚Ä¢ API: http://localhost:{port}\")\n",
    "    print(f\"   ‚Ä¢ Docs: http://localhost:{port}/docs\")\n",
    "    print(f\"   ‚Ä¢ Health: http://localhost:{port}/health\")\n",
    "    \n",
    "    # Start server in background\n",
    "    import threading\n",
    "    \n",
    "    def run_server():\n",
    "        subprocess.run(\n",
    "            [\n",
    "                str(python_path),\n",
    "                \"-m\", \"uvicorn\",\n",
    "                \"src.api.app:app\",\n",
    "                \"--reload\",\n",
    "                \"--port\", str(port),\n",
    "                \"--host\", \"0.0.0.0\"\n",
    "            ],\n",
    "            cwd=Path.cwd()\n",
    "        )\n",
    "    \n",
    "    server_thread = threading.Thread(target=run_server, daemon=True)\n",
    "    server_thread.start()\n",
    "    \n",
    "    # Wait a bit and check if server started\n",
    "    print(\"\\n‚è≥ Waiting for server to start...\")\n",
    "    for i in range(10):\n",
    "        time.sleep(1)\n",
    "        if check_port(port):\n",
    "            print(f\"‚úÖ Backend server is running on port {port}!\")\n",
    "            return True\n",
    "        print(f\"   Waiting... ({i+1}/10)\")\n",
    "    \n",
    "    print(\"‚ö†Ô∏è  Server may still be starting. Check manually:\")\n",
    "    print(f\"   curl http://localhost:{port}/health\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "print(\"üí° To start the backend server, you have two options:\")\n",
    "print(\"\\n1Ô∏è‚É£  Run in this notebook (uncomment below):\")\n",
    "print(\"   # start_backend()\")\n",
    "print(\"\\n2Ô∏è‚É£  Run in a separate terminal (recommended):\")\n",
    "print(\"   ./scripts/start_server.sh\")\n",
    "print(\"\\n   Or manually:\")\n",
    "print(\"   source env/bin/activate\")\n",
    "print(\"   python -m uvicorn src.api.app:app --reload --port 8001 --host 0.0.0.0\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Start Frontend\n",
    "\n",
    "The frontend is a React application that runs on port 3001. You'll need to install Node.js dependencies first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "def setup_frontend():\n",
    "    \"\"\"Setup and start the frontend.\"\"\"\n",
    "    print(\"üé® Frontend Setup and Start\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    frontend_dir = Path(\"src/ui/web\")\n",
    "    if not frontend_dir.exists():\n",
    "        print(f\"‚ùå Frontend directory not found: {frontend_dir}\")\n",
    "        return False\n",
    "    \n",
    "    # Check if node_modules exists\n",
    "    node_modules = frontend_dir / \"node_modules\"\n",
    "    if not node_modules.exists():\n",
    "        print(\"\\nüì¶ Installing Node.js dependencies...\")\n",
    "        print(\"   This may take a few minutes...\")\n",
    "        \n",
    "        result = subprocess.run(\n",
    "            [\"npm\", \"install\"],\n",
    "            cwd=frontend_dir,\n",
    "            capture_output=True,\n",
    "            text=True\n",
    "        )\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"‚úÖ Dependencies installed\")\n",
    "        else:\n",
    "            print(f\"‚ùå Failed to install dependencies: {result.stderr}\")\n",
    "            return False\n",
    "    else:\n",
    "        print(\"‚úÖ Node.js dependencies already installed\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"‚úÖ Frontend setup complete!\")\n",
    "    print(\"\\nüìã To start the frontend, run in a separate terminal:\")\n",
    "    print(f\"   cd {frontend_dir}\")\n",
    "    print(\"   npm start\")\n",
    "    print(\"\\n   The frontend will be available at: http://localhost:3001\")\n",
    "    print(\"   Default login: admin / (check DEFAULT_ADMIN_PASSWORD in .env)\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Setup frontend\n",
    "setup_frontend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 13: Verification\n",
    "\n",
    "Let's verify that everything is set up correctly and the services are running.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import subprocess\n",
    "import socket\n",
    "from pathlib import Path\n",
    "\n",
    "def check_service(host, port, name):\n",
    "    \"\"\"Check if a service is running on a port.\"\"\"\n",
    "    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    sock.settimeout(2)\n",
    "    result = sock.connect_ex((host, port))\n",
    "    sock.close()\n",
    "    return result == 0\n",
    "\n",
    "def verify_setup():\n",
    "    \"\"\"Verify the complete setup.\"\"\"\n",
    "    print(\"‚úÖ Verification Checklist\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    checks = {\n",
    "        \"Virtual Environment\": Path(\"env\").exists(),\n",
    "        \"Environment File\": Path(\".env\").exists(),\n",
    "        \"Backend Port (8001)\": check_service(\"localhost\", 8001, \"Backend\"),\n",
    "        \"Frontend Port (3001)\": check_service(\"localhost\", 3001, \"Frontend\"),\n",
    "        \"TimescaleDB (5435)\": check_service(\"localhost\", 5435, \"TimescaleDB\"),\n",
    "        \"Redis (6379)\": check_service(\"localhost\", 6379, \"Redis\"),\n",
    "        \"Milvus (19530)\": check_service(\"localhost\", 19530, \"Milvus\"),\n",
    "    }\n",
    "    \n",
    "    print(\"\\nüîç Service Status:\\n\")\n",
    "    for service, status in checks.items():\n",
    "        status_icon = \"‚úÖ\" if status else \"‚ùå\"\n",
    "        print(f\"  {status_icon} {service:25} {'Running' if status else 'Not Running'}\")\n",
    "    \n",
    "    # Test backend health endpoint\n",
    "    print(\"\\nüè• Backend Health Check:\")\n",
    "    try:\n",
    "        response = requests.get(\"http://localhost:8001/health\", timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            print(\"  ‚úÖ Backend is healthy\")\n",
    "            health_data = response.json()\n",
    "            if isinstance(health_data, dict):\n",
    "                print(f\"     Status: {health_data.get('status', 'unknown')}\")\n",
    "        else:\n",
    "            print(f\"  ‚ö†Ô∏è  Backend returned status {response.status_code}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"  ‚ùå Backend health check failed: {e}\")\n",
    "    \n",
    "    # Test API endpoint\n",
    "    print(\"\\nüîå API Endpoint Check:\")\n",
    "    try:\n",
    "        response = requests.get(\"http://localhost:8001/api/v1/version\", timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            print(\"  ‚úÖ API is accessible\")\n",
    "            version_data = response.json()\n",
    "            if isinstance(version_data, dict):\n",
    "                print(f\"     Version: {version_data.get('version', 'unknown')}\")\n",
    "        else:\n",
    "            print(f\"  ‚ö†Ô∏è  API returned status {response.status_code}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"  ‚ùå API check failed: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    \n",
    "    all_checks = all(checks.values())\n",
    "    if all_checks:\n",
    "        print(\"üéâ All checks passed! Your setup is complete!\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Some checks failed. Please review the status above.\")\n",
    "    \n",
    "    print(\"\\nüìã Access Points:\")\n",
    "    print(\"   ‚Ä¢ Frontend: http://localhost:3001\")\n",
    "    print(\"   ‚Ä¢ Backend API: http://localhost:8001\")\n",
    "    print(\"   ‚Ä¢ API Docs: http://localhost:8001/docs\")\n",
    "    print(\"   ‚Ä¢ Health Check: http://localhost:8001/health\")\n",
    "    \n",
    "    return all_checks\n",
    "\n",
    "# Run verification\n",
    "verify_setup()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 14: Troubleshooting\n",
    "\n",
    "### Common Issues and Solutions\n",
    "\n",
    "#### 1. Port Already in Use\n",
    "\n",
    "If a port is already in use, you can either:\n",
    "- Stop the existing service\n",
    "- Change the port in the configuration\n",
    "\n",
    "**Backend (port 8001):**\n",
    "```bash\n",
    "# Find and kill process\n",
    "lsof -ti:8001 | xargs kill -9\n",
    "# Or change port: export PORT=8002\n",
    "```\n",
    "\n",
    "**Frontend (port 3001):**\n",
    "```bash\n",
    "# Find and kill process\n",
    "lsof -ti:3001 | xargs kill -9\n",
    "# Or change port: PORT=3002 npm start\n",
    "```\n",
    "\n",
    "#### 2. Database Connection Errors\n",
    "\n",
    "**Check if TimescaleDB is running:**\n",
    "```bash\n",
    "docker ps | grep timescaledb\n",
    "```\n",
    "\n",
    "**Test connection:**\n",
    "```bash\n",
    "PGPASSWORD=${POSTGRES_PASSWORD:-changeme} psql -h localhost -p 5435 -U warehouse -d warehouse -c \"SELECT 1;\"\n",
    "```\n",
    "\n",
    "#### 3. Missing Dependencies\n",
    "\n",
    "**Python:**\n",
    "```bash\n",
    "source env/bin/activate\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "**Node.js:**\n",
    "```bash\n",
    "cd src/ui/web\n",
    "npm install\n",
    "```\n",
    "\n",
    "#### 4. NVIDIA API Key Issues\n",
    "\n",
    "- Verify your API key at https://build.nvidia.com/\n",
    "- Check that `NVIDIA_API_KEY` is set in `.env`\n",
    "- Test the API key with a curl command (see DEPLOYMENT.md)\n",
    "\n",
    "#### 5. Node.js Version Issues\n",
    "\n",
    "If you see `Cannot find module 'node:path'`:\n",
    "- Upgrade to Node.js 18.17.0+ (recommended: 20.0.0+)\n",
    "- Check version: `node --version`\n",
    "- Use nvm to switch versions: `nvm use 20`\n",
    "\n",
    "### Getting Help\n",
    "\n",
    "- **Documentation**: See `DEPLOYMENT.md` for detailed deployment guide\n",
    "- **Issues**: Check GitHub Issues for known problems\n",
    "- **Logs**: Check service logs for error messages\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. ‚úÖ Access the frontend at http://localhost:3001\n",
    "2. ‚úÖ Log in with admin credentials\n",
    "3. ‚úÖ Explore the features:\n",
    "   - Chat Assistant\n",
    "   - Equipment Management\n",
    "   - Forecasting\n",
    "   - Operations\n",
    "   - Safety\n",
    "   - Document Extraction\n",
    "\n",
    "**Congratulations! Your Warehouse Operational Assistant is now set up and running! üéâ**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Summary\n",
    "print(\"üìã Setup Summary\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n‚úÖ Completed Steps:\")\n",
    "print(\"   1. Prerequisites verified\")\n",
    "print(\"   2. Repository setup\")\n",
    "print(\"   3. Environment configured\")\n",
    "print(\"   4. API keys configured\")\n",
    "print(\"   5. Infrastructure services started\")\n",
    "print(\"   6. Database migrations completed\")\n",
    "print(\"   7. Default users created\")\n",
    "print(\"   8. Demo data generated (optional)\")\n",
    "print(\"\\nüöÄ Next Steps:\")\n",
    "print(\"   1. Start backend: ./scripts/start_server.sh\")\n",
    "print(\"   2. Start frontend: cd src/ui/web && npm start\")\n",
    "print(\"   3. Access: http://localhost:3001\")\n",
    "print(\"\\nüìö Documentation:\")\n",
    "print(\"   ‚Ä¢ DEPLOYMENT.md - Detailed deployment guide\")\n",
    "print(\"   ‚Ä¢ README.md - Project overview\")\n",
    "print(\"   ‚Ä¢ docs/ - Additional documentation\")\n",
    "print(\"\\nüéâ Setup complete! Happy coding!\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
